{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75e7585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries and packages\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import pandas as pd\n",
    "from xgboost import plot_importance\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import imblearn\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.datasets as datasets\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from numpy import argmax \n",
    "from lightgbm import early_stopping\n",
    "import copy\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c1b9cf",
   "metadata": {},
   "source": [
    "# We start the data reading and data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "858aa1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading data from data file\n",
    "\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "# df.head()     # Checking the entries\n",
    "# df.shape      #Getting the data on number of entries\n",
    "# df.Lowest_distortion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc6507a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We removed all the theoretically non-exhisting molecules \n",
    "# Here we removed entries that had no structure label or data on valence electrons.\n",
    "\n",
    "df.drop(df.index[(df[\"Lowest_distortion\"] == \"-\")],axis=0,inplace=True)     \n",
    "df.drop(df.index[(df[\"Valence_B\"] == \"5\")],axis=0,inplace=True)\n",
    "df.drop(df.index[(df[\"Valence_A\"] == \"5\")],axis=0,inplace=True)\n",
    "df.drop(df.index[(df[\"Valence_B\"] == \"4\")],axis=0,inplace=True)\n",
    "df.drop(df.index[(df[\"Valence_A\"] == \"4\")],axis=0,inplace=True)\n",
    "df.drop(df.index[(df[\"Valence_A\"] == \"element not in BV\")],axis=0,inplace=True)\n",
    "df.drop(df.index[(df[\"Valence_B\"] == \"element not in BV\")],axis=0,inplace=True)\n",
    "df.drop(df.index[(df[\"Vacancy_energy_eV_per_O_atom\"] == \"-\")],axis=0,inplace=True)\n",
    "\n",
    "# df.Lowest_distortion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c815ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chemical_formula</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>In_literature</th>\n",
       "      <th>Valence_A</th>\n",
       "      <th>Valence_B</th>\n",
       "      <th>Radius_A_angs</th>\n",
       "      <th>Radius_B_angs</th>\n",
       "      <th>Lowest_distortion</th>\n",
       "      <th>Formation_energy_eVperatom</th>\n",
       "      <th>Stability_eV_per_atom</th>\n",
       "      <th>Magnetic_moment_mu_B</th>\n",
       "      <th>Volume_per_atom_A_cube_per_atom</th>\n",
       "      <th>Band_gap_eV</th>\n",
       "      <th>Vacancy_energy_eV_per_O_atom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>AgAlO3</td>\n",
       "      <td>Ag</td>\n",
       "      <td>Al</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.510</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.898</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-1.341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>AgBO3</td>\n",
       "      <td>Ag</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.350</td>\n",
       "      <td>1.074</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.138</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-2.641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>AgBaO3</td>\n",
       "      <td>Ag</td>\n",
       "      <td>Ba</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.631</td>\n",
       "      <td>0.247</td>\n",
       "      <td>-6.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>AgBeO3</td>\n",
       "      <td>Ag</td>\n",
       "      <td>Be</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.616</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.781</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-3.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>AgCaO3</td>\n",
       "      <td>Ag</td>\n",
       "      <td>Ca</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.975</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.204</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-6.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5321</th>\n",
       "      <td>ZrTmO3</td>\n",
       "      <td>Zr</td>\n",
       "      <td>Tm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.315</td>\n",
       "      <td>1.295</td>\n",
       "      <td>0.200</td>\n",
       "      <td>14.496</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-3.645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5325</th>\n",
       "      <td>ZrYO3</td>\n",
       "      <td>Zr</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.126</td>\n",
       "      <td>1.422</td>\n",
       "      <td>0.200</td>\n",
       "      <td>15.277</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-4.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5326</th>\n",
       "      <td>ZrYbO3</td>\n",
       "      <td>Zr</td>\n",
       "      <td>Yb</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.455</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.000</td>\n",
       "      <td>13.136</td>\n",
       "      <td>4.007</td>\n",
       "      <td>-6.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5327</th>\n",
       "      <td>ZrZnO3</td>\n",
       "      <td>Zr</td>\n",
       "      <td>Zn</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.630</td>\n",
       "      <td>1.210</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10.804</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5328</th>\n",
       "      <td>Zr2O3</td>\n",
       "      <td>Zr</td>\n",
       "      <td>Zr</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.382</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.382</td>\n",
       "      <td>13.915</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2638 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Chemical_formula   A   B In_literature Valence_A Valence_B  \\\n",
       "75             AgAlO3  Ag  Al             0         0         0   \n",
       "78              AgBO3  Ag   B             0         1         1   \n",
       "79             AgBaO3  Ag  Ba             0         0         0   \n",
       "80             AgBeO3  Ag  Be             0         0         0   \n",
       "82             AgCaO3  Ag  Ca             0         0         0   \n",
       "...               ...  ..  ..           ...       ...       ...   \n",
       "5321           ZrTmO3  Zr  Tm             0         0         0   \n",
       "5325            ZrYO3  Zr   Y             0         0         0   \n",
       "5326           ZrYbO3  Zr  Yb             0         0         0   \n",
       "5327           ZrZnO3  Zr  Zn             0         0         0   \n",
       "5328            Zr2O3  Zr  Zr             0         0         0   \n",
       "\n",
       "      Radius_A_angs  Radius_B_angs Lowest_distortion  \\\n",
       "75             1.28           0.54                 1   \n",
       "78             0.75           0.27                 0   \n",
       "79             1.28           1.35                 1   \n",
       "80             1.28           0.45                 0   \n",
       "82             1.28           1.00                 2   \n",
       "...             ...            ...               ...   \n",
       "5321           0.89           0.96                 0   \n",
       "5325           0.89           0.90                 0   \n",
       "5326           0.89           0.95                 1   \n",
       "5327           0.89           0.74                 0   \n",
       "5328           0.89           0.72                 0   \n",
       "\n",
       "     Formation_energy_eVperatom Stability_eV_per_atom Magnetic_moment_mu_B  \\\n",
       "75                       -1.510                 0.235                 0.00   \n",
       "78                       -0.350                 1.074                 0.00   \n",
       "79                       -0.989                 0.388                 0.00   \n",
       "80                       -0.616                 0.683                 0.00   \n",
       "82                       -0.975                 0.435                 0.00   \n",
       "...                         ...                   ...                  ...   \n",
       "5321                     -2.315                 1.295                0.200   \n",
       "5325                     -2.126                 1.422                0.200   \n",
       "5326                     -3.455                 0.205                0.000   \n",
       "5327                     -1.630                 1.210                0.001   \n",
       "5328                     -2.382                 0.906                0.382   \n",
       "\n",
       "     Volume_per_atom_A_cube_per_atom Band_gap_eV Vacancy_energy_eV_per_O_atom  \n",
       "75                             9.898       0.000                       -1.341  \n",
       "78                             8.138       0.000                       -2.641  \n",
       "79                            15.631       0.247                       -6.975  \n",
       "80                             8.781       0.000                       -3.058  \n",
       "82                            14.204       0.000                       -6.108  \n",
       "...                              ...         ...                          ...  \n",
       "5321                          14.496       0.000                       -3.645  \n",
       "5325                          15.277       0.000                       -4.920  \n",
       "5326                          13.136       4.007                       -6.177  \n",
       "5327                          10.804       0.000                       -0.762  \n",
       "5328                          13.915       0.000                        3.218  \n",
       "\n",
       "[2638 rows x 15 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing Strings with integers so that we dont encounter errors in smote\n",
    "# print(df)\n",
    "\n",
    "\n",
    "df['Valence_A'] = df['Valence_A'].replace(['not balanced'], '0')    #Replacing not balanced with 0\n",
    "df['Valence_A'] = df['Valence_A'].replace(['3'], '1')               #Replacing 3 with 1\n",
    "df['Valence_B'] = df['Valence_B'].replace(['not balanced'], '0')    #Replacing not balanced with 0\n",
    "df['Valence_B'] = df['Valence_B'].replace(['3'], '1')               #Replacing 3 with 1\n",
    "\n",
    "\n",
    "\n",
    "df['Lowest_distortion'] = df['Lowest_distortion'].replace(['cubic'], '0')        #Replacing cubic-0,orthorhombic-1,rhombohedral-2,tetragonal-3\n",
    "df['Lowest_distortion'] = df['Lowest_distortion'].replace(['orthorhombic'], '1')\n",
    "df['Lowest_distortion'] = df['Lowest_distortion'].replace(['rhombohedral'], '2')\n",
    "df['Lowest_distortion'] = df['Lowest_distortion'].replace(['tetragonal'], '3')\n",
    "df['Magnetic_moment_mu_B'] = df['Magnetic_moment_mu_B'].replace(['-'], '0.00')\n",
    "\n",
    "df['In_literature'] = df['In_literature'].replace([False], '0')   #Replacing False with 0\n",
    "df['In_literature'] = df['In_literature'].replace([True], '1')    #Replacing True with 1\n",
    "\n",
    "\n",
    "df.drop(['alpha_deg', 'beta_deg', 'gamma_deg'], axis=1, inplace=True)\n",
    "df.drop(['a_angs', 'b_angs', 'c_angs'], axis=1, inplace=True)\n",
    "\n",
    "# print(df)\n",
    "df[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac9c68c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Swapping labels for simplicity.\n",
    "def df_column_switch(df, column1, column2):\n",
    "    i = list(df.columns)\n",
    "    a, b = i.index(column1), i.index(column2)\n",
    "    i[b], i[a] = i[a], i[b]\n",
    "    df = df[i]\n",
    "    return df\n",
    "df = df_column_switch(df, \"Lowest_distortion\", \"Vacancy_energy_eV_per_O_atom\")\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f51c7800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '0' '0' ... '0' '0' '0']\n"
     ]
    }
   ],
   "source": [
    "training_data = df.sample(frac=0.8, random_state=25)   #Distributing data set into training and testing dataset\n",
    "testing_data = df.drop(training_data.index)            # Getting the testing data from dataframe\n",
    "\n",
    "\n",
    "train_data = training_data.values\n",
    "X_train = train_data[:, 3:14]\n",
    "Y_train = train_data[:,14]\n",
    "# print(X_train)\n",
    "# print(Y_train)\n",
    "# print(len(Y_train))\n",
    "# print(len(X_train))\n",
    "\n",
    "test_data = testing_data.values\n",
    "X_test = test_data[:, 3:14]\n",
    "Y_test = test_data[:,14]\n",
    "print(Y_train)\n",
    "# X_test.shape\n",
    "# Y_test.shape\n",
    "# X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0642e65",
   "metadata": {},
   "source": [
    "# Applying SMOTE here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78123e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=0, n=1279 (60.587%)\n",
      "Class=1, n=688 (32.591%)\n",
      "Class=2, n=100 (4.737%)\n",
      "Class=3, n=44 (2.084%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=0, n=1279 (25.000%)\n",
      "Class=1, n=1279 (25.000%)\n",
      "Class=2, n=1279 (25.000%)\n",
      "Class=3, n=1279 (25.000%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_train = LabelEncoder().fit_transform(Y_train)\n",
    "#Applying SMOTE\n",
    "\n",
    "# print(len(X_train))\n",
    "#Showing data imbalance\n",
    "# print(Y_train)\n",
    "counter = Counter(Y_train)\n",
    "for k,v in counter.items():\n",
    " per = v / len(Y_train) * 100\n",
    " print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "# plot the distribution\n",
    "pyplot.bar(counter.keys(), counter.values())\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "#Applying SMOTE\n",
    "oversample = SMOTE()\n",
    "X_train, Y_train = oversample.fit_resample(X_train, Y_train)\n",
    "\n",
    "\n",
    "# Summarize distribution after SMOTE\n",
    "counter = Counter(Y_train)\n",
    "for k,v in counter.items():\n",
    " per = v / len(Y_train) * 100\n",
    " print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "# plot the distribution\n",
    "pyplot.bar(counter.keys(), counter.values())\n",
    "pyplot.show()\n",
    "\n",
    "# print(X_test)\n",
    "#Here we oversampled the data with SMOTE ignoring the first 3 columns as they are not important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a1866d",
   "metadata": {},
   "source": [
    "# Validation and parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02a2d52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2563\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[1]\tvalid_0's multi_logloss: 1.36316\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.34039\n",
      "[3]\tvalid_0's multi_logloss: 1.31866\n",
      "[4]\tvalid_0's multi_logloss: 1.2979\n",
      "[5]\tvalid_0's multi_logloss: 1.27801\n",
      "[6]\tvalid_0's multi_logloss: 1.25895\n",
      "[7]\tvalid_0's multi_logloss: 1.24064\n",
      "[8]\tvalid_0's multi_logloss: 1.22304\n",
      "[9]\tvalid_0's multi_logloss: 1.20613\n",
      "[10]\tvalid_0's multi_logloss: 1.18988\n",
      "[11]\tvalid_0's multi_logloss: 1.17421\n",
      "[12]\tvalid_0's multi_logloss: 1.1591\n",
      "[13]\tvalid_0's multi_logloss: 1.14453\n",
      "[14]\tvalid_0's multi_logloss: 1.13048\n",
      "[15]\tvalid_0's multi_logloss: 1.11689\n",
      "[16]\tvalid_0's multi_logloss: 1.10374\n",
      "[17]\tvalid_0's multi_logloss: 1.091\n",
      "[18]\tvalid_0's multi_logloss: 1.07873\n",
      "[19]\tvalid_0's multi_logloss: 1.0668\n",
      "[20]\tvalid_0's multi_logloss: 1.05528\n",
      "[21]\tvalid_0's multi_logloss: 1.04402\n",
      "[22]\tvalid_0's multi_logloss: 1.03327\n",
      "[23]\tvalid_0's multi_logloss: 1.02268\n",
      "[24]\tvalid_0's multi_logloss: 1.0124\n",
      "[25]\tvalid_0's multi_logloss: 1.00243\n",
      "[26]\tvalid_0's multi_logloss: 0.992849\n",
      "[27]\tvalid_0's multi_logloss: 0.983548\n",
      "[28]\tvalid_0's multi_logloss: 0.974329\n",
      "[29]\tvalid_0's multi_logloss: 0.965357\n",
      "[30]\tvalid_0's multi_logloss: 0.956833\n",
      "[31]\tvalid_0's multi_logloss: 0.948265\n",
      "[32]\tvalid_0's multi_logloss: 0.94012\n",
      "[33]\tvalid_0's multi_logloss: 0.93211\n",
      "[34]\tvalid_0's multi_logloss: 0.924265\n",
      "[35]\tvalid_0's multi_logloss: 0.91667\n",
      "[36]\tvalid_0's multi_logloss: 0.909209\n",
      "[37]\tvalid_0's multi_logloss: 0.901968\n",
      "[38]\tvalid_0's multi_logloss: 0.894818\n",
      "[39]\tvalid_0's multi_logloss: 0.887785\n",
      "[40]\tvalid_0's multi_logloss: 0.881173\n",
      "[41]\tvalid_0's multi_logloss: 0.8745\n",
      "[42]\tvalid_0's multi_logloss: 0.868021\n",
      "[43]\tvalid_0's multi_logloss: 0.861589\n",
      "[44]\tvalid_0's multi_logloss: 0.855501\n",
      "[45]\tvalid_0's multi_logloss: 0.849409\n",
      "[46]\tvalid_0's multi_logloss: 0.843303\n",
      "[47]\tvalid_0's multi_logloss: 0.837535\n",
      "[48]\tvalid_0's multi_logloss: 0.83185\n",
      "[49]\tvalid_0's multi_logloss: 0.826352\n",
      "[50]\tvalid_0's multi_logloss: 0.820802\n",
      "[51]\tvalid_0's multi_logloss: 0.815481\n",
      "[52]\tvalid_0's multi_logloss: 0.810068\n",
      "[53]\tvalid_0's multi_logloss: 0.804996\n",
      "[54]\tvalid_0's multi_logloss: 0.799856\n",
      "[55]\tvalid_0's multi_logloss: 0.795138\n",
      "[56]\tvalid_0's multi_logloss: 0.79029\n",
      "[57]\tvalid_0's multi_logloss: 0.785781\n",
      "[58]\tvalid_0's multi_logloss: 0.780848\n",
      "[59]\tvalid_0's multi_logloss: 0.776296\n",
      "[60]\tvalid_0's multi_logloss: 0.771979\n",
      "[61]\tvalid_0's multi_logloss: 0.767601\n",
      "[62]\tvalid_0's multi_logloss: 0.763122\n",
      "[63]\tvalid_0's multi_logloss: 0.758914\n",
      "[64]\tvalid_0's multi_logloss: 0.754706\n",
      "[65]\tvalid_0's multi_logloss: 0.750678\n",
      "[66]\tvalid_0's multi_logloss: 0.746795\n",
      "[67]\tvalid_0's multi_logloss: 0.742877\n",
      "[68]\tvalid_0's multi_logloss: 0.738851\n",
      "[69]\tvalid_0's multi_logloss: 0.735305\n",
      "[70]\tvalid_0's multi_logloss: 0.731431\n",
      "[71]\tvalid_0's multi_logloss: 0.72757\n",
      "[72]\tvalid_0's multi_logloss: 0.724118\n",
      "[73]\tvalid_0's multi_logloss: 0.720564\n",
      "[74]\tvalid_0's multi_logloss: 0.717089\n",
      "[75]\tvalid_0's multi_logloss: 0.713492\n",
      "[76]\tvalid_0's multi_logloss: 0.71017\n",
      "[77]\tvalid_0's multi_logloss: 0.706829\n",
      "[78]\tvalid_0's multi_logloss: 0.703523\n",
      "[79]\tvalid_0's multi_logloss: 0.70038\n",
      "[80]\tvalid_0's multi_logloss: 0.697432\n",
      "[81]\tvalid_0's multi_logloss: 0.694308\n",
      "[82]\tvalid_0's multi_logloss: 0.691103\n",
      "[83]\tvalid_0's multi_logloss: 0.68839\n",
      "[84]\tvalid_0's multi_logloss: 0.685282\n",
      "[85]\tvalid_0's multi_logloss: 0.682479\n",
      "[86]\tvalid_0's multi_logloss: 0.679463\n",
      "[87]\tvalid_0's multi_logloss: 0.67676\n",
      "[88]\tvalid_0's multi_logloss: 0.673982\n",
      "[89]\tvalid_0's multi_logloss: 0.671317\n",
      "[90]\tvalid_0's multi_logloss: 0.668659\n",
      "[91]\tvalid_0's multi_logloss: 0.665891\n",
      "[92]\tvalid_0's multi_logloss: 0.663415\n",
      "[93]\tvalid_0's multi_logloss: 0.660705\n",
      "[94]\tvalid_0's multi_logloss: 0.658258\n",
      "[95]\tvalid_0's multi_logloss: 0.655943\n",
      "[96]\tvalid_0's multi_logloss: 0.653178\n",
      "[97]\tvalid_0's multi_logloss: 0.650873\n",
      "[98]\tvalid_0's multi_logloss: 0.648383\n",
      "[99]\tvalid_0's multi_logloss: 0.646067\n",
      "[100]\tvalid_0's multi_logloss: 0.643821\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.643821\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       339\n",
      "           1       0.76      0.74      0.75       311\n",
      "           2       0.78      0.69      0.73       302\n",
      "           3       0.79      0.91      0.85       327\n",
      "\n",
      "    accuracy                           0.83      1279\n",
      "   macro avg       0.83      0.83      0.82      1279\n",
      "weighted avg       0.83      0.83      0.83      1279\n",
      "\n",
      "[[327   5   3   4]\n",
      " [  1 230  44  36]\n",
      " [  6  51 207  38]\n",
      " [  3  15  10 299]]\n",
      "Accuracy: 83.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    }
   ],
   "source": [
    "# 'num_leaves': 2\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 2,\n",
    "    'learning_rate': 0.02,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "745ed15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2563\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[1]\tvalid_0's multi_logloss: 1.35737\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.32958\n",
      "[3]\tvalid_0's multi_logloss: 1.30292\n",
      "[4]\tvalid_0's multi_logloss: 1.27762\n",
      "[5]\tvalid_0's multi_logloss: 1.25375\n",
      "[6]\tvalid_0's multi_logloss: 1.2307\n",
      "[7]\tvalid_0's multi_logloss: 1.20847\n",
      "[8]\tvalid_0's multi_logloss: 1.18723\n",
      "[9]\tvalid_0's multi_logloss: 1.16696\n",
      "[10]\tvalid_0's multi_logloss: 1.14781\n",
      "[11]\tvalid_0's multi_logloss: 1.12917\n",
      "[12]\tvalid_0's multi_logloss: 1.11127\n",
      "[13]\tvalid_0's multi_logloss: 1.09409\n",
      "[14]\tvalid_0's multi_logloss: 1.07781\n",
      "[15]\tvalid_0's multi_logloss: 1.06215\n",
      "[16]\tvalid_0's multi_logloss: 1.04692\n",
      "[17]\tvalid_0's multi_logloss: 1.03209\n",
      "[18]\tvalid_0's multi_logloss: 1.01795\n",
      "[19]\tvalid_0's multi_logloss: 1.00445\n",
      "[20]\tvalid_0's multi_logloss: 0.99105\n",
      "[21]\tvalid_0's multi_logloss: 0.977985\n",
      "[22]\tvalid_0's multi_logloss: 0.965472\n",
      "[23]\tvalid_0's multi_logloss: 0.952933\n",
      "[24]\tvalid_0's multi_logloss: 0.940925\n",
      "[25]\tvalid_0's multi_logloss: 0.929434\n",
      "[26]\tvalid_0's multi_logloss: 0.918368\n",
      "[27]\tvalid_0's multi_logloss: 0.907387\n",
      "[28]\tvalid_0's multi_logloss: 0.896737\n",
      "[29]\tvalid_0's multi_logloss: 0.886683\n",
      "[30]\tvalid_0's multi_logloss: 0.876693\n",
      "[31]\tvalid_0's multi_logloss: 0.867159\n",
      "[32]\tvalid_0's multi_logloss: 0.85766\n",
      "[33]\tvalid_0's multi_logloss: 0.848654\n",
      "[34]\tvalid_0's multi_logloss: 0.839809\n",
      "[35]\tvalid_0's multi_logloss: 0.83126\n",
      "[36]\tvalid_0's multi_logloss: 0.82284\n",
      "[37]\tvalid_0's multi_logloss: 0.814878\n",
      "[38]\tvalid_0's multi_logloss: 0.806817\n",
      "[39]\tvalid_0's multi_logloss: 0.799121\n",
      "[40]\tvalid_0's multi_logloss: 0.791439\n",
      "[41]\tvalid_0's multi_logloss: 0.784068\n",
      "[42]\tvalid_0's multi_logloss: 0.776879\n",
      "[43]\tvalid_0's multi_logloss: 0.769682\n",
      "[44]\tvalid_0's multi_logloss: 0.762797\n",
      "[45]\tvalid_0's multi_logloss: 0.756095\n",
      "[46]\tvalid_0's multi_logloss: 0.749361\n",
      "[47]\tvalid_0's multi_logloss: 0.743022\n",
      "[48]\tvalid_0's multi_logloss: 0.736534\n",
      "[49]\tvalid_0's multi_logloss: 0.730255\n",
      "[50]\tvalid_0's multi_logloss: 0.724288\n",
      "[51]\tvalid_0's multi_logloss: 0.718237\n",
      "[52]\tvalid_0's multi_logloss: 0.712408\n",
      "[53]\tvalid_0's multi_logloss: 0.706681\n",
      "[54]\tvalid_0's multi_logloss: 0.701072\n",
      "[55]\tvalid_0's multi_logloss: 0.695655\n",
      "[56]\tvalid_0's multi_logloss: 0.690119\n",
      "[57]\tvalid_0's multi_logloss: 0.68502\n",
      "[58]\tvalid_0's multi_logloss: 0.67988\n",
      "[59]\tvalid_0's multi_logloss: 0.674807\n",
      "[60]\tvalid_0's multi_logloss: 0.669899\n",
      "[61]\tvalid_0's multi_logloss: 0.664908\n",
      "[62]\tvalid_0's multi_logloss: 0.660341\n",
      "[63]\tvalid_0's multi_logloss: 0.655871\n",
      "[64]\tvalid_0's multi_logloss: 0.651336\n",
      "[65]\tvalid_0's multi_logloss: 0.646832\n",
      "[66]\tvalid_0's multi_logloss: 0.642709\n",
      "[67]\tvalid_0's multi_logloss: 0.638437\n",
      "[68]\tvalid_0's multi_logloss: 0.634324\n",
      "[69]\tvalid_0's multi_logloss: 0.630248\n",
      "[70]\tvalid_0's multi_logloss: 0.626461\n",
      "[71]\tvalid_0's multi_logloss: 0.622388\n",
      "[72]\tvalid_0's multi_logloss: 0.618599\n",
      "[73]\tvalid_0's multi_logloss: 0.614615\n",
      "[74]\tvalid_0's multi_logloss: 0.610824\n",
      "[75]\tvalid_0's multi_logloss: 0.607172\n",
      "[76]\tvalid_0's multi_logloss: 0.603391\n",
      "[77]\tvalid_0's multi_logloss: 0.599688\n",
      "[78]\tvalid_0's multi_logloss: 0.596345\n",
      "[79]\tvalid_0's multi_logloss: 0.592788\n",
      "[80]\tvalid_0's multi_logloss: 0.589316\n",
      "[81]\tvalid_0's multi_logloss: 0.586\n",
      "[82]\tvalid_0's multi_logloss: 0.582804\n",
      "[83]\tvalid_0's multi_logloss: 0.579518\n",
      "[84]\tvalid_0's multi_logloss: 0.576335\n",
      "[85]\tvalid_0's multi_logloss: 0.573226\n",
      "[86]\tvalid_0's multi_logloss: 0.570248\n",
      "[87]\tvalid_0's multi_logloss: 0.567164\n",
      "[88]\tvalid_0's multi_logloss: 0.564372\n",
      "[89]\tvalid_0's multi_logloss: 0.561591\n",
      "[90]\tvalid_0's multi_logloss: 0.558575\n",
      "[91]\tvalid_0's multi_logloss: 0.55579\n",
      "[92]\tvalid_0's multi_logloss: 0.553167\n",
      "[93]\tvalid_0's multi_logloss: 0.550485\n",
      "[94]\tvalid_0's multi_logloss: 0.547637\n",
      "[95]\tvalid_0's multi_logloss: 0.545184\n",
      "[96]\tvalid_0's multi_logloss: 0.542862\n",
      "[97]\tvalid_0's multi_logloss: 0.540467\n",
      "[98]\tvalid_0's multi_logloss: 0.537958\n",
      "[99]\tvalid_0's multi_logloss: 0.535581\n",
      "[100]\tvalid_0's multi_logloss: 0.533131\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.533131\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       339\n",
      "           1       0.76      0.76      0.76       311\n",
      "           2       0.80      0.71      0.75       302\n",
      "           3       0.82      0.92      0.87       327\n",
      "\n",
      "    accuracy                           0.84      1279\n",
      "   macro avg       0.84      0.84      0.84      1279\n",
      "weighted avg       0.84      0.84      0.84      1279\n",
      "\n",
      "[[327   3   5   4]\n",
      " [  1 236  41  33]\n",
      " [  5  55 214  28]\n",
      " [  3  15   7 302]]\n",
      "Accuracy: 84.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    }
   ],
   "source": [
    "# 'num_leaves': 3\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 3,\n",
    "    'learning_rate': 0.02,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5916bc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2563\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[1]\tvalid_0's multi_logloss: 1.35334\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.32155\n",
      "[3]\tvalid_0's multi_logloss: 1.29157\n",
      "[4]\tvalid_0's multi_logloss: 1.26308\n",
      "[5]\tvalid_0's multi_logloss: 1.23611\n",
      "[6]\tvalid_0's multi_logloss: 1.21042\n",
      "[7]\tvalid_0's multi_logloss: 1.18584\n",
      "[8]\tvalid_0's multi_logloss: 1.16265\n",
      "[9]\tvalid_0's multi_logloss: 1.1408\n",
      "[10]\tvalid_0's multi_logloss: 1.11983\n",
      "[11]\tvalid_0's multi_logloss: 1.09936\n",
      "[12]\tvalid_0's multi_logloss: 1.08032\n",
      "[13]\tvalid_0's multi_logloss: 1.06155\n",
      "[14]\tvalid_0's multi_logloss: 1.04366\n",
      "[15]\tvalid_0's multi_logloss: 1.02657\n",
      "[16]\tvalid_0's multi_logloss: 1.00996\n",
      "[17]\tvalid_0's multi_logloss: 0.993622\n",
      "[18]\tvalid_0's multi_logloss: 0.978314\n",
      "[19]\tvalid_0's multi_logloss: 0.963311\n",
      "[20]\tvalid_0's multi_logloss: 0.948642\n",
      "[21]\tvalid_0's multi_logloss: 0.934255\n",
      "[22]\tvalid_0's multi_logloss: 0.920596\n",
      "[23]\tvalid_0's multi_logloss: 0.907176\n",
      "[24]\tvalid_0's multi_logloss: 0.894122\n",
      "[25]\tvalid_0's multi_logloss: 0.881304\n",
      "[26]\tvalid_0's multi_logloss: 0.868831\n",
      "[27]\tvalid_0's multi_logloss: 0.857045\n",
      "[28]\tvalid_0's multi_logloss: 0.845468\n",
      "[29]\tvalid_0's multi_logloss: 0.834302\n",
      "[30]\tvalid_0's multi_logloss: 0.823405\n",
      "[31]\tvalid_0's multi_logloss: 0.812964\n",
      "[32]\tvalid_0's multi_logloss: 0.802662\n",
      "[33]\tvalid_0's multi_logloss: 0.79283\n",
      "[34]\tvalid_0's multi_logloss: 0.783317\n",
      "[35]\tvalid_0's multi_logloss: 0.774065\n",
      "[36]\tvalid_0's multi_logloss: 0.764761\n",
      "[37]\tvalid_0's multi_logloss: 0.755935\n",
      "[38]\tvalid_0's multi_logloss: 0.747258\n",
      "[39]\tvalid_0's multi_logloss: 0.738847\n",
      "[40]\tvalid_0's multi_logloss: 0.730782\n",
      "[41]\tvalid_0's multi_logloss: 0.722792\n",
      "[42]\tvalid_0's multi_logloss: 0.71497\n",
      "[43]\tvalid_0's multi_logloss: 0.707471\n",
      "[44]\tvalid_0's multi_logloss: 0.70038\n",
      "[45]\tvalid_0's multi_logloss: 0.693228\n",
      "[46]\tvalid_0's multi_logloss: 0.686341\n",
      "[47]\tvalid_0's multi_logloss: 0.679591\n",
      "[48]\tvalid_0's multi_logloss: 0.672914\n",
      "[49]\tvalid_0's multi_logloss: 0.666321\n",
      "[50]\tvalid_0's multi_logloss: 0.659629\n",
      "[51]\tvalid_0's multi_logloss: 0.653485\n",
      "[52]\tvalid_0's multi_logloss: 0.647187\n",
      "[53]\tvalid_0's multi_logloss: 0.641342\n",
      "[54]\tvalid_0's multi_logloss: 0.635261\n",
      "[55]\tvalid_0's multi_logloss: 0.629453\n",
      "[56]\tvalid_0's multi_logloss: 0.6239\n",
      "[57]\tvalid_0's multi_logloss: 0.618397\n",
      "[58]\tvalid_0's multi_logloss: 0.613126\n",
      "[59]\tvalid_0's multi_logloss: 0.607867\n",
      "[60]\tvalid_0's multi_logloss: 0.602858\n",
      "[61]\tvalid_0's multi_logloss: 0.597776\n",
      "[62]\tvalid_0's multi_logloss: 0.593088\n",
      "[63]\tvalid_0's multi_logloss: 0.588217\n",
      "[64]\tvalid_0's multi_logloss: 0.583414\n",
      "[65]\tvalid_0's multi_logloss: 0.578666\n",
      "[66]\tvalid_0's multi_logloss: 0.574033\n",
      "[67]\tvalid_0's multi_logloss: 0.569733\n",
      "[68]\tvalid_0's multi_logloss: 0.565415\n",
      "[69]\tvalid_0's multi_logloss: 0.561277\n",
      "[70]\tvalid_0's multi_logloss: 0.55709\n",
      "[71]\tvalid_0's multi_logloss: 0.552871\n",
      "[72]\tvalid_0's multi_logloss: 0.54876\n",
      "[73]\tvalid_0's multi_logloss: 0.545008\n",
      "[74]\tvalid_0's multi_logloss: 0.541177\n",
      "[75]\tvalid_0's multi_logloss: 0.53753\n",
      "[76]\tvalid_0's multi_logloss: 0.533923\n",
      "[77]\tvalid_0's multi_logloss: 0.530249\n",
      "[78]\tvalid_0's multi_logloss: 0.526863\n",
      "[79]\tvalid_0's multi_logloss: 0.523651\n",
      "[80]\tvalid_0's multi_logloss: 0.520447\n",
      "[81]\tvalid_0's multi_logloss: 0.517092\n",
      "[82]\tvalid_0's multi_logloss: 0.51377\n",
      "[83]\tvalid_0's multi_logloss: 0.510651\n",
      "[84]\tvalid_0's multi_logloss: 0.507612\n",
      "[85]\tvalid_0's multi_logloss: 0.504848\n",
      "[86]\tvalid_0's multi_logloss: 0.501612\n",
      "[87]\tvalid_0's multi_logloss: 0.498622\n",
      "[88]\tvalid_0's multi_logloss: 0.495467\n",
      "[89]\tvalid_0's multi_logloss: 0.492861\n",
      "[90]\tvalid_0's multi_logloss: 0.490035\n",
      "[91]\tvalid_0's multi_logloss: 0.487264\n",
      "[92]\tvalid_0's multi_logloss: 0.484452\n",
      "[93]\tvalid_0's multi_logloss: 0.481718\n",
      "[94]\tvalid_0's multi_logloss: 0.479178\n",
      "[95]\tvalid_0's multi_logloss: 0.476688\n",
      "[96]\tvalid_0's multi_logloss: 0.474014\n",
      "[97]\tvalid_0's multi_logloss: 0.471835\n",
      "[98]\tvalid_0's multi_logloss: 0.469474\n",
      "[99]\tvalid_0's multi_logloss: 0.467182\n",
      "[100]\tvalid_0's multi_logloss: 0.464471\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.464471\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       339\n",
      "           1       0.77      0.80      0.78       311\n",
      "           2       0.84      0.73      0.78       302\n",
      "           3       0.85      0.93      0.89       327\n",
      "\n",
      "    accuracy                           0.86      1279\n",
      "   macro avg       0.86      0.86      0.86      1279\n",
      "weighted avg       0.86      0.86      0.86      1279\n",
      "\n",
      "[[327   6   3   3]\n",
      " [  1 250  33  27]\n",
      " [  4  54 219  25]\n",
      " [  0  16   7 304]]\n",
      "Accuracy: 86.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    }
   ],
   "source": [
    "# 'num_leaves': 4\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 4,\n",
    "    'learning_rate': 0.02,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da9cfafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2563\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[1]\tvalid_0's multi_logloss: 1.35125\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.31752\n",
      "[3]\tvalid_0's multi_logloss: 1.28569\n",
      "[4]\tvalid_0's multi_logloss: 1.25565\n",
      "[5]\tvalid_0's multi_logloss: 1.22706\n",
      "[6]\tvalid_0's multi_logloss: 1.20018\n",
      "[7]\tvalid_0's multi_logloss: 1.1744\n",
      "[8]\tvalid_0's multi_logloss: 1.14983\n",
      "[9]\tvalid_0's multi_logloss: 1.12657\n",
      "[10]\tvalid_0's multi_logloss: 1.10473\n",
      "[11]\tvalid_0's multi_logloss: 1.08321\n",
      "[12]\tvalid_0's multi_logloss: 1.06323\n",
      "[13]\tvalid_0's multi_logloss: 1.04403\n",
      "[14]\tvalid_0's multi_logloss: 1.02546\n",
      "[15]\tvalid_0's multi_logloss: 1.00763\n",
      "[16]\tvalid_0's multi_logloss: 0.99006\n",
      "[17]\tvalid_0's multi_logloss: 0.973498\n",
      "[18]\tvalid_0's multi_logloss: 0.957354\n",
      "[19]\tvalid_0's multi_logloss: 0.94155\n",
      "[20]\tvalid_0's multi_logloss: 0.926091\n",
      "[21]\tvalid_0's multi_logloss: 0.911036\n",
      "[22]\tvalid_0's multi_logloss: 0.896909\n",
      "[23]\tvalid_0's multi_logloss: 0.882738\n",
      "[24]\tvalid_0's multi_logloss: 0.869429\n",
      "[25]\tvalid_0's multi_logloss: 0.8564\n",
      "[26]\tvalid_0's multi_logloss: 0.843685\n",
      "[27]\tvalid_0's multi_logloss: 0.831618\n",
      "[28]\tvalid_0's multi_logloss: 0.819677\n",
      "[29]\tvalid_0's multi_logloss: 0.808247\n",
      "[30]\tvalid_0's multi_logloss: 0.79709\n",
      "[31]\tvalid_0's multi_logloss: 0.786368\n",
      "[32]\tvalid_0's multi_logloss: 0.775859\n",
      "[33]\tvalid_0's multi_logloss: 0.765469\n",
      "[34]\tvalid_0's multi_logloss: 0.755645\n",
      "[35]\tvalid_0's multi_logloss: 0.746228\n",
      "[36]\tvalid_0's multi_logloss: 0.736718\n",
      "[37]\tvalid_0's multi_logloss: 0.727327\n",
      "[38]\tvalid_0's multi_logloss: 0.718538\n",
      "[39]\tvalid_0's multi_logloss: 0.709764\n",
      "[40]\tvalid_0's multi_logloss: 0.701395\n",
      "[41]\tvalid_0's multi_logloss: 0.693356\n",
      "[42]\tvalid_0's multi_logloss: 0.685314\n",
      "[43]\tvalid_0's multi_logloss: 0.677407\n",
      "[44]\tvalid_0's multi_logloss: 0.669788\n",
      "[45]\tvalid_0's multi_logloss: 0.662254\n",
      "[46]\tvalid_0's multi_logloss: 0.655361\n",
      "[47]\tvalid_0's multi_logloss: 0.648615\n",
      "[48]\tvalid_0's multi_logloss: 0.641719\n",
      "[49]\tvalid_0's multi_logloss: 0.634347\n",
      "[50]\tvalid_0's multi_logloss: 0.627345\n",
      "[51]\tvalid_0's multi_logloss: 0.621066\n",
      "[52]\tvalid_0's multi_logloss: 0.614578\n",
      "[53]\tvalid_0's multi_logloss: 0.608459\n",
      "[54]\tvalid_0's multi_logloss: 0.6027\n",
      "[55]\tvalid_0's multi_logloss: 0.596652\n",
      "[56]\tvalid_0's multi_logloss: 0.590696\n",
      "[57]\tvalid_0's multi_logloss: 0.585095\n",
      "[58]\tvalid_0's multi_logloss: 0.578955\n",
      "[59]\tvalid_0's multi_logloss: 0.573315\n",
      "[60]\tvalid_0's multi_logloss: 0.568095\n",
      "[61]\tvalid_0's multi_logloss: 0.562401\n",
      "[62]\tvalid_0's multi_logloss: 0.557133\n",
      "[63]\tvalid_0's multi_logloss: 0.552296\n",
      "[64]\tvalid_0's multi_logloss: 0.54741\n",
      "[65]\tvalid_0's multi_logloss: 0.542186\n",
      "[66]\tvalid_0's multi_logloss: 0.537875\n",
      "[67]\tvalid_0's multi_logloss: 0.533124\n",
      "[68]\tvalid_0's multi_logloss: 0.528429\n",
      "[69]\tvalid_0's multi_logloss: 0.523894\n",
      "[70]\tvalid_0's multi_logloss: 0.519314\n",
      "[71]\tvalid_0's multi_logloss: 0.515327\n",
      "[72]\tvalid_0's multi_logloss: 0.511177\n",
      "[73]\tvalid_0's multi_logloss: 0.506916\n",
      "[74]\tvalid_0's multi_logloss: 0.50286\n",
      "[75]\tvalid_0's multi_logloss: 0.498945\n",
      "[76]\tvalid_0's multi_logloss: 0.494931\n",
      "[77]\tvalid_0's multi_logloss: 0.490704\n",
      "[78]\tvalid_0's multi_logloss: 0.48676\n",
      "[79]\tvalid_0's multi_logloss: 0.483319\n",
      "[80]\tvalid_0's multi_logloss: 0.479985\n",
      "[81]\tvalid_0's multi_logloss: 0.476625\n",
      "[82]\tvalid_0's multi_logloss: 0.473224\n",
      "[83]\tvalid_0's multi_logloss: 0.469785\n",
      "[84]\tvalid_0's multi_logloss: 0.46629\n",
      "[85]\tvalid_0's multi_logloss: 0.463146\n",
      "[86]\tvalid_0's multi_logloss: 0.459612\n",
      "[87]\tvalid_0's multi_logloss: 0.456634\n",
      "[88]\tvalid_0's multi_logloss: 0.453431\n",
      "[89]\tvalid_0's multi_logloss: 0.450371\n",
      "[90]\tvalid_0's multi_logloss: 0.447231\n",
      "[91]\tvalid_0's multi_logloss: 0.444282\n",
      "[92]\tvalid_0's multi_logloss: 0.441425\n",
      "[93]\tvalid_0's multi_logloss: 0.43838\n",
      "[94]\tvalid_0's multi_logloss: 0.435638\n",
      "[95]\tvalid_0's multi_logloss: 0.433224\n",
      "[96]\tvalid_0's multi_logloss: 0.430452\n",
      "[97]\tvalid_0's multi_logloss: 0.427482\n",
      "[98]\tvalid_0's multi_logloss: 0.424978\n",
      "[99]\tvalid_0's multi_logloss: 0.422612\n",
      "[100]\tvalid_0's multi_logloss: 0.42016\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.42016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       339\n",
      "           1       0.79      0.81      0.80       311\n",
      "           2       0.86      0.76      0.81       302\n",
      "           3       0.86      0.95      0.90       327\n",
      "\n",
      "    accuracy                           0.88      1279\n",
      "   macro avg       0.87      0.87      0.87      1279\n",
      "weighted avg       0.88      0.88      0.87      1279\n",
      "\n",
      "[[327   7   3   2]\n",
      " [  0 251  33  27]\n",
      " [  4  46 230  22]\n",
      " [  0  12   3 312]]\n",
      "Accuracy: 87.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    }
   ],
   "source": [
    "# 'num_leaves': 5\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 5,\n",
    "    'learning_rate': 0.02,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99fae220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000535 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2563\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[1]\tvalid_0's multi_logloss: 1.35\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.31503\n",
      "[3]\tvalid_0's multi_logloss: 1.28202\n",
      "[4]\tvalid_0's multi_logloss: 1.25075\n",
      "[5]\tvalid_0's multi_logloss: 1.22128\n",
      "[6]\tvalid_0's multi_logloss: 1.19308\n",
      "[7]\tvalid_0's multi_logloss: 1.16623\n",
      "[8]\tvalid_0's multi_logloss: 1.14109\n",
      "[9]\tvalid_0's multi_logloss: 1.11688\n",
      "[10]\tvalid_0's multi_logloss: 1.09353\n",
      "[11]\tvalid_0's multi_logloss: 1.07197\n",
      "[12]\tvalid_0's multi_logloss: 1.05025\n",
      "[13]\tvalid_0's multi_logloss: 1.03019\n",
      "[14]\tvalid_0's multi_logloss: 1.01118\n",
      "[15]\tvalid_0's multi_logloss: 0.99237\n",
      "[16]\tvalid_0's multi_logloss: 0.973948\n",
      "[17]\tvalid_0's multi_logloss: 0.956602\n",
      "[18]\tvalid_0's multi_logloss: 0.940339\n",
      "[19]\tvalid_0's multi_logloss: 0.923509\n",
      "[20]\tvalid_0's multi_logloss: 0.908372\n",
      "[21]\tvalid_0's multi_logloss: 0.892895\n",
      "[22]\tvalid_0's multi_logloss: 0.878265\n",
      "[23]\tvalid_0's multi_logloss: 0.863474\n",
      "[24]\tvalid_0's multi_logloss: 0.849188\n",
      "[25]\tvalid_0's multi_logloss: 0.835759\n",
      "[26]\tvalid_0's multi_logloss: 0.823093\n",
      "[27]\tvalid_0's multi_logloss: 0.810012\n",
      "[28]\tvalid_0's multi_logloss: 0.797754\n",
      "[29]\tvalid_0's multi_logloss: 0.786265\n",
      "[30]\tvalid_0's multi_logloss: 0.774451\n",
      "[31]\tvalid_0's multi_logloss: 0.763742\n",
      "[32]\tvalid_0's multi_logloss: 0.752418\n",
      "[33]\tvalid_0's multi_logloss: 0.741905\n",
      "[34]\tvalid_0's multi_logloss: 0.732107\n",
      "[35]\tvalid_0's multi_logloss: 0.72153\n",
      "[36]\tvalid_0's multi_logloss: 0.71173\n",
      "[37]\tvalid_0's multi_logloss: 0.701945\n",
      "[38]\tvalid_0's multi_logloss: 0.692407\n",
      "[39]\tvalid_0's multi_logloss: 0.683174\n",
      "[40]\tvalid_0's multi_logloss: 0.674324\n",
      "[41]\tvalid_0's multi_logloss: 0.665676\n",
      "[42]\tvalid_0's multi_logloss: 0.657358\n",
      "[43]\tvalid_0's multi_logloss: 0.64923\n",
      "[44]\tvalid_0's multi_logloss: 0.641407\n",
      "[45]\tvalid_0's multi_logloss: 0.633806\n",
      "[46]\tvalid_0's multi_logloss: 0.626321\n",
      "[47]\tvalid_0's multi_logloss: 0.618846\n",
      "[48]\tvalid_0's multi_logloss: 0.611712\n",
      "[49]\tvalid_0's multi_logloss: 0.604457\n",
      "[50]\tvalid_0's multi_logloss: 0.597204\n",
      "[51]\tvalid_0's multi_logloss: 0.590532\n",
      "[52]\tvalid_0's multi_logloss: 0.58364\n",
      "[53]\tvalid_0's multi_logloss: 0.577664\n",
      "[54]\tvalid_0's multi_logloss: 0.57148\n",
      "[55]\tvalid_0's multi_logloss: 0.565388\n",
      "[56]\tvalid_0's multi_logloss: 0.559494\n",
      "[57]\tvalid_0's multi_logloss: 0.55372\n",
      "[58]\tvalid_0's multi_logloss: 0.548024\n",
      "[59]\tvalid_0's multi_logloss: 0.541822\n",
      "[60]\tvalid_0's multi_logloss: 0.536062\n",
      "[61]\tvalid_0's multi_logloss: 0.530487\n",
      "[62]\tvalid_0's multi_logloss: 0.524592\n",
      "[63]\tvalid_0's multi_logloss: 0.519333\n",
      "[64]\tvalid_0's multi_logloss: 0.514125\n",
      "[65]\tvalid_0's multi_logloss: 0.508824\n",
      "[66]\tvalid_0's multi_logloss: 0.504253\n",
      "[67]\tvalid_0's multi_logloss: 0.499204\n",
      "[68]\tvalid_0's multi_logloss: 0.494699\n",
      "[69]\tvalid_0's multi_logloss: 0.489521\n",
      "[70]\tvalid_0's multi_logloss: 0.48545\n",
      "[71]\tvalid_0's multi_logloss: 0.480766\n",
      "[72]\tvalid_0's multi_logloss: 0.476714\n",
      "[73]\tvalid_0's multi_logloss: 0.47202\n",
      "[74]\tvalid_0's multi_logloss: 0.468035\n",
      "[75]\tvalid_0's multi_logloss: 0.463775\n",
      "[76]\tvalid_0's multi_logloss: 0.459709\n",
      "[77]\tvalid_0's multi_logloss: 0.455631\n",
      "[78]\tvalid_0's multi_logloss: 0.451883\n",
      "[79]\tvalid_0's multi_logloss: 0.448018\n",
      "[80]\tvalid_0's multi_logloss: 0.444443\n",
      "[81]\tvalid_0's multi_logloss: 0.440814\n",
      "[82]\tvalid_0's multi_logloss: 0.437083\n",
      "[83]\tvalid_0's multi_logloss: 0.433834\n",
      "[84]\tvalid_0's multi_logloss: 0.430738\n",
      "[85]\tvalid_0's multi_logloss: 0.427405\n",
      "[86]\tvalid_0's multi_logloss: 0.424335\n",
      "[87]\tvalid_0's multi_logloss: 0.421185\n",
      "[88]\tvalid_0's multi_logloss: 0.417957\n",
      "[89]\tvalid_0's multi_logloss: 0.415057\n",
      "[90]\tvalid_0's multi_logloss: 0.411758\n",
      "[91]\tvalid_0's multi_logloss: 0.409061\n",
      "[92]\tvalid_0's multi_logloss: 0.406061\n",
      "[93]\tvalid_0's multi_logloss: 0.403095\n",
      "[94]\tvalid_0's multi_logloss: 0.40038\n",
      "[95]\tvalid_0's multi_logloss: 0.397485\n",
      "[96]\tvalid_0's multi_logloss: 0.394816\n",
      "[97]\tvalid_0's multi_logloss: 0.39195\n",
      "[98]\tvalid_0's multi_logloss: 0.389272\n",
      "[99]\tvalid_0's multi_logloss: 0.386803\n",
      "[100]\tvalid_0's multi_logloss: 0.384188\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.384188\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       339\n",
      "           1       0.80      0.83      0.82       311\n",
      "           2       0.87      0.77      0.82       302\n",
      "           3       0.88      0.97      0.92       327\n",
      "\n",
      "    accuracy                           0.89      1279\n",
      "   macro avg       0.89      0.89      0.89      1279\n",
      "weighted avg       0.89      0.89      0.89      1279\n",
      "\n",
      "[[327   7   3   2]\n",
      " [  0 259  28  24]\n",
      " [  2  50 233  17]\n",
      " [  0   6   3 318]]\n",
      "Accuracy: 88.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    }
   ],
   "source": [
    "# 'num_leaves': 6\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 6,\n",
    "    'learning_rate': 0.02,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c118157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2563\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[1]\tvalid_0's multi_logloss: 1.3489\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.31304\n",
      "[3]\tvalid_0's multi_logloss: 1.27901\n",
      "[4]\tvalid_0's multi_logloss: 1.24697\n",
      "[5]\tvalid_0's multi_logloss: 1.21665\n",
      "[6]\tvalid_0's multi_logloss: 1.18778\n",
      "[7]\tvalid_0's multi_logloss: 1.16017\n",
      "[8]\tvalid_0's multi_logloss: 1.13397\n",
      "[9]\tvalid_0's multi_logloss: 1.10896\n",
      "[10]\tvalid_0's multi_logloss: 1.08496\n",
      "[11]\tvalid_0's multi_logloss: 1.06184\n",
      "[12]\tvalid_0's multi_logloss: 1.03894\n",
      "[13]\tvalid_0's multi_logloss: 1.01819\n",
      "[14]\tvalid_0's multi_logloss: 0.998002\n",
      "[15]\tvalid_0's multi_logloss: 0.978423\n",
      "[16]\tvalid_0's multi_logloss: 0.960204\n",
      "[17]\tvalid_0's multi_logloss: 0.941997\n",
      "[18]\tvalid_0's multi_logloss: 0.92503\n",
      "[19]\tvalid_0's multi_logloss: 0.908693\n",
      "[20]\tvalid_0's multi_logloss: 0.892065\n",
      "[21]\tvalid_0's multi_logloss: 0.877032\n",
      "[22]\tvalid_0's multi_logloss: 0.862339\n",
      "[23]\tvalid_0's multi_logloss: 0.847456\n",
      "[24]\tvalid_0's multi_logloss: 0.833506\n",
      "[25]\tvalid_0's multi_logloss: 0.81976\n",
      "[26]\tvalid_0's multi_logloss: 0.806696\n",
      "[27]\tvalid_0's multi_logloss: 0.793509\n",
      "[28]\tvalid_0's multi_logloss: 0.780806\n",
      "[29]\tvalid_0's multi_logloss: 0.768586\n",
      "[30]\tvalid_0's multi_logloss: 0.757079\n",
      "[31]\tvalid_0's multi_logloss: 0.746144\n",
      "[32]\tvalid_0's multi_logloss: 0.735544\n",
      "[33]\tvalid_0's multi_logloss: 0.724379\n",
      "[34]\tvalid_0's multi_logloss: 0.713587\n",
      "[35]\tvalid_0's multi_logloss: 0.703067\n",
      "[36]\tvalid_0's multi_logloss: 0.69303\n",
      "[37]\tvalid_0's multi_logloss: 0.683145\n",
      "[38]\tvalid_0's multi_logloss: 0.673239\n",
      "[39]\tvalid_0's multi_logloss: 0.663891\n",
      "[40]\tvalid_0's multi_logloss: 0.65432\n",
      "[41]\tvalid_0's multi_logloss: 0.645261\n",
      "[42]\tvalid_0's multi_logloss: 0.63652\n",
      "[43]\tvalid_0's multi_logloss: 0.62812\n",
      "[44]\tvalid_0's multi_logloss: 0.619608\n",
      "[45]\tvalid_0's multi_logloss: 0.611673\n",
      "[46]\tvalid_0's multi_logloss: 0.603916\n",
      "[47]\tvalid_0's multi_logloss: 0.596234\n",
      "[48]\tvalid_0's multi_logloss: 0.588931\n",
      "[49]\tvalid_0's multi_logloss: 0.58152\n",
      "[50]\tvalid_0's multi_logloss: 0.574247\n",
      "[51]\tvalid_0's multi_logloss: 0.567141\n",
      "[52]\tvalid_0's multi_logloss: 0.560115\n",
      "[53]\tvalid_0's multi_logloss: 0.553459\n",
      "[54]\tvalid_0's multi_logloss: 0.547067\n",
      "[55]\tvalid_0's multi_logloss: 0.540371\n",
      "[56]\tvalid_0's multi_logloss: 0.534531\n",
      "[57]\tvalid_0's multi_logloss: 0.528394\n",
      "[58]\tvalid_0's multi_logloss: 0.522231\n",
      "[59]\tvalid_0's multi_logloss: 0.516052\n",
      "[60]\tvalid_0's multi_logloss: 0.51038\n",
      "[61]\tvalid_0's multi_logloss: 0.505183\n",
      "[62]\tvalid_0's multi_logloss: 0.499474\n",
      "[63]\tvalid_0's multi_logloss: 0.494503\n",
      "[64]\tvalid_0's multi_logloss: 0.489037\n",
      "[65]\tvalid_0's multi_logloss: 0.483813\n",
      "[66]\tvalid_0's multi_logloss: 0.478889\n",
      "[67]\tvalid_0's multi_logloss: 0.47402\n",
      "[68]\tvalid_0's multi_logloss: 0.469276\n",
      "[69]\tvalid_0's multi_logloss: 0.464189\n",
      "[70]\tvalid_0's multi_logloss: 0.459926\n",
      "[71]\tvalid_0's multi_logloss: 0.455191\n",
      "[72]\tvalid_0's multi_logloss: 0.451006\n",
      "[73]\tvalid_0's multi_logloss: 0.446366\n",
      "[74]\tvalid_0's multi_logloss: 0.442108\n",
      "[75]\tvalid_0's multi_logloss: 0.438416\n",
      "[76]\tvalid_0's multi_logloss: 0.434428\n",
      "[77]\tvalid_0's multi_logloss: 0.430735\n",
      "[78]\tvalid_0's multi_logloss: 0.426832\n",
      "[79]\tvalid_0's multi_logloss: 0.423124\n",
      "[80]\tvalid_0's multi_logloss: 0.419677\n",
      "[81]\tvalid_0's multi_logloss: 0.416233\n",
      "[82]\tvalid_0's multi_logloss: 0.412532\n",
      "[83]\tvalid_0's multi_logloss: 0.409426\n",
      "[84]\tvalid_0's multi_logloss: 0.40583\n",
      "[85]\tvalid_0's multi_logloss: 0.402415\n",
      "[86]\tvalid_0's multi_logloss: 0.39924\n",
      "[87]\tvalid_0's multi_logloss: 0.396222\n",
      "[88]\tvalid_0's multi_logloss: 0.392786\n",
      "[89]\tvalid_0's multi_logloss: 0.389914\n",
      "[90]\tvalid_0's multi_logloss: 0.386844\n",
      "[91]\tvalid_0's multi_logloss: 0.384067\n",
      "[92]\tvalid_0's multi_logloss: 0.380867\n",
      "[93]\tvalid_0's multi_logloss: 0.377796\n",
      "[94]\tvalid_0's multi_logloss: 0.374935\n",
      "[95]\tvalid_0's multi_logloss: 0.372496\n",
      "[96]\tvalid_0's multi_logloss: 0.369627\n",
      "[97]\tvalid_0's multi_logloss: 0.367045\n",
      "[98]\tvalid_0's multi_logloss: 0.364215\n",
      "[99]\tvalid_0's multi_logloss: 0.361652\n",
      "[100]\tvalid_0's multi_logloss: 0.359034\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.359034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       339\n",
      "           1       0.82      0.85      0.83       311\n",
      "           2       0.87      0.80      0.84       302\n",
      "           3       0.91      0.98      0.94       327\n",
      "\n",
      "    accuracy                           0.90      1279\n",
      "   macro avg       0.90      0.90      0.90      1279\n",
      "weighted avg       0.90      0.90      0.90      1279\n",
      "\n",
      "[[327   7   3   2]\n",
      " [  0 263  29  19]\n",
      " [  2  48 242  10]\n",
      " [  0   4   3 320]]\n",
      "Accuracy: 90.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    }
   ],
   "source": [
    "# 'num_leaves': 7\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 7,\n",
    "    'learning_rate': 0.02,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef6abe99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000521 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2563\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[1]\tvalid_0's multi_logloss: 1.34771\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.31102\n",
      "[3]\tvalid_0's multi_logloss: 1.27555\n",
      "[4]\tvalid_0's multi_logloss: 1.24287\n",
      "[5]\tvalid_0's multi_logloss: 1.21111\n",
      "[6]\tvalid_0's multi_logloss: 1.18162\n",
      "[7]\tvalid_0's multi_logloss: 1.15354\n",
      "[8]\tvalid_0's multi_logloss: 1.12651\n",
      "[9]\tvalid_0's multi_logloss: 1.10045\n",
      "[10]\tvalid_0's multi_logloss: 1.07522\n",
      "[11]\tvalid_0's multi_logloss: 1.05143\n",
      "[12]\tvalid_0's multi_logloss: 1.02851\n",
      "[13]\tvalid_0's multi_logloss: 1.0072\n",
      "[14]\tvalid_0's multi_logloss: 0.986948\n",
      "[15]\tvalid_0's multi_logloss: 0.967693\n",
      "[16]\tvalid_0's multi_logloss: 0.948142\n",
      "[17]\tvalid_0's multi_logloss: 0.929935\n",
      "[18]\tvalid_0's multi_logloss: 0.912666\n",
      "[19]\tvalid_0's multi_logloss: 0.89498\n",
      "[20]\tvalid_0's multi_logloss: 0.878977\n",
      "[21]\tvalid_0's multi_logloss: 0.863785\n",
      "[22]\tvalid_0's multi_logloss: 0.848043\n",
      "[23]\tvalid_0's multi_logloss: 0.833378\n",
      "[24]\tvalid_0's multi_logloss: 0.81876\n",
      "[25]\tvalid_0's multi_logloss: 0.804963\n",
      "[26]\tvalid_0's multi_logloss: 0.791308\n",
      "[27]\tvalid_0's multi_logloss: 0.778235\n",
      "[28]\tvalid_0's multi_logloss: 0.765368\n",
      "[29]\tvalid_0's multi_logloss: 0.753059\n",
      "[30]\tvalid_0's multi_logloss: 0.740866\n",
      "[31]\tvalid_0's multi_logloss: 0.729382\n",
      "[32]\tvalid_0's multi_logloss: 0.717992\n",
      "[33]\tvalid_0's multi_logloss: 0.706766\n",
      "[34]\tvalid_0's multi_logloss: 0.695857\n",
      "[35]\tvalid_0's multi_logloss: 0.685134\n",
      "[36]\tvalid_0's multi_logloss: 0.675103\n",
      "[37]\tvalid_0's multi_logloss: 0.665089\n",
      "[38]\tvalid_0's multi_logloss: 0.655142\n",
      "[39]\tvalid_0's multi_logloss: 0.645756\n",
      "[40]\tvalid_0's multi_logloss: 0.636067\n",
      "[41]\tvalid_0's multi_logloss: 0.626867\n",
      "[42]\tvalid_0's multi_logloss: 0.618329\n",
      "[43]\tvalid_0's multi_logloss: 0.609413\n",
      "[44]\tvalid_0's multi_logloss: 0.600314\n",
      "[45]\tvalid_0's multi_logloss: 0.59151\n",
      "[46]\tvalid_0's multi_logloss: 0.583516\n",
      "[47]\tvalid_0's multi_logloss: 0.575284\n",
      "[48]\tvalid_0's multi_logloss: 0.567237\n",
      "[49]\tvalid_0's multi_logloss: 0.55975\n",
      "[50]\tvalid_0's multi_logloss: 0.552158\n",
      "[51]\tvalid_0's multi_logloss: 0.545042\n",
      "[52]\tvalid_0's multi_logloss: 0.53798\n",
      "[53]\tvalid_0's multi_logloss: 0.531609\n",
      "[54]\tvalid_0's multi_logloss: 0.525325\n",
      "[55]\tvalid_0's multi_logloss: 0.518523\n",
      "[56]\tvalid_0's multi_logloss: 0.512678\n",
      "[57]\tvalid_0's multi_logloss: 0.506214\n",
      "[58]\tvalid_0's multi_logloss: 0.500362\n",
      "[59]\tvalid_0's multi_logloss: 0.49414\n",
      "[60]\tvalid_0's multi_logloss: 0.488236\n",
      "[61]\tvalid_0's multi_logloss: 0.482593\n",
      "[62]\tvalid_0's multi_logloss: 0.476954\n",
      "[63]\tvalid_0's multi_logloss: 0.471536\n",
      "[64]\tvalid_0's multi_logloss: 0.466011\n",
      "[65]\tvalid_0's multi_logloss: 0.460885\n",
      "[66]\tvalid_0's multi_logloss: 0.455639\n",
      "[67]\tvalid_0's multi_logloss: 0.450907\n",
      "[68]\tvalid_0's multi_logloss: 0.445972\n",
      "[69]\tvalid_0's multi_logloss: 0.441387\n",
      "[70]\tvalid_0's multi_logloss: 0.436561\n",
      "[71]\tvalid_0's multi_logloss: 0.431931\n",
      "[72]\tvalid_0's multi_logloss: 0.427515\n",
      "[73]\tvalid_0's multi_logloss: 0.423461\n",
      "[74]\tvalid_0's multi_logloss: 0.41915\n",
      "[75]\tvalid_0's multi_logloss: 0.41503\n",
      "[76]\tvalid_0's multi_logloss: 0.411057\n",
      "[77]\tvalid_0's multi_logloss: 0.407203\n",
      "[78]\tvalid_0's multi_logloss: 0.403348\n",
      "[79]\tvalid_0's multi_logloss: 0.399607\n",
      "[80]\tvalid_0's multi_logloss: 0.396057\n",
      "[81]\tvalid_0's multi_logloss: 0.392498\n",
      "[82]\tvalid_0's multi_logloss: 0.389035\n",
      "[83]\tvalid_0's multi_logloss: 0.385741\n",
      "[84]\tvalid_0's multi_logloss: 0.382555\n",
      "[85]\tvalid_0's multi_logloss: 0.379389\n",
      "[86]\tvalid_0's multi_logloss: 0.376204\n",
      "[87]\tvalid_0's multi_logloss: 0.373162\n",
      "[88]\tvalid_0's multi_logloss: 0.370005\n",
      "[89]\tvalid_0's multi_logloss: 0.366844\n",
      "[90]\tvalid_0's multi_logloss: 0.363403\n",
      "[91]\tvalid_0's multi_logloss: 0.360293\n",
      "[92]\tvalid_0's multi_logloss: 0.357404\n",
      "[93]\tvalid_0's multi_logloss: 0.354699\n",
      "[94]\tvalid_0's multi_logloss: 0.3517\n",
      "[95]\tvalid_0's multi_logloss: 0.348962\n",
      "[96]\tvalid_0's multi_logloss: 0.346532\n",
      "[97]\tvalid_0's multi_logloss: 0.344192\n",
      "[98]\tvalid_0's multi_logloss: 0.341798\n",
      "[99]\tvalid_0's multi_logloss: 0.339298\n",
      "[100]\tvalid_0's multi_logloss: 0.336907\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.336907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       339\n",
      "           1       0.83      0.85      0.84       311\n",
      "           2       0.87      0.82      0.85       302\n",
      "           3       0.93      0.98      0.96       327\n",
      "\n",
      "    accuracy                           0.91      1279\n",
      "   macro avg       0.91      0.91      0.91      1279\n",
      "weighted avg       0.91      0.91      0.91      1279\n",
      "\n",
      "[[328   7   3   1]\n",
      " [  0 265  31  15]\n",
      " [  2  44 249   7]\n",
      " [  0   4   2 321]]\n",
      "Accuracy: 90.93%\n"
     ]
    }
   ],
   "source": [
    "# 'num_leaves': 8\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 8,\n",
    "    'learning_rate': 0.02,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a303dcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000507 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2563\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[1]\tvalid_0's multi_logloss: 1.3463\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.3086\n",
      "[3]\tvalid_0's multi_logloss: 1.27295\n",
      "[4]\tvalid_0's multi_logloss: 1.23922\n",
      "[5]\tvalid_0's multi_logloss: 1.20662\n",
      "[6]\tvalid_0's multi_logloss: 1.17591\n",
      "[7]\tvalid_0's multi_logloss: 1.14721\n",
      "[8]\tvalid_0's multi_logloss: 1.11938\n",
      "[9]\tvalid_0's multi_logloss: 1.09293\n",
      "[10]\tvalid_0's multi_logloss: 1.06717\n",
      "[11]\tvalid_0's multi_logloss: 1.04279\n",
      "[12]\tvalid_0's multi_logloss: 1.0198\n",
      "[13]\tvalid_0's multi_logloss: 0.997681\n",
      "[14]\tvalid_0's multi_logloss: 0.976848\n",
      "[15]\tvalid_0's multi_logloss: 0.956781\n",
      "[16]\tvalid_0's multi_logloss: 0.937563\n",
      "[17]\tvalid_0's multi_logloss: 0.919034\n",
      "[18]\tvalid_0's multi_logloss: 0.901203\n",
      "[19]\tvalid_0's multi_logloss: 0.884521\n",
      "[20]\tvalid_0's multi_logloss: 0.867389\n",
      "[21]\tvalid_0's multi_logloss: 0.85178\n",
      "[22]\tvalid_0's multi_logloss: 0.836386\n",
      "[23]\tvalid_0's multi_logloss: 0.820709\n",
      "[24]\tvalid_0's multi_logloss: 0.806775\n",
      "[25]\tvalid_0's multi_logloss: 0.792395\n",
      "[26]\tvalid_0's multi_logloss: 0.778454\n",
      "[27]\tvalid_0's multi_logloss: 0.765128\n",
      "[28]\tvalid_0's multi_logloss: 0.751998\n",
      "[29]\tvalid_0's multi_logloss: 0.738998\n",
      "[30]\tvalid_0's multi_logloss: 0.726338\n",
      "[31]\tvalid_0's multi_logloss: 0.714171\n",
      "[32]\tvalid_0's multi_logloss: 0.702647\n",
      "[33]\tvalid_0's multi_logloss: 0.691226\n",
      "[34]\tvalid_0's multi_logloss: 0.680121\n",
      "[35]\tvalid_0's multi_logloss: 0.669355\n",
      "[36]\tvalid_0's multi_logloss: 0.658922\n",
      "[37]\tvalid_0's multi_logloss: 0.648239\n",
      "[38]\tvalid_0's multi_logloss: 0.6378\n",
      "[39]\tvalid_0's multi_logloss: 0.627473\n",
      "[40]\tvalid_0's multi_logloss: 0.617493\n",
      "[41]\tvalid_0's multi_logloss: 0.608054\n",
      "[42]\tvalid_0's multi_logloss: 0.598634\n",
      "[43]\tvalid_0's multi_logloss: 0.589516\n",
      "[44]\tvalid_0's multi_logloss: 0.580911\n",
      "[45]\tvalid_0's multi_logloss: 0.572767\n",
      "[46]\tvalid_0's multi_logloss: 0.564436\n",
      "[47]\tvalid_0's multi_logloss: 0.556572\n",
      "[48]\tvalid_0's multi_logloss: 0.549098\n",
      "[49]\tvalid_0's multi_logloss: 0.541386\n",
      "[50]\tvalid_0's multi_logloss: 0.533777\n",
      "[51]\tvalid_0's multi_logloss: 0.526919\n",
      "[52]\tvalid_0's multi_logloss: 0.519721\n",
      "[53]\tvalid_0's multi_logloss: 0.513207\n",
      "[54]\tvalid_0's multi_logloss: 0.506465\n",
      "[55]\tvalid_0's multi_logloss: 0.499602\n",
      "[56]\tvalid_0's multi_logloss: 0.492978\n",
      "[57]\tvalid_0's multi_logloss: 0.486892\n",
      "[58]\tvalid_0's multi_logloss: 0.480946\n",
      "[59]\tvalid_0's multi_logloss: 0.474864\n",
      "[60]\tvalid_0's multi_logloss: 0.469296\n",
      "[61]\tvalid_0's multi_logloss: 0.463508\n",
      "[62]\tvalid_0's multi_logloss: 0.457932\n",
      "[63]\tvalid_0's multi_logloss: 0.452849\n",
      "[64]\tvalid_0's multi_logloss: 0.447332\n",
      "[65]\tvalid_0's multi_logloss: 0.442639\n",
      "[66]\tvalid_0's multi_logloss: 0.437557\n",
      "[67]\tvalid_0's multi_logloss: 0.432748\n",
      "[68]\tvalid_0's multi_logloss: 0.428065\n",
      "[69]\tvalid_0's multi_logloss: 0.423393\n",
      "[70]\tvalid_0's multi_logloss: 0.419187\n",
      "[71]\tvalid_0's multi_logloss: 0.414671\n",
      "[72]\tvalid_0's multi_logloss: 0.410291\n",
      "[73]\tvalid_0's multi_logloss: 0.405975\n",
      "[74]\tvalid_0's multi_logloss: 0.401973\n",
      "[75]\tvalid_0's multi_logloss: 0.397908\n",
      "[76]\tvalid_0's multi_logloss: 0.393863\n",
      "[77]\tvalid_0's multi_logloss: 0.390348\n",
      "[78]\tvalid_0's multi_logloss: 0.386263\n",
      "[79]\tvalid_0's multi_logloss: 0.382483\n",
      "[80]\tvalid_0's multi_logloss: 0.378734\n",
      "[81]\tvalid_0's multi_logloss: 0.37496\n",
      "[82]\tvalid_0's multi_logloss: 0.371801\n",
      "[83]\tvalid_0's multi_logloss: 0.368165\n",
      "[84]\tvalid_0's multi_logloss: 0.364943\n",
      "[85]\tvalid_0's multi_logloss: 0.361622\n",
      "[86]\tvalid_0's multi_logloss: 0.358253\n",
      "[87]\tvalid_0's multi_logloss: 0.35505\n",
      "[88]\tvalid_0's multi_logloss: 0.351856\n",
      "[89]\tvalid_0's multi_logloss: 0.348845\n",
      "[90]\tvalid_0's multi_logloss: 0.345764\n",
      "[91]\tvalid_0's multi_logloss: 0.342637\n",
      "[92]\tvalid_0's multi_logloss: 0.339578\n",
      "[93]\tvalid_0's multi_logloss: 0.336709\n",
      "[94]\tvalid_0's multi_logloss: 0.333907\n",
      "[95]\tvalid_0's multi_logloss: 0.331048\n",
      "[96]\tvalid_0's multi_logloss: 0.328246\n",
      "[97]\tvalid_0's multi_logloss: 0.325331\n",
      "[98]\tvalid_0's multi_logloss: 0.322678\n",
      "[99]\tvalid_0's multi_logloss: 0.320046\n",
      "[100]\tvalid_0's multi_logloss: 0.317665\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.317665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       339\n",
      "           1       0.85      0.86      0.86       311\n",
      "           2       0.88      0.85      0.87       302\n",
      "           3       0.94      0.98      0.96       327\n",
      "\n",
      "    accuracy                           0.92      1279\n",
      "   macro avg       0.92      0.92      0.92      1279\n",
      "weighted avg       0.92      0.92      0.92      1279\n",
      "\n",
      "[[328   7   3   1]\n",
      " [  0 269  28  14]\n",
      " [  2  38 257   5]\n",
      " [  1   2   3 321]]\n",
      "Accuracy: 91.87%\n"
     ]
    }
   ],
   "source": [
    "# 'num_leaves': 9\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 9,\n",
    "    'learning_rate': 0.02,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3457f434",
   "metadata": {},
   "source": [
    "# Running differerent models, we find that the best accuracy was obtained for num_leaves = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2f6e9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2563\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[1]\tvalid_0's multi_logloss: 1.36789\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.34928\n",
      "[3]\tvalid_0's multi_logloss: 1.33125\n",
      "[4]\tvalid_0's multi_logloss: 1.3137\n",
      "[5]\tvalid_0's multi_logloss: 1.29662\n",
      "[6]\tvalid_0's multi_logloss: 1.28002\n",
      "[7]\tvalid_0's multi_logloss: 1.2639\n",
      "[8]\tvalid_0's multi_logloss: 1.24816\n",
      "[9]\tvalid_0's multi_logloss: 1.23285\n",
      "[10]\tvalid_0's multi_logloss: 1.21799\n",
      "[11]\tvalid_0's multi_logloss: 1.20347\n",
      "[12]\tvalid_0's multi_logloss: 1.18926\n",
      "[13]\tvalid_0's multi_logloss: 1.17543\n",
      "[14]\tvalid_0's multi_logloss: 1.16184\n",
      "[15]\tvalid_0's multi_logloss: 1.14864\n",
      "[16]\tvalid_0's multi_logloss: 1.13574\n",
      "[17]\tvalid_0's multi_logloss: 1.12311\n",
      "[18]\tvalid_0's multi_logloss: 1.11081\n",
      "[19]\tvalid_0's multi_logloss: 1.09871\n",
      "[20]\tvalid_0's multi_logloss: 1.08678\n",
      "[21]\tvalid_0's multi_logloss: 1.07524\n",
      "[22]\tvalid_0's multi_logloss: 1.06383\n",
      "[23]\tvalid_0's multi_logloss: 1.05268\n",
      "[24]\tvalid_0's multi_logloss: 1.04165\n",
      "[25]\tvalid_0's multi_logloss: 1.03118\n",
      "[26]\tvalid_0's multi_logloss: 1.02071\n",
      "[27]\tvalid_0's multi_logloss: 1.01024\n",
      "[28]\tvalid_0's multi_logloss: 1.00026\n",
      "[29]\tvalid_0's multi_logloss: 0.990664\n",
      "[30]\tvalid_0's multi_logloss: 0.981068\n",
      "[31]\tvalid_0's multi_logloss: 0.971822\n",
      "[32]\tvalid_0's multi_logloss: 0.962781\n",
      "[33]\tvalid_0's multi_logloss: 0.953601\n",
      "[34]\tvalid_0's multi_logloss: 0.944921\n",
      "[35]\tvalid_0's multi_logloss: 0.93635\n",
      "[36]\tvalid_0's multi_logloss: 0.927476\n",
      "[37]\tvalid_0's multi_logloss: 0.919291\n",
      "[38]\tvalid_0's multi_logloss: 0.911271\n",
      "[39]\tvalid_0's multi_logloss: 0.903026\n",
      "[40]\tvalid_0's multi_logloss: 0.895257\n",
      "[41]\tvalid_0's multi_logloss: 0.887551\n",
      "[42]\tvalid_0's multi_logloss: 0.879759\n",
      "[43]\tvalid_0's multi_logloss: 0.87245\n",
      "[44]\tvalid_0's multi_logloss: 0.864873\n",
      "[45]\tvalid_0's multi_logloss: 0.857535\n",
      "[46]\tvalid_0's multi_logloss: 0.850149\n",
      "[47]\tvalid_0's multi_logloss: 0.843065\n",
      "[48]\tvalid_0's multi_logloss: 0.836008\n",
      "[49]\tvalid_0's multi_logloss: 0.829191\n",
      "[50]\tvalid_0's multi_logloss: 0.822192\n",
      "[51]\tvalid_0's multi_logloss: 0.815313\n",
      "[52]\tvalid_0's multi_logloss: 0.808562\n",
      "[53]\tvalid_0's multi_logloss: 0.802446\n",
      "[54]\tvalid_0's multi_logloss: 0.795945\n",
      "[55]\tvalid_0's multi_logloss: 0.789746\n",
      "[56]\tvalid_0's multi_logloss: 0.783318\n",
      "[57]\tvalid_0's multi_logloss: 0.777078\n",
      "[58]\tvalid_0's multi_logloss: 0.770914\n",
      "[59]\tvalid_0's multi_logloss: 0.764814\n",
      "[60]\tvalid_0's multi_logloss: 0.759115\n",
      "[61]\tvalid_0's multi_logloss: 0.753589\n",
      "[62]\tvalid_0's multi_logloss: 0.748073\n",
      "[63]\tvalid_0's multi_logloss: 0.742384\n",
      "[64]\tvalid_0's multi_logloss: 0.736728\n",
      "[65]\tvalid_0's multi_logloss: 0.731228\n",
      "[66]\tvalid_0's multi_logloss: 0.725734\n",
      "[67]\tvalid_0's multi_logloss: 0.720781\n",
      "[68]\tvalid_0's multi_logloss: 0.715255\n",
      "[69]\tvalid_0's multi_logloss: 0.709997\n",
      "[70]\tvalid_0's multi_logloss: 0.704815\n",
      "[71]\tvalid_0's multi_logloss: 0.699736\n",
      "[72]\tvalid_0's multi_logloss: 0.694698\n",
      "[73]\tvalid_0's multi_logloss: 0.689598\n",
      "[74]\tvalid_0's multi_logloss: 0.684777\n",
      "[75]\tvalid_0's multi_logloss: 0.679954\n",
      "[76]\tvalid_0's multi_logloss: 0.674886\n",
      "[77]\tvalid_0's multi_logloss: 0.67032\n",
      "[78]\tvalid_0's multi_logloss: 0.665507\n",
      "[79]\tvalid_0's multi_logloss: 0.660941\n",
      "[80]\tvalid_0's multi_logloss: 0.656158\n",
      "[81]\tvalid_0's multi_logloss: 0.651586\n",
      "[82]\tvalid_0's multi_logloss: 0.647342\n",
      "[83]\tvalid_0's multi_logloss: 0.643101\n",
      "[84]\tvalid_0's multi_logloss: 0.638622\n",
      "[85]\tvalid_0's multi_logloss: 0.634334\n",
      "[86]\tvalid_0's multi_logloss: 0.629997\n",
      "[87]\tvalid_0's multi_logloss: 0.625737\n",
      "[88]\tvalid_0's multi_logloss: 0.621665\n",
      "[89]\tvalid_0's multi_logloss: 0.617493\n",
      "[90]\tvalid_0's multi_logloss: 0.613714\n",
      "[91]\tvalid_0's multi_logloss: 0.609703\n",
      "[92]\tvalid_0's multi_logloss: 0.60586\n",
      "[93]\tvalid_0's multi_logloss: 0.601876\n",
      "[94]\tvalid_0's multi_logloss: 0.598134\n",
      "[95]\tvalid_0's multi_logloss: 0.594326\n",
      "[96]\tvalid_0's multi_logloss: 0.590604\n",
      "[97]\tvalid_0's multi_logloss: 0.586924\n",
      "[98]\tvalid_0's multi_logloss: 0.583331\n",
      "[99]\tvalid_0's multi_logloss: 0.579796\n",
      "[100]\tvalid_0's multi_logloss: 0.576126\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.576126\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       339\n",
      "           1       0.79      0.79      0.79       311\n",
      "           2       0.86      0.75      0.80       302\n",
      "           3       0.84      0.95      0.89       327\n",
      "\n",
      "    accuracy                           0.87      1279\n",
      "   macro avg       0.87      0.87      0.87      1279\n",
      "weighted avg       0.87      0.87      0.87      1279\n",
      "\n",
      "[[327   6   3   3]\n",
      " [  1 247  32  31]\n",
      " [  2  45 228  27]\n",
      " [  0  13   2 312]]\n",
      "Accuracy: 87.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    }
   ],
   "source": [
    "# 'learning_rate': 0.01\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 7,\n",
    "    'learning_rate': 0.01,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "023e8d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000452 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2563\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[1]\tvalid_0's multi_logloss: 1.3489\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.31304\n",
      "[3]\tvalid_0's multi_logloss: 1.27901\n",
      "[4]\tvalid_0's multi_logloss: 1.24697\n",
      "[5]\tvalid_0's multi_logloss: 1.21665\n",
      "[6]\tvalid_0's multi_logloss: 1.18778\n",
      "[7]\tvalid_0's multi_logloss: 1.16017\n",
      "[8]\tvalid_0's multi_logloss: 1.13397\n",
      "[9]\tvalid_0's multi_logloss: 1.10896\n",
      "[10]\tvalid_0's multi_logloss: 1.08496\n",
      "[11]\tvalid_0's multi_logloss: 1.06184\n",
      "[12]\tvalid_0's multi_logloss: 1.03894\n",
      "[13]\tvalid_0's multi_logloss: 1.01819\n",
      "[14]\tvalid_0's multi_logloss: 0.998002\n",
      "[15]\tvalid_0's multi_logloss: 0.978423\n",
      "[16]\tvalid_0's multi_logloss: 0.960204\n",
      "[17]\tvalid_0's multi_logloss: 0.941997\n",
      "[18]\tvalid_0's multi_logloss: 0.92503\n",
      "[19]\tvalid_0's multi_logloss: 0.908693\n",
      "[20]\tvalid_0's multi_logloss: 0.892065\n",
      "[21]\tvalid_0's multi_logloss: 0.877032\n",
      "[22]\tvalid_0's multi_logloss: 0.862339\n",
      "[23]\tvalid_0's multi_logloss: 0.847456\n",
      "[24]\tvalid_0's multi_logloss: 0.833506\n",
      "[25]\tvalid_0's multi_logloss: 0.81976\n",
      "[26]\tvalid_0's multi_logloss: 0.806696\n",
      "[27]\tvalid_0's multi_logloss: 0.793509\n",
      "[28]\tvalid_0's multi_logloss: 0.780806\n",
      "[29]\tvalid_0's multi_logloss: 0.768586\n",
      "[30]\tvalid_0's multi_logloss: 0.757079\n",
      "[31]\tvalid_0's multi_logloss: 0.746144\n",
      "[32]\tvalid_0's multi_logloss: 0.735544\n",
      "[33]\tvalid_0's multi_logloss: 0.724379\n",
      "[34]\tvalid_0's multi_logloss: 0.713587\n",
      "[35]\tvalid_0's multi_logloss: 0.703067\n",
      "[36]\tvalid_0's multi_logloss: 0.69303\n",
      "[37]\tvalid_0's multi_logloss: 0.683145\n",
      "[38]\tvalid_0's multi_logloss: 0.673239\n",
      "[39]\tvalid_0's multi_logloss: 0.663891\n",
      "[40]\tvalid_0's multi_logloss: 0.65432\n",
      "[41]\tvalid_0's multi_logloss: 0.645261\n",
      "[42]\tvalid_0's multi_logloss: 0.63652\n",
      "[43]\tvalid_0's multi_logloss: 0.62812\n",
      "[44]\tvalid_0's multi_logloss: 0.619608\n",
      "[45]\tvalid_0's multi_logloss: 0.611673\n",
      "[46]\tvalid_0's multi_logloss: 0.603916\n",
      "[47]\tvalid_0's multi_logloss: 0.596234\n",
      "[48]\tvalid_0's multi_logloss: 0.588931\n",
      "[49]\tvalid_0's multi_logloss: 0.58152\n",
      "[50]\tvalid_0's multi_logloss: 0.574247\n",
      "[51]\tvalid_0's multi_logloss: 0.567141\n",
      "[52]\tvalid_0's multi_logloss: 0.560115\n",
      "[53]\tvalid_0's multi_logloss: 0.553459\n",
      "[54]\tvalid_0's multi_logloss: 0.547067\n",
      "[55]\tvalid_0's multi_logloss: 0.540371\n",
      "[56]\tvalid_0's multi_logloss: 0.534531\n",
      "[57]\tvalid_0's multi_logloss: 0.528394\n",
      "[58]\tvalid_0's multi_logloss: 0.522231\n",
      "[59]\tvalid_0's multi_logloss: 0.516052\n",
      "[60]\tvalid_0's multi_logloss: 0.51038\n",
      "[61]\tvalid_0's multi_logloss: 0.505183\n",
      "[62]\tvalid_0's multi_logloss: 0.499474\n",
      "[63]\tvalid_0's multi_logloss: 0.494503\n",
      "[64]\tvalid_0's multi_logloss: 0.489037\n",
      "[65]\tvalid_0's multi_logloss: 0.483813\n",
      "[66]\tvalid_0's multi_logloss: 0.478889\n",
      "[67]\tvalid_0's multi_logloss: 0.47402\n",
      "[68]\tvalid_0's multi_logloss: 0.469276\n",
      "[69]\tvalid_0's multi_logloss: 0.464189\n",
      "[70]\tvalid_0's multi_logloss: 0.459926\n",
      "[71]\tvalid_0's multi_logloss: 0.455191\n",
      "[72]\tvalid_0's multi_logloss: 0.451006\n",
      "[73]\tvalid_0's multi_logloss: 0.446366\n",
      "[74]\tvalid_0's multi_logloss: 0.442108\n",
      "[75]\tvalid_0's multi_logloss: 0.438416\n",
      "[76]\tvalid_0's multi_logloss: 0.434428\n",
      "[77]\tvalid_0's multi_logloss: 0.430735\n",
      "[78]\tvalid_0's multi_logloss: 0.426832\n",
      "[79]\tvalid_0's multi_logloss: 0.423124\n",
      "[80]\tvalid_0's multi_logloss: 0.419677\n",
      "[81]\tvalid_0's multi_logloss: 0.416233\n",
      "[82]\tvalid_0's multi_logloss: 0.412532\n",
      "[83]\tvalid_0's multi_logloss: 0.409426\n",
      "[84]\tvalid_0's multi_logloss: 0.40583\n",
      "[85]\tvalid_0's multi_logloss: 0.402415\n",
      "[86]\tvalid_0's multi_logloss: 0.39924\n",
      "[87]\tvalid_0's multi_logloss: 0.396222\n",
      "[88]\tvalid_0's multi_logloss: 0.392786\n",
      "[89]\tvalid_0's multi_logloss: 0.389914\n",
      "[90]\tvalid_0's multi_logloss: 0.386844\n",
      "[91]\tvalid_0's multi_logloss: 0.384067\n",
      "[92]\tvalid_0's multi_logloss: 0.380867\n",
      "[93]\tvalid_0's multi_logloss: 0.377796\n",
      "[94]\tvalid_0's multi_logloss: 0.374935\n",
      "[95]\tvalid_0's multi_logloss: 0.372496\n",
      "[96]\tvalid_0's multi_logloss: 0.369627\n",
      "[97]\tvalid_0's multi_logloss: 0.367045\n",
      "[98]\tvalid_0's multi_logloss: 0.364215\n",
      "[99]\tvalid_0's multi_logloss: 0.361652\n",
      "[100]\tvalid_0's multi_logloss: 0.359034\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.359034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       339\n",
      "           1       0.82      0.85      0.83       311\n",
      "           2       0.87      0.80      0.84       302\n",
      "           3       0.91      0.98      0.94       327\n",
      "\n",
      "    accuracy                           0.90      1279\n",
      "   macro avg       0.90      0.90      0.90      1279\n",
      "weighted avg       0.90      0.90      0.90      1279\n",
      "\n",
      "[[327   7   3   2]\n",
      " [  0 263  29  19]\n",
      " [  2  48 242  10]\n",
      " [  0   4   3 320]]\n",
      "Accuracy: 90.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    }
   ],
   "source": [
    "# 'learning_rate': 0.02\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 7,\n",
    "    'learning_rate': 0.02,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84e158e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2563\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[1]\tvalid_0's multi_logloss: 1.3301\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.27816\n",
      "[3]\tvalid_0's multi_logloss: 1.23019\n",
      "[4]\tvalid_0's multi_logloss: 1.18627\n",
      "[5]\tvalid_0's multi_logloss: 1.14523\n",
      "[6]\tvalid_0's multi_logloss: 1.10718\n",
      "[7]\tvalid_0's multi_logloss: 1.07161\n",
      "[8]\tvalid_0's multi_logloss: 1.03789\n",
      "[9]\tvalid_0's multi_logloss: 1.00742\n",
      "[10]\tvalid_0's multi_logloss: 0.977579\n",
      "[11]\tvalid_0's multi_logloss: 0.949707\n",
      "[12]\tvalid_0's multi_logloss: 0.924217\n",
      "[13]\tvalid_0's multi_logloss: 0.899016\n",
      "[14]\tvalid_0's multi_logloss: 0.876144\n",
      "[15]\tvalid_0's multi_logloss: 0.85343\n",
      "[16]\tvalid_0's multi_logloss: 0.832221\n",
      "[17]\tvalid_0's multi_logloss: 0.812147\n",
      "[18]\tvalid_0's multi_logloss: 0.792415\n",
      "[19]\tvalid_0's multi_logloss: 0.774324\n",
      "[20]\tvalid_0's multi_logloss: 0.755909\n",
      "[21]\tvalid_0's multi_logloss: 0.739641\n",
      "[22]\tvalid_0's multi_logloss: 0.723422\n",
      "[23]\tvalid_0's multi_logloss: 0.70797\n",
      "[24]\tvalid_0's multi_logloss: 0.692597\n",
      "[25]\tvalid_0's multi_logloss: 0.677644\n",
      "[26]\tvalid_0's multi_logloss: 0.66332\n",
      "[27]\tvalid_0's multi_logloss: 0.649091\n",
      "[28]\tvalid_0's multi_logloss: 0.635424\n",
      "[29]\tvalid_0's multi_logloss: 0.622821\n",
      "[30]\tvalid_0's multi_logloss: 0.610875\n",
      "[31]\tvalid_0's multi_logloss: 0.599157\n",
      "[32]\tvalid_0's multi_logloss: 0.587631\n",
      "[33]\tvalid_0's multi_logloss: 0.576911\n",
      "[34]\tvalid_0's multi_logloss: 0.566407\n",
      "[35]\tvalid_0's multi_logloss: 0.556145\n",
      "[36]\tvalid_0's multi_logloss: 0.54593\n",
      "[37]\tvalid_0's multi_logloss: 0.536589\n",
      "[38]\tvalid_0's multi_logloss: 0.52712\n",
      "[39]\tvalid_0's multi_logloss: 0.51816\n",
      "[40]\tvalid_0's multi_logloss: 0.509171\n",
      "[41]\tvalid_0's multi_logloss: 0.501438\n",
      "[42]\tvalid_0's multi_logloss: 0.493568\n",
      "[43]\tvalid_0's multi_logloss: 0.486002\n",
      "[44]\tvalid_0's multi_logloss: 0.478448\n",
      "[45]\tvalid_0's multi_logloss: 0.471069\n",
      "[46]\tvalid_0's multi_logloss: 0.463827\n",
      "[47]\tvalid_0's multi_logloss: 0.456901\n",
      "[48]\tvalid_0's multi_logloss: 0.450141\n",
      "[49]\tvalid_0's multi_logloss: 0.444112\n",
      "[50]\tvalid_0's multi_logloss: 0.43761\n",
      "[51]\tvalid_0's multi_logloss: 0.432314\n",
      "[52]\tvalid_0's multi_logloss: 0.42679\n",
      "[53]\tvalid_0's multi_logloss: 0.420676\n",
      "[54]\tvalid_0's multi_logloss: 0.415618\n",
      "[55]\tvalid_0's multi_logloss: 0.410261\n",
      "[56]\tvalid_0's multi_logloss: 0.405104\n",
      "[57]\tvalid_0's multi_logloss: 0.399882\n",
      "[58]\tvalid_0's multi_logloss: 0.395455\n",
      "[59]\tvalid_0's multi_logloss: 0.390625\n",
      "[60]\tvalid_0's multi_logloss: 0.386098\n",
      "[61]\tvalid_0's multi_logloss: 0.381762\n",
      "[62]\tvalid_0's multi_logloss: 0.377496\n",
      "[63]\tvalid_0's multi_logloss: 0.373073\n",
      "[64]\tvalid_0's multi_logloss: 0.368858\n",
      "[65]\tvalid_0's multi_logloss: 0.364888\n",
      "[66]\tvalid_0's multi_logloss: 0.361349\n",
      "[67]\tvalid_0's multi_logloss: 0.357666\n",
      "[68]\tvalid_0's multi_logloss: 0.35455\n",
      "[69]\tvalid_0's multi_logloss: 0.350635\n",
      "[70]\tvalid_0's multi_logloss: 0.347415\n",
      "[71]\tvalid_0's multi_logloss: 0.343753\n",
      "[72]\tvalid_0's multi_logloss: 0.340289\n",
      "[73]\tvalid_0's multi_logloss: 0.336831\n",
      "[74]\tvalid_0's multi_logloss: 0.333535\n",
      "[75]\tvalid_0's multi_logloss: 0.330415\n",
      "[76]\tvalid_0's multi_logloss: 0.326855\n",
      "[77]\tvalid_0's multi_logloss: 0.3241\n",
      "[78]\tvalid_0's multi_logloss: 0.321018\n",
      "[79]\tvalid_0's multi_logloss: 0.318157\n",
      "[80]\tvalid_0's multi_logloss: 0.315586\n",
      "[81]\tvalid_0's multi_logloss: 0.31284\n",
      "[82]\tvalid_0's multi_logloss: 0.309922\n",
      "[83]\tvalid_0's multi_logloss: 0.307022\n",
      "[84]\tvalid_0's multi_logloss: 0.304503\n",
      "[85]\tvalid_0's multi_logloss: 0.302124\n",
      "[86]\tvalid_0's multi_logloss: 0.299871\n",
      "[87]\tvalid_0's multi_logloss: 0.297433\n",
      "[88]\tvalid_0's multi_logloss: 0.294951\n",
      "[89]\tvalid_0's multi_logloss: 0.292387\n",
      "[90]\tvalid_0's multi_logloss: 0.290024\n",
      "[91]\tvalid_0's multi_logloss: 0.287837\n",
      "[92]\tvalid_0's multi_logloss: 0.285383\n",
      "[93]\tvalid_0's multi_logloss: 0.283149\n",
      "[94]\tvalid_0's multi_logloss: 0.281146\n",
      "[95]\tvalid_0's multi_logloss: 0.278888\n",
      "[96]\tvalid_0's multi_logloss: 0.276975\n",
      "[97]\tvalid_0's multi_logloss: 0.274772\n",
      "[98]\tvalid_0's multi_logloss: 0.273046\n",
      "[99]\tvalid_0's multi_logloss: 0.271245\n",
      "[100]\tvalid_0's multi_logloss: 0.269375\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.269375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       339\n",
      "           1       0.86      0.87      0.87       311\n",
      "           2       0.90      0.86      0.88       302\n",
      "           3       0.93      0.98      0.95       327\n",
      "\n",
      "    accuracy                           0.92      1279\n",
      "   macro avg       0.92      0.92      0.92      1279\n",
      "weighted avg       0.92      0.92      0.92      1279\n",
      "\n",
      "[[327   7   3   2]\n",
      " [  0 271  23  17]\n",
      " [  1  34 260   7]\n",
      " [  0   2   3 322]]\n",
      "Accuracy: 92.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    }
   ],
   "source": [
    "# 'learning_rate': 0.03\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 7,\n",
    "    'learning_rate': 0.03,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f6169b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2563\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[1]\tvalid_0's multi_logloss: 1.31149\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.24442\n",
      "[3]\tvalid_0's multi_logloss: 1.18448\n",
      "[4]\tvalid_0's multi_logloss: 1.13038\n",
      "[5]\tvalid_0's multi_logloss: 1.08143\n",
      "[6]\tvalid_0's multi_logloss: 1.03635\n",
      "[7]\tvalid_0's multi_logloss: 0.994794\n",
      "[8]\tvalid_0's multi_logloss: 0.95678\n",
      "[9]\tvalid_0's multi_logloss: 0.920933\n",
      "[10]\tvalid_0's multi_logloss: 0.889112\n",
      "[11]\tvalid_0's multi_logloss: 0.859432\n",
      "[12]\tvalid_0's multi_logloss: 0.830102\n",
      "[13]\tvalid_0's multi_logloss: 0.803523\n",
      "[14]\tvalid_0's multi_logloss: 0.778254\n",
      "[15]\tvalid_0's multi_logloss: 0.755117\n",
      "[16]\tvalid_0's multi_logloss: 0.731965\n",
      "[17]\tvalid_0's multi_logloss: 0.711074\n",
      "[18]\tvalid_0's multi_logloss: 0.691324\n",
      "[19]\tvalid_0's multi_logloss: 0.671093\n",
      "[20]\tvalid_0's multi_logloss: 0.652735\n",
      "[21]\tvalid_0's multi_logloss: 0.634932\n",
      "[22]\tvalid_0's multi_logloss: 0.618336\n",
      "[23]\tvalid_0's multi_logloss: 0.602014\n",
      "[24]\tvalid_0's multi_logloss: 0.586625\n",
      "[25]\tvalid_0's multi_logloss: 0.572629\n",
      "[26]\tvalid_0's multi_logloss: 0.55872\n",
      "[27]\tvalid_0's multi_logloss: 0.545458\n",
      "[28]\tvalid_0's multi_logloss: 0.533087\n",
      "[29]\tvalid_0's multi_logloss: 0.520976\n",
      "[30]\tvalid_0's multi_logloss: 0.50972\n",
      "[31]\tvalid_0's multi_logloss: 0.498385\n",
      "[32]\tvalid_0's multi_logloss: 0.488841\n",
      "[33]\tvalid_0's multi_logloss: 0.479029\n",
      "[34]\tvalid_0's multi_logloss: 0.469647\n",
      "[35]\tvalid_0's multi_logloss: 0.459784\n",
      "[36]\tvalid_0's multi_logloss: 0.450901\n",
      "[37]\tvalid_0's multi_logloss: 0.442019\n",
      "[38]\tvalid_0's multi_logloss: 0.433558\n",
      "[39]\tvalid_0's multi_logloss: 0.42614\n",
      "[40]\tvalid_0's multi_logloss: 0.41927\n",
      "[41]\tvalid_0's multi_logloss: 0.412227\n",
      "[42]\tvalid_0's multi_logloss: 0.405168\n",
      "[43]\tvalid_0's multi_logloss: 0.399072\n",
      "[44]\tvalid_0's multi_logloss: 0.392499\n",
      "[45]\tvalid_0's multi_logloss: 0.38653\n",
      "[46]\tvalid_0's multi_logloss: 0.380307\n",
      "[47]\tvalid_0's multi_logloss: 0.375049\n",
      "[48]\tvalid_0's multi_logloss: 0.369741\n",
      "[49]\tvalid_0's multi_logloss: 0.364961\n",
      "[50]\tvalid_0's multi_logloss: 0.359345\n",
      "[51]\tvalid_0's multi_logloss: 0.355067\n",
      "[52]\tvalid_0's multi_logloss: 0.350375\n",
      "[53]\tvalid_0's multi_logloss: 0.345517\n",
      "[54]\tvalid_0's multi_logloss: 0.341031\n",
      "[55]\tvalid_0's multi_logloss: 0.336414\n",
      "[56]\tvalid_0's multi_logloss: 0.331788\n",
      "[57]\tvalid_0's multi_logloss: 0.32725\n",
      "[58]\tvalid_0's multi_logloss: 0.323432\n",
      "[59]\tvalid_0's multi_logloss: 0.319541\n",
      "[60]\tvalid_0's multi_logloss: 0.31539\n",
      "[61]\tvalid_0's multi_logloss: 0.311636\n",
      "[62]\tvalid_0's multi_logloss: 0.308625\n",
      "[63]\tvalid_0's multi_logloss: 0.3047\n",
      "[64]\tvalid_0's multi_logloss: 0.301702\n",
      "[65]\tvalid_0's multi_logloss: 0.298208\n",
      "[66]\tvalid_0's multi_logloss: 0.295003\n",
      "[67]\tvalid_0's multi_logloss: 0.291957\n",
      "[68]\tvalid_0's multi_logloss: 0.288741\n",
      "[69]\tvalid_0's multi_logloss: 0.285949\n",
      "[70]\tvalid_0's multi_logloss: 0.282921\n",
      "[71]\tvalid_0's multi_logloss: 0.279732\n",
      "[72]\tvalid_0's multi_logloss: 0.277208\n",
      "[73]\tvalid_0's multi_logloss: 0.274692\n",
      "[74]\tvalid_0's multi_logloss: 0.271843\n",
      "[75]\tvalid_0's multi_logloss: 0.269677\n",
      "[76]\tvalid_0's multi_logloss: 0.267115\n",
      "[77]\tvalid_0's multi_logloss: 0.265069\n",
      "[78]\tvalid_0's multi_logloss: 0.262581\n",
      "[79]\tvalid_0's multi_logloss: 0.260116\n",
      "[80]\tvalid_0's multi_logloss: 0.257943\n",
      "[81]\tvalid_0's multi_logloss: 0.25586\n",
      "[82]\tvalid_0's multi_logloss: 0.254006\n",
      "[83]\tvalid_0's multi_logloss: 0.252095\n",
      "[84]\tvalid_0's multi_logloss: 0.250327\n",
      "[85]\tvalid_0's multi_logloss: 0.248395\n",
      "[86]\tvalid_0's multi_logloss: 0.246391\n",
      "[87]\tvalid_0's multi_logloss: 0.244629\n",
      "[88]\tvalid_0's multi_logloss: 0.242755\n",
      "[89]\tvalid_0's multi_logloss: 0.240686\n",
      "[90]\tvalid_0's multi_logloss: 0.239042\n",
      "[91]\tvalid_0's multi_logloss: 0.237226\n",
      "[92]\tvalid_0's multi_logloss: 0.235236\n",
      "[93]\tvalid_0's multi_logloss: 0.233424\n",
      "[94]\tvalid_0's multi_logloss: 0.231569\n",
      "[95]\tvalid_0's multi_logloss: 0.22925\n",
      "[96]\tvalid_0's multi_logloss: 0.227375\n",
      "[97]\tvalid_0's multi_logloss: 0.225975\n",
      "[98]\tvalid_0's multi_logloss: 0.224415\n",
      "[99]\tvalid_0's multi_logloss: 0.22298\n",
      "[100]\tvalid_0's multi_logloss: 0.221429\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.221429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       339\n",
      "           1       0.89      0.89      0.89       311\n",
      "           2       0.91      0.90      0.90       302\n",
      "           3       0.94      0.99      0.96       327\n",
      "\n",
      "    accuracy                           0.94      1279\n",
      "   macro avg       0.93      0.93      0.93      1279\n",
      "weighted avg       0.94      0.94      0.94      1279\n",
      "\n",
      "[[327   7   3   2]\n",
      " [  0 276  20  15]\n",
      " [  1  27 271   3]\n",
      " [  0   0   4 323]]\n",
      "Accuracy: 93.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    }
   ],
   "source": [
    "# 'learning_rate': 0.04\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 7,\n",
    "    'learning_rate': 0.04,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42e982fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2563\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[1]\tvalid_0's multi_logloss: 1.29308\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.21214\n",
      "[3]\tvalid_0's multi_logloss: 1.1418\n",
      "[4]\tvalid_0's multi_logloss: 1.07923\n",
      "[5]\tvalid_0's multi_logloss: 1.02371\n",
      "[6]\tvalid_0's multi_logloss: 0.972596\n",
      "[7]\tvalid_0's multi_logloss: 0.927029\n",
      "[8]\tvalid_0's multi_logloss: 0.885008\n",
      "[9]\tvalid_0's multi_logloss: 0.848484\n",
      "[10]\tvalid_0's multi_logloss: 0.813678\n",
      "[11]\tvalid_0's multi_logloss: 0.78124\n",
      "[12]\tvalid_0's multi_logloss: 0.751189\n",
      "[13]\tvalid_0's multi_logloss: 0.722479\n",
      "[14]\tvalid_0's multi_logloss: 0.696122\n",
      "[15]\tvalid_0's multi_logloss: 0.671399\n",
      "[16]\tvalid_0's multi_logloss: 0.647204\n",
      "[17]\tvalid_0's multi_logloss: 0.624944\n",
      "[18]\tvalid_0's multi_logloss: 0.604845\n",
      "[19]\tvalid_0's multi_logloss: 0.58583\n",
      "[20]\tvalid_0's multi_logloss: 0.567373\n",
      "[21]\tvalid_0's multi_logloss: 0.550281\n",
      "[22]\tvalid_0's multi_logloss: 0.535078\n",
      "[23]\tvalid_0's multi_logloss: 0.519816\n",
      "[24]\tvalid_0's multi_logloss: 0.505753\n",
      "[25]\tvalid_0's multi_logloss: 0.492427\n",
      "[26]\tvalid_0's multi_logloss: 0.479789\n",
      "[27]\tvalid_0's multi_logloss: 0.467329\n",
      "[28]\tvalid_0's multi_logloss: 0.4566\n",
      "[29]\tvalid_0's multi_logloss: 0.446293\n",
      "[30]\tvalid_0's multi_logloss: 0.436591\n",
      "[31]\tvalid_0's multi_logloss: 0.427249\n",
      "[32]\tvalid_0's multi_logloss: 0.418858\n",
      "[33]\tvalid_0's multi_logloss: 0.410318\n",
      "[34]\tvalid_0's multi_logloss: 0.401936\n",
      "[35]\tvalid_0's multi_logloss: 0.393229\n",
      "[36]\tvalid_0's multi_logloss: 0.385381\n",
      "[37]\tvalid_0's multi_logloss: 0.37866\n",
      "[38]\tvalid_0's multi_logloss: 0.371588\n",
      "[39]\tvalid_0's multi_logloss: 0.365328\n",
      "[40]\tvalid_0's multi_logloss: 0.358553\n",
      "[41]\tvalid_0's multi_logloss: 0.35306\n",
      "[42]\tvalid_0's multi_logloss: 0.34721\n",
      "[43]\tvalid_0's multi_logloss: 0.341239\n",
      "[44]\tvalid_0's multi_logloss: 0.335293\n",
      "[45]\tvalid_0's multi_logloss: 0.330211\n",
      "[46]\tvalid_0's multi_logloss: 0.324817\n",
      "[47]\tvalid_0's multi_logloss: 0.320147\n",
      "[48]\tvalid_0's multi_logloss: 0.315417\n",
      "[49]\tvalid_0's multi_logloss: 0.311096\n",
      "[50]\tvalid_0's multi_logloss: 0.306827\n",
      "[51]\tvalid_0's multi_logloss: 0.302148\n",
      "[52]\tvalid_0's multi_logloss: 0.297609\n",
      "[53]\tvalid_0's multi_logloss: 0.29394\n",
      "[54]\tvalid_0's multi_logloss: 0.289424\n",
      "[55]\tvalid_0's multi_logloss: 0.285641\n",
      "[56]\tvalid_0's multi_logloss: 0.282485\n",
      "[57]\tvalid_0's multi_logloss: 0.278572\n",
      "[58]\tvalid_0's multi_logloss: 0.275198\n",
      "[59]\tvalid_0's multi_logloss: 0.271462\n",
      "[60]\tvalid_0's multi_logloss: 0.26841\n",
      "[61]\tvalid_0's multi_logloss: 0.264931\n",
      "[62]\tvalid_0's multi_logloss: 0.262081\n",
      "[63]\tvalid_0's multi_logloss: 0.259194\n",
      "[64]\tvalid_0's multi_logloss: 0.256574\n",
      "[65]\tvalid_0's multi_logloss: 0.254048\n",
      "[66]\tvalid_0's multi_logloss: 0.251356\n",
      "[67]\tvalid_0's multi_logloss: 0.249155\n",
      "[68]\tvalid_0's multi_logloss: 0.246611\n",
      "[69]\tvalid_0's multi_logloss: 0.244221\n",
      "[70]\tvalid_0's multi_logloss: 0.241724\n",
      "[71]\tvalid_0's multi_logloss: 0.23906\n",
      "[72]\tvalid_0's multi_logloss: 0.236614\n",
      "[73]\tvalid_0's multi_logloss: 0.234253\n",
      "[74]\tvalid_0's multi_logloss: 0.232124\n",
      "[75]\tvalid_0's multi_logloss: 0.229755\n",
      "[76]\tvalid_0's multi_logloss: 0.227851\n",
      "[77]\tvalid_0's multi_logloss: 0.225788\n",
      "[78]\tvalid_0's multi_logloss: 0.224126\n",
      "[79]\tvalid_0's multi_logloss: 0.222496\n",
      "[80]\tvalid_0's multi_logloss: 0.22066\n",
      "[81]\tvalid_0's multi_logloss: 0.219014\n",
      "[82]\tvalid_0's multi_logloss: 0.217703\n",
      "[83]\tvalid_0's multi_logloss: 0.215543\n",
      "[84]\tvalid_0's multi_logloss: 0.213994\n",
      "[85]\tvalid_0's multi_logloss: 0.212455\n",
      "[86]\tvalid_0's multi_logloss: 0.210194\n",
      "[87]\tvalid_0's multi_logloss: 0.208365\n",
      "[88]\tvalid_0's multi_logloss: 0.206782\n",
      "[89]\tvalid_0's multi_logloss: 0.205172\n",
      "[90]\tvalid_0's multi_logloss: 0.203855\n",
      "[91]\tvalid_0's multi_logloss: 0.202371\n",
      "[92]\tvalid_0's multi_logloss: 0.200705\n",
      "[93]\tvalid_0's multi_logloss: 0.199223\n",
      "[94]\tvalid_0's multi_logloss: 0.197384\n",
      "[95]\tvalid_0's multi_logloss: 0.196268\n",
      "[96]\tvalid_0's multi_logloss: 0.195167\n",
      "[97]\tvalid_0's multi_logloss: 0.193478\n",
      "[98]\tvalid_0's multi_logloss: 0.192056\n",
      "[99]\tvalid_0's multi_logloss: 0.190682\n",
      "[100]\tvalid_0's multi_logloss: 0.189421\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.189421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       339\n",
      "           1       0.90      0.91      0.91       311\n",
      "           2       0.93      0.92      0.92       302\n",
      "           3       0.96      0.99      0.97       327\n",
      "\n",
      "    accuracy                           0.95      1279\n",
      "   macro avg       0.95      0.95      0.95      1279\n",
      "weighted avg       0.95      0.95      0.95      1279\n",
      "\n",
      "[[327   7   3   2]\n",
      " [  0 284  16  11]\n",
      " [  0  24 277   1]\n",
      " [  0   0   3 324]]\n",
      "Accuracy: 94.76%\n"
     ]
    }
   ],
   "source": [
    "# 'learning_rate': 0.05\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 7,\n",
    "    'learning_rate': 0.05,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d81e9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000538 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2563\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[1]\tvalid_0's multi_logloss: 1.23905\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.12287\n",
      "[3]\tvalid_0's multi_logloss: 1.02779\n",
      "[4]\tvalid_0's multi_logloss: 0.947741\n",
      "[5]\tvalid_0's multi_logloss: 0.881324\n",
      "[6]\tvalid_0's multi_logloss: 0.821942\n",
      "[7]\tvalid_0's multi_logloss: 0.770785\n",
      "[8]\tvalid_0's multi_logloss: 0.724588\n",
      "[9]\tvalid_0's multi_logloss: 0.681586\n",
      "[10]\tvalid_0's multi_logloss: 0.643264\n",
      "[11]\tvalid_0's multi_logloss: 0.609484\n",
      "[12]\tvalid_0's multi_logloss: 0.580109\n",
      "[13]\tvalid_0's multi_logloss: 0.55234\n",
      "[14]\tvalid_0's multi_logloss: 0.526352\n",
      "[15]\tvalid_0's multi_logloss: 0.504781\n",
      "[16]\tvalid_0's multi_logloss: 0.486409\n",
      "[17]\tvalid_0's multi_logloss: 0.464807\n",
      "[18]\tvalid_0's multi_logloss: 0.446134\n",
      "[19]\tvalid_0's multi_logloss: 0.42935\n",
      "[20]\tvalid_0's multi_logloss: 0.413806\n",
      "[21]\tvalid_0's multi_logloss: 0.401904\n",
      "[22]\tvalid_0's multi_logloss: 0.388291\n",
      "[23]\tvalid_0's multi_logloss: 0.375865\n",
      "[24]\tvalid_0's multi_logloss: 0.365794\n",
      "[25]\tvalid_0's multi_logloss: 0.355918\n",
      "[26]\tvalid_0's multi_logloss: 0.346328\n",
      "[27]\tvalid_0's multi_logloss: 0.338\n",
      "[28]\tvalid_0's multi_logloss: 0.329192\n",
      "[29]\tvalid_0's multi_logloss: 0.320574\n",
      "[30]\tvalid_0's multi_logloss: 0.31181\n",
      "[31]\tvalid_0's multi_logloss: 0.303986\n",
      "[32]\tvalid_0's multi_logloss: 0.29754\n",
      "[33]\tvalid_0's multi_logloss: 0.291835\n",
      "[34]\tvalid_0's multi_logloss: 0.284449\n",
      "[35]\tvalid_0's multi_logloss: 0.278043\n",
      "[36]\tvalid_0's multi_logloss: 0.273193\n",
      "[37]\tvalid_0's multi_logloss: 0.267442\n",
      "[38]\tvalid_0's multi_logloss: 0.262628\n",
      "[39]\tvalid_0's multi_logloss: 0.258315\n",
      "[40]\tvalid_0's multi_logloss: 0.253307\n",
      "[41]\tvalid_0's multi_logloss: 0.248723\n",
      "[42]\tvalid_0's multi_logloss: 0.244809\n",
      "[43]\tvalid_0's multi_logloss: 0.241326\n",
      "[44]\tvalid_0's multi_logloss: 0.237574\n",
      "[45]\tvalid_0's multi_logloss: 0.234226\n",
      "[46]\tvalid_0's multi_logloss: 0.230889\n",
      "[47]\tvalid_0's multi_logloss: 0.227525\n",
      "[48]\tvalid_0's multi_logloss: 0.224432\n",
      "[49]\tvalid_0's multi_logloss: 0.221194\n",
      "[50]\tvalid_0's multi_logloss: 0.21845\n",
      "[51]\tvalid_0's multi_logloss: 0.215346\n",
      "[52]\tvalid_0's multi_logloss: 0.212735\n",
      "[53]\tvalid_0's multi_logloss: 0.210088\n",
      "[54]\tvalid_0's multi_logloss: 0.207901\n",
      "[55]\tvalid_0's multi_logloss: 0.204592\n",
      "[56]\tvalid_0's multi_logloss: 0.202367\n",
      "[57]\tvalid_0's multi_logloss: 0.20006\n",
      "[58]\tvalid_0's multi_logloss: 0.19743\n",
      "[59]\tvalid_0's multi_logloss: 0.195709\n",
      "[60]\tvalid_0's multi_logloss: 0.193556\n",
      "[61]\tvalid_0's multi_logloss: 0.1915\n",
      "[62]\tvalid_0's multi_logloss: 0.189444\n",
      "[63]\tvalid_0's multi_logloss: 0.187449\n",
      "[64]\tvalid_0's multi_logloss: 0.18519\n",
      "[65]\tvalid_0's multi_logloss: 0.183208\n",
      "[66]\tvalid_0's multi_logloss: 0.180914\n",
      "[67]\tvalid_0's multi_logloss: 0.17885\n",
      "[68]\tvalid_0's multi_logloss: 0.177343\n",
      "[69]\tvalid_0's multi_logloss: 0.175244\n",
      "[70]\tvalid_0's multi_logloss: 0.173796\n",
      "[71]\tvalid_0's multi_logloss: 0.172447\n",
      "[72]\tvalid_0's multi_logloss: 0.171405\n",
      "[73]\tvalid_0's multi_logloss: 0.169748\n",
      "[74]\tvalid_0's multi_logloss: 0.168185\n",
      "[75]\tvalid_0's multi_logloss: 0.166946\n",
      "[76]\tvalid_0's multi_logloss: 0.165418\n",
      "[77]\tvalid_0's multi_logloss: 0.164268\n",
      "[78]\tvalid_0's multi_logloss: 0.162509\n",
      "[79]\tvalid_0's multi_logloss: 0.161526\n",
      "[80]\tvalid_0's multi_logloss: 0.160607\n",
      "[81]\tvalid_0's multi_logloss: 0.159377\n",
      "[82]\tvalid_0's multi_logloss: 0.157774\n",
      "[83]\tvalid_0's multi_logloss: 0.15685\n",
      "[84]\tvalid_0's multi_logloss: 0.155604\n",
      "[85]\tvalid_0's multi_logloss: 0.154887\n",
      "[86]\tvalid_0's multi_logloss: 0.153598\n",
      "[87]\tvalid_0's multi_logloss: 0.151772\n",
      "[88]\tvalid_0's multi_logloss: 0.150595\n",
      "[89]\tvalid_0's multi_logloss: 0.149357\n",
      "[90]\tvalid_0's multi_logloss: 0.14848\n",
      "[91]\tvalid_0's multi_logloss: 0.147614\n",
      "[92]\tvalid_0's multi_logloss: 0.146995\n",
      "[93]\tvalid_0's multi_logloss: 0.1461\n",
      "[94]\tvalid_0's multi_logloss: 0.145223\n",
      "[95]\tvalid_0's multi_logloss: 0.144369\n",
      "[96]\tvalid_0's multi_logloss: 0.143217\n",
      "[97]\tvalid_0's multi_logloss: 0.142334\n",
      "[98]\tvalid_0's multi_logloss: 0.141853\n",
      "[99]\tvalid_0's multi_logloss: 0.14093\n",
      "[100]\tvalid_0's multi_logloss: 0.139957\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.139957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       339\n",
      "           1       0.92      0.93      0.92       311\n",
      "           2       0.95      0.94      0.95       302\n",
      "           3       0.97      0.99      0.98       327\n",
      "\n",
      "    accuracy                           0.96      1279\n",
      "   macro avg       0.96      0.96      0.96      1279\n",
      "weighted avg       0.96      0.96      0.96      1279\n",
      "\n",
      "[[328   7   2   2]\n",
      " [  2 289  13   7]\n",
      " [  1  16 284   1]\n",
      " [  0   2   0 325]]\n",
      "Accuracy: 95.86%\n"
     ]
    }
   ],
   "source": [
    "# 'learning_rate': 0.08\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 7,\n",
    "    'learning_rate': 0.08,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71c648be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2563\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[1]\tvalid_0's multi_logloss: 1.38322\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.37939\n",
      "[3]\tvalid_0's multi_logloss: 1.37559\n",
      "[4]\tvalid_0's multi_logloss: 1.3718\n",
      "[5]\tvalid_0's multi_logloss: 1.36805\n",
      "[6]\tvalid_0's multi_logloss: 1.36431\n",
      "[7]\tvalid_0's multi_logloss: 1.3606\n",
      "[8]\tvalid_0's multi_logloss: 1.35691\n",
      "[9]\tvalid_0's multi_logloss: 1.35324\n",
      "[10]\tvalid_0's multi_logloss: 1.34959\n",
      "[11]\tvalid_0's multi_logloss: 1.34597\n",
      "[12]\tvalid_0's multi_logloss: 1.34236\n",
      "[13]\tvalid_0's multi_logloss: 1.33878\n",
      "[14]\tvalid_0's multi_logloss: 1.33522\n",
      "[15]\tvalid_0's multi_logloss: 1.33167\n",
      "[16]\tvalid_0's multi_logloss: 1.32815\n",
      "[17]\tvalid_0's multi_logloss: 1.32464\n",
      "[18]\tvalid_0's multi_logloss: 1.32116\n",
      "[19]\tvalid_0's multi_logloss: 1.31769\n",
      "[20]\tvalid_0's multi_logloss: 1.31425\n",
      "[21]\tvalid_0's multi_logloss: 1.31081\n",
      "[22]\tvalid_0's multi_logloss: 1.30741\n",
      "[23]\tvalid_0's multi_logloss: 1.30402\n",
      "[24]\tvalid_0's multi_logloss: 1.30064\n",
      "[25]\tvalid_0's multi_logloss: 1.29729\n",
      "[26]\tvalid_0's multi_logloss: 1.29395\n",
      "[27]\tvalid_0's multi_logloss: 1.29064\n",
      "[28]\tvalid_0's multi_logloss: 1.28733\n",
      "[29]\tvalid_0's multi_logloss: 1.28405\n",
      "[30]\tvalid_0's multi_logloss: 1.28079\n",
      "[31]\tvalid_0's multi_logloss: 1.27754\n",
      "[32]\tvalid_0's multi_logloss: 1.27431\n",
      "[33]\tvalid_0's multi_logloss: 1.27109\n",
      "[34]\tvalid_0's multi_logloss: 1.2679\n",
      "[35]\tvalid_0's multi_logloss: 1.26472\n",
      "[36]\tvalid_0's multi_logloss: 1.26156\n",
      "[37]\tvalid_0's multi_logloss: 1.25842\n",
      "[38]\tvalid_0's multi_logloss: 1.25529\n",
      "[39]\tvalid_0's multi_logloss: 1.25217\n",
      "[40]\tvalid_0's multi_logloss: 1.24909\n",
      "[41]\tvalid_0's multi_logloss: 1.24601\n",
      "[42]\tvalid_0's multi_logloss: 1.24295\n",
      "[43]\tvalid_0's multi_logloss: 1.23991\n",
      "[44]\tvalid_0's multi_logloss: 1.23689\n",
      "[45]\tvalid_0's multi_logloss: 1.23387\n",
      "[46]\tvalid_0's multi_logloss: 1.23088\n",
      "[47]\tvalid_0's multi_logloss: 1.22789\n",
      "[48]\tvalid_0's multi_logloss: 1.22493\n",
      "[49]\tvalid_0's multi_logloss: 1.22199\n",
      "[50]\tvalid_0's multi_logloss: 1.21904\n",
      "[51]\tvalid_0's multi_logloss: 1.21612\n",
      "[52]\tvalid_0's multi_logloss: 1.21319\n",
      "[53]\tvalid_0's multi_logloss: 1.2103\n",
      "[54]\tvalid_0's multi_logloss: 1.20743\n",
      "[55]\tvalid_0's multi_logloss: 1.20455\n",
      "[56]\tvalid_0's multi_logloss: 1.2017\n",
      "[57]\tvalid_0's multi_logloss: 1.19885\n",
      "[58]\tvalid_0's multi_logloss: 1.19604\n",
      "[59]\tvalid_0's multi_logloss: 1.19322\n",
      "[60]\tvalid_0's multi_logloss: 1.19042\n",
      "[61]\tvalid_0's multi_logloss: 1.18764\n",
      "[62]\tvalid_0's multi_logloss: 1.18486\n",
      "[63]\tvalid_0's multi_logloss: 1.1821\n",
      "[64]\tvalid_0's multi_logloss: 1.17935\n",
      "[65]\tvalid_0's multi_logloss: 1.1766\n",
      "[66]\tvalid_0's multi_logloss: 1.17388\n",
      "[67]\tvalid_0's multi_logloss: 1.17117\n",
      "[68]\tvalid_0's multi_logloss: 1.16846\n",
      "[69]\tvalid_0's multi_logloss: 1.16579\n",
      "[70]\tvalid_0's multi_logloss: 1.1631\n",
      "[71]\tvalid_0's multi_logloss: 1.16045\n",
      "[72]\tvalid_0's multi_logloss: 1.15781\n",
      "[73]\tvalid_0's multi_logloss: 1.15516\n",
      "[74]\tvalid_0's multi_logloss: 1.15254\n",
      "[75]\tvalid_0's multi_logloss: 1.14992\n",
      "[76]\tvalid_0's multi_logloss: 1.14733\n",
      "[77]\tvalid_0's multi_logloss: 1.14474\n",
      "[78]\tvalid_0's multi_logloss: 1.14217\n",
      "[79]\tvalid_0's multi_logloss: 1.13962\n",
      "[80]\tvalid_0's multi_logloss: 1.13706\n",
      "[81]\tvalid_0's multi_logloss: 1.13452\n",
      "[82]\tvalid_0's multi_logloss: 1.13199\n",
      "[83]\tvalid_0's multi_logloss: 1.12948\n",
      "[84]\tvalid_0's multi_logloss: 1.12697\n",
      "[85]\tvalid_0's multi_logloss: 1.12449\n",
      "[86]\tvalid_0's multi_logloss: 1.12201\n",
      "[87]\tvalid_0's multi_logloss: 1.11953\n",
      "[88]\tvalid_0's multi_logloss: 1.11708\n",
      "[89]\tvalid_0's multi_logloss: 1.11462\n",
      "[90]\tvalid_0's multi_logloss: 1.1122\n",
      "[91]\tvalid_0's multi_logloss: 1.10976\n",
      "[92]\tvalid_0's multi_logloss: 1.10735\n",
      "[93]\tvalid_0's multi_logloss: 1.10495\n",
      "[94]\tvalid_0's multi_logloss: 1.10255\n",
      "[95]\tvalid_0's multi_logloss: 1.10014\n",
      "[96]\tvalid_0's multi_logloss: 1.09777\n",
      "[97]\tvalid_0's multi_logloss: 1.09537\n",
      "[98]\tvalid_0's multi_logloss: 1.09302\n",
      "[99]\tvalid_0's multi_logloss: 1.09065\n",
      "[100]\tvalid_0's multi_logloss: 1.08831\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 1.08831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       339\n",
      "           1       0.80      0.74      0.77       311\n",
      "           2       0.82      0.76      0.79       302\n",
      "           3       0.80      0.93      0.86       327\n",
      "\n",
      "    accuracy                           0.85      1279\n",
      "   macro avg       0.85      0.85      0.85      1279\n",
      "weighted avg       0.86      0.85      0.85      1279\n",
      "\n",
      "[[325   6   3   5]\n",
      " [  1 231  43  36]\n",
      " [  1  36 231  34]\n",
      " [  0  17   5 305]]\n",
      "Accuracy: 85.38%\n"
     ]
    }
   ],
   "source": [
    "# 'learning_rate': 0.002\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 7,\n",
    "    'learning_rate': 0.002,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6281b439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2563\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[1]\tvalid_0's multi_logloss: 1.37171\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.35672\n",
      "[3]\tvalid_0's multi_logloss: 1.34211\n",
      "[4]\tvalid_0's multi_logloss: 1.32781\n",
      "[5]\tvalid_0's multi_logloss: 1.31386\n",
      "[6]\tvalid_0's multi_logloss: 1.30015\n",
      "[7]\tvalid_0's multi_logloss: 1.2868\n",
      "[8]\tvalid_0's multi_logloss: 1.27375\n",
      "[9]\tvalid_0's multi_logloss: 1.26091\n",
      "[10]\tvalid_0's multi_logloss: 1.24838\n",
      "[11]\tvalid_0's multi_logloss: 1.23613\n",
      "[12]\tvalid_0's multi_logloss: 1.22416\n",
      "[13]\tvalid_0's multi_logloss: 1.21244\n",
      "[14]\tvalid_0's multi_logloss: 1.20086\n",
      "[15]\tvalid_0's multi_logloss: 1.18957\n",
      "[16]\tvalid_0's multi_logloss: 1.17847\n",
      "[17]\tvalid_0's multi_logloss: 1.16757\n",
      "[18]\tvalid_0's multi_logloss: 1.15691\n",
      "[19]\tvalid_0's multi_logloss: 1.14637\n",
      "[20]\tvalid_0's multi_logloss: 1.13609\n",
      "[21]\tvalid_0's multi_logloss: 1.12597\n",
      "[22]\tvalid_0's multi_logloss: 1.11606\n",
      "[23]\tvalid_0's multi_logloss: 1.10631\n",
      "[24]\tvalid_0's multi_logloss: 1.09676\n",
      "[25]\tvalid_0's multi_logloss: 1.08721\n",
      "[26]\tvalid_0's multi_logloss: 1.07796\n",
      "[27]\tvalid_0's multi_logloss: 1.06877\n",
      "[28]\tvalid_0's multi_logloss: 1.05956\n",
      "[29]\tvalid_0's multi_logloss: 1.05053\n",
      "[30]\tvalid_0's multi_logloss: 1.04177\n",
      "[31]\tvalid_0's multi_logloss: 1.0334\n",
      "[32]\tvalid_0's multi_logloss: 1.02498\n",
      "[33]\tvalid_0's multi_logloss: 1.01676\n",
      "[34]\tvalid_0's multi_logloss: 1.00881\n",
      "[35]\tvalid_0's multi_logloss: 1.00082\n",
      "[36]\tvalid_0's multi_logloss: 0.992776\n",
      "[37]\tvalid_0's multi_logloss: 0.985214\n",
      "[38]\tvalid_0's multi_logloss: 0.977775\n",
      "[39]\tvalid_0's multi_logloss: 0.970405\n",
      "[40]\tvalid_0's multi_logloss: 0.962918\n",
      "[41]\tvalid_0's multi_logloss: 0.955834\n",
      "[42]\tvalid_0's multi_logloss: 0.948855\n",
      "[43]\tvalid_0's multi_logloss: 0.941652\n",
      "[44]\tvalid_0's multi_logloss: 0.93489\n",
      "[45]\tvalid_0's multi_logloss: 0.928181\n",
      "[46]\tvalid_0's multi_logloss: 0.921293\n",
      "[47]\tvalid_0's multi_logloss: 0.914723\n",
      "[48]\tvalid_0's multi_logloss: 0.908356\n",
      "[49]\tvalid_0's multi_logloss: 0.901823\n",
      "[50]\tvalid_0's multi_logloss: 0.895488\n",
      "[51]\tvalid_0's multi_logloss: 0.889415\n",
      "[52]\tvalid_0's multi_logloss: 0.883006\n",
      "[53]\tvalid_0's multi_logloss: 0.877133\n",
      "[54]\tvalid_0's multi_logloss: 0.871325\n",
      "[55]\tvalid_0's multi_logloss: 0.865316\n",
      "[56]\tvalid_0's multi_logloss: 0.859345\n",
      "[57]\tvalid_0's multi_logloss: 0.853468\n",
      "[58]\tvalid_0's multi_logloss: 0.847757\n",
      "[59]\tvalid_0's multi_logloss: 0.842014\n",
      "[60]\tvalid_0's multi_logloss: 0.83647\n",
      "[61]\tvalid_0's multi_logloss: 0.830851\n",
      "[62]\tvalid_0's multi_logloss: 0.825485\n",
      "[63]\tvalid_0's multi_logloss: 0.82006\n",
      "[64]\tvalid_0's multi_logloss: 0.814586\n",
      "[65]\tvalid_0's multi_logloss: 0.809339\n",
      "[66]\tvalid_0's multi_logloss: 0.804261\n",
      "[67]\tvalid_0's multi_logloss: 0.79901\n",
      "[68]\tvalid_0's multi_logloss: 0.793985\n",
      "[69]\tvalid_0's multi_logloss: 0.789053\n",
      "[70]\tvalid_0's multi_logloss: 0.784114\n",
      "[71]\tvalid_0's multi_logloss: 0.778964\n",
      "[72]\tvalid_0's multi_logloss: 0.774056\n",
      "[73]\tvalid_0's multi_logloss: 0.769361\n",
      "[74]\tvalid_0's multi_logloss: 0.76443\n",
      "[75]\tvalid_0's multi_logloss: 0.759719\n",
      "[76]\tvalid_0's multi_logloss: 0.755124\n",
      "[77]\tvalid_0's multi_logloss: 0.750464\n",
      "[78]\tvalid_0's multi_logloss: 0.745998\n",
      "[79]\tvalid_0's multi_logloss: 0.741505\n",
      "[80]\tvalid_0's multi_logloss: 0.736977\n",
      "[81]\tvalid_0's multi_logloss: 0.732714\n",
      "[82]\tvalid_0's multi_logloss: 0.728258\n",
      "[83]\tvalid_0's multi_logloss: 0.723888\n",
      "[84]\tvalid_0's multi_logloss: 0.719479\n",
      "[85]\tvalid_0's multi_logloss: 0.715266\n",
      "[86]\tvalid_0's multi_logloss: 0.711074\n",
      "[87]\tvalid_0's multi_logloss: 0.706849\n",
      "[88]\tvalid_0's multi_logloss: 0.702662\n",
      "[89]\tvalid_0's multi_logloss: 0.698605\n",
      "[90]\tvalid_0's multi_logloss: 0.694465\n",
      "[91]\tvalid_0's multi_logloss: 0.690478\n",
      "[92]\tvalid_0's multi_logloss: 0.686515\n",
      "[93]\tvalid_0's multi_logloss: 0.682487\n",
      "[94]\tvalid_0's multi_logloss: 0.678582\n",
      "[95]\tvalid_0's multi_logloss: 0.67482\n",
      "[96]\tvalid_0's multi_logloss: 0.671028\n",
      "[97]\tvalid_0's multi_logloss: 0.667158\n",
      "[98]\tvalid_0's multi_logloss: 0.663266\n",
      "[99]\tvalid_0's multi_logloss: 0.659522\n",
      "[100]\tvalid_0's multi_logloss: 0.655857\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.655857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       339\n",
      "           1       0.78      0.77      0.78       311\n",
      "           2       0.85      0.74      0.79       302\n",
      "           3       0.82      0.95      0.88       327\n",
      "\n",
      "    accuracy                           0.86      1279\n",
      "   macro avg       0.86      0.86      0.86      1279\n",
      "weighted avg       0.86      0.86      0.86      1279\n",
      "\n",
      "[[327   5   3   4]\n",
      " [  2 240  36  33]\n",
      " [  2  47 224  29]\n",
      " [  0  14   2 311]]\n",
      "Accuracy: 86.16%\n"
     ]
    }
   ],
   "source": [
    "# 'learning_rate': 0.008\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 7,\n",
    "    'learning_rate': 0.008,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61114b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000968 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2563\n",
      "[LightGBM] [Info] Number of data points in the train set: 3837, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.406566\n",
      "[LightGBM] [Info] Start training from score -1.377214\n",
      "[LightGBM] [Info] Start training from score -1.367959\n",
      "[LightGBM] [Info] Start training from score -1.393881\n",
      "[1]\tvalid_0's multi_logloss: 1.3698\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.35299\n",
      "[3]\tvalid_0's multi_logloss: 1.33666\n",
      "[4]\tvalid_0's multi_logloss: 1.32072\n",
      "[5]\tvalid_0's multi_logloss: 1.30521\n",
      "[6]\tvalid_0's multi_logloss: 1.29001\n",
      "[7]\tvalid_0's multi_logloss: 1.27525\n",
      "[8]\tvalid_0's multi_logloss: 1.26081\n",
      "[9]\tvalid_0's multi_logloss: 1.24673\n",
      "[10]\tvalid_0's multi_logloss: 1.233\n",
      "[11]\tvalid_0's multi_logloss: 1.21959\n",
      "[12]\tvalid_0's multi_logloss: 1.20651\n",
      "[13]\tvalid_0's multi_logloss: 1.1936\n",
      "[14]\tvalid_0's multi_logloss: 1.18109\n",
      "[15]\tvalid_0's multi_logloss: 1.16871\n",
      "[16]\tvalid_0's multi_logloss: 1.15669\n",
      "[17]\tvalid_0's multi_logloss: 1.14491\n",
      "[18]\tvalid_0's multi_logloss: 1.13334\n",
      "[19]\tvalid_0's multi_logloss: 1.12205\n",
      "[20]\tvalid_0's multi_logloss: 1.11096\n",
      "[21]\tvalid_0's multi_logloss: 1.10012\n",
      "[22]\tvalid_0's multi_logloss: 1.08934\n",
      "[23]\tvalid_0's multi_logloss: 1.0789\n",
      "[24]\tvalid_0's multi_logloss: 1.06855\n",
      "[25]\tvalid_0's multi_logloss: 1.05818\n",
      "[26]\tvalid_0's multi_logloss: 1.04818\n",
      "[27]\tvalid_0's multi_logloss: 1.03862\n",
      "[28]\tvalid_0's multi_logloss: 1.02896\n",
      "[29]\tvalid_0's multi_logloss: 1.01956\n",
      "[30]\tvalid_0's multi_logloss: 1.0104\n",
      "[31]\tvalid_0's multi_logloss: 1.00143\n",
      "[32]\tvalid_0's multi_logloss: 0.992762\n",
      "[33]\tvalid_0's multi_logloss: 0.98423\n",
      "[34]\tvalid_0's multi_logloss: 0.9756\n",
      "[35]\tvalid_0's multi_logloss: 0.967417\n",
      "[36]\tvalid_0's multi_logloss: 0.95931\n",
      "[37]\tvalid_0's multi_logloss: 0.951407\n",
      "[38]\tvalid_0's multi_logloss: 0.943326\n",
      "[39]\tvalid_0's multi_logloss: 0.935515\n",
      "[40]\tvalid_0's multi_logloss: 0.928006\n",
      "[41]\tvalid_0's multi_logloss: 0.920322\n",
      "[42]\tvalid_0's multi_logloss: 0.913029\n",
      "[43]\tvalid_0's multi_logloss: 0.905728\n",
      "[44]\tvalid_0's multi_logloss: 0.898427\n",
      "[45]\tvalid_0's multi_logloss: 0.891542\n",
      "[46]\tvalid_0's multi_logloss: 0.884774\n",
      "[47]\tvalid_0's multi_logloss: 0.87771\n",
      "[48]\tvalid_0's multi_logloss: 0.871059\n",
      "[49]\tvalid_0's multi_logloss: 0.864344\n",
      "[50]\tvalid_0's multi_logloss: 0.857641\n",
      "[51]\tvalid_0's multi_logloss: 0.851183\n",
      "[52]\tvalid_0's multi_logloss: 0.844664\n",
      "[53]\tvalid_0's multi_logloss: 0.838245\n",
      "[54]\tvalid_0's multi_logloss: 0.832041\n",
      "[55]\tvalid_0's multi_logloss: 0.825854\n",
      "[56]\tvalid_0's multi_logloss: 0.81986\n",
      "[57]\tvalid_0's multi_logloss: 0.813695\n",
      "[58]\tvalid_0's multi_logloss: 0.807639\n",
      "[59]\tvalid_0's multi_logloss: 0.80168\n",
      "[60]\tvalid_0's multi_logloss: 0.795838\n",
      "[61]\tvalid_0's multi_logloss: 0.790243\n",
      "[62]\tvalid_0's multi_logloss: 0.784586\n",
      "[63]\tvalid_0's multi_logloss: 0.77918\n",
      "[64]\tvalid_0's multi_logloss: 0.773908\n",
      "[65]\tvalid_0's multi_logloss: 0.768275\n",
      "[66]\tvalid_0's multi_logloss: 0.762932\n",
      "[67]\tvalid_0's multi_logloss: 0.757714\n",
      "[68]\tvalid_0's multi_logloss: 0.752487\n",
      "[69]\tvalid_0's multi_logloss: 0.747433\n",
      "[70]\tvalid_0's multi_logloss: 0.742619\n",
      "[71]\tvalid_0's multi_logloss: 0.737494\n",
      "[72]\tvalid_0's multi_logloss: 0.732478\n",
      "[73]\tvalid_0's multi_logloss: 0.727447\n",
      "[74]\tvalid_0's multi_logloss: 0.722512\n",
      "[75]\tvalid_0's multi_logloss: 0.717655\n",
      "[76]\tvalid_0's multi_logloss: 0.712792\n",
      "[77]\tvalid_0's multi_logloss: 0.708055\n",
      "[78]\tvalid_0's multi_logloss: 0.703457\n",
      "[79]\tvalid_0's multi_logloss: 0.698819\n",
      "[80]\tvalid_0's multi_logloss: 0.694197\n",
      "[81]\tvalid_0's multi_logloss: 0.689757\n",
      "[82]\tvalid_0's multi_logloss: 0.68519\n",
      "[83]\tvalid_0's multi_logloss: 0.680789\n",
      "[84]\tvalid_0's multi_logloss: 0.676242\n",
      "[85]\tvalid_0's multi_logloss: 0.671977\n",
      "[86]\tvalid_0's multi_logloss: 0.667544\n",
      "[87]\tvalid_0's multi_logloss: 0.663451\n",
      "[88]\tvalid_0's multi_logloss: 0.659129\n",
      "[89]\tvalid_0's multi_logloss: 0.655001\n",
      "[90]\tvalid_0's multi_logloss: 0.650898\n",
      "[91]\tvalid_0's multi_logloss: 0.647067\n",
      "[92]\tvalid_0's multi_logloss: 0.643118\n",
      "[93]\tvalid_0's multi_logloss: 0.639224\n",
      "[94]\tvalid_0's multi_logloss: 0.635201\n",
      "[95]\tvalid_0's multi_logloss: 0.631397\n",
      "[96]\tvalid_0's multi_logloss: 0.627505\n",
      "[97]\tvalid_0's multi_logloss: 0.62379\n",
      "[98]\tvalid_0's multi_logloss: 0.620169\n",
      "[99]\tvalid_0's multi_logloss: 0.616574\n",
      "[100]\tvalid_0's multi_logloss: 0.613003\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.613003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       339\n",
      "           1       0.80      0.79      0.80       311\n",
      "           2       0.86      0.75      0.80       302\n",
      "           3       0.83      0.95      0.89       327\n",
      "\n",
      "    accuracy                           0.87      1279\n",
      "   macro avg       0.87      0.87      0.87      1279\n",
      "weighted avg       0.87      0.87      0.87      1279\n",
      "\n",
      "[[327   6   3   3]\n",
      " [  1 247  33  30]\n",
      " [  2  43 228  29]\n",
      " [  0  13   2 312]]\n",
      "Accuracy: 87.10%\n"
     ]
    }
   ],
   "source": [
    "# 'learning_rate': 0.009\n",
    "\n",
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 7,\n",
    "    'learning_rate': 0.009,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "print(len(X_val))\n",
    "print(len(Y_val))\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(Xtrain, Ytrain)\n",
    "lgb_eval = lgb.Dataset(X_val, Y_val, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Ypred = model.predict(X_val)\n",
    "\n",
    "Ypred = argmax(Ypred, axis=1)\n",
    "cr = classification_report(Y_val, Ypred)\n",
    "cm = confusion_matrix(Y_val, Ypred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, Ypred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9862c01a",
   "metadata": {},
   "source": [
    "# We see that learning rate = 0.08 gives best accuracy and Number of leaves = 7 give best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e989a09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Feature importance'}, xlabel='Feature importance', ylabel='Features'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm8AAAHFCAYAAACkWR6dAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABwD0lEQVR4nO3deVhV1f4/8PdhOgiHQRQEvcTkwCAoCZhKAqaCmEnmkKlodLsWTogWeg1DEiH0BmWK1wa9kpV19auVXAwHKCtzRFTIciDMQEwDVK54Dmf9/vDHvh45KCByztH363nOA3vttdf67L1QPqw9yYQQAkRERERkEIx0HQARERERNR+TNyIiIiIDwuSNiIiIyIAweSMiIiIyIEzeiIiIiAwIkzciIiIiA8LkjYiIiMiAMHkjIiIiMiBM3oiIiIgMCJM3Imo369evh0wm0/qZP3/+femzuLgYSUlJKC0tvS/t34vS0lLIZDKsX79e16G0Wk5ODpKSknQdBtFDxUTXARDRw2fdunXw9PTUKOvatet96au4uBhLlixBaGgoXF1d70sfreXk5IQffvgBHh4eug6l1XJycrBq1SomcETtiMkbEbW73r17IyAgQNdh3BOlUgmZTAYTk9b/NyqXy/HYY4+1YVTtp7a2FhYWFroOg+ihxNOmRKR3Nm3ahAEDBsDS0hIKhQLh4eE4cuSIRp2DBw/i2WefhaurKzp06ABXV1dMnDgRv/76q1Rn/fr1GDduHAAgLCxMOkXbcJrS1dUV06ZNa9R/aGgoQkNDpeX8/HzIZDJkZ2dj3rx56NatG+RyOU6dOgUA2LlzJ5544glYW1vDwsICgwYNwq5du+66n9pOmyYlJUEmk6GoqAjjxo2DjY0N7OzsEB8fD5VKhZMnTyIiIgJWVlZwdXVFenq6RpsNsX700UeIj4+Ho6MjOnTogJCQkEbHEAC++OILDBgwABYWFrCyssKwYcPwww8/aNRpiOnw4cMYO3YsOnbsCA8PD0ybNg2rVq0CAI1T4A2nqFetWoXBgwfDwcEBlpaW8PX1RXp6OpRKZaPj3bt3bxw4cACPP/44LCws4O7ujrS0NKjVao26VVVVmDdvHtzd3SGXy+Hg4IDIyEj89NNPUp0bN25g6dKl8PT0hFwuh729PZ5//nlcvHjxrmNCZAiYvBFRu6uvr4dKpdL4NFi2bBkmTpwIb29vfPbZZ8jOzsaVK1fw+OOPo7i4WKpXWlqKXr16ITMzEzt27MCbb76J8vJyBAYG4o8//gAAjBw5EsuWLQNwM5H44Ycf8MMPP2DkyJGtinvhwoUoKyvDmjVr8OWXX8LBwQEfffQRhg8fDmtra/zrX//CZ599Bjs7O4SHhzcrgWvK+PHj0adPH2zevBkvvvgiMjIyMHfuXERFRWHkyJH4v//7PwwZMgQJCQnYsmVLo+3//ve/48yZM3j//ffx/vvv4/fff0doaCjOnDkj1fn4448xevRoWFtb45NPPsEHH3yAP//8E6Ghodi7d2+jNseMGYPu3bvj888/x5o1a5CYmIixY8cCgHRsf/jhBzg5OQEATp8+jeeeew7Z2dn46quv8MILL2D58uWYPn16o7YrKiowadIkTJ48GV988QVGjBiBhQsX4qOPPpLqXLlyBcHBwfjnP/+J559/Hl9++SXWrFmDnj17ory8HACgVqsxevRopKWl4bnnnsP27duRlpaGvLw8hIaG4r///W+rx4RIbwgionaybt06AUDrR6lUirKyMmFiYiJmzZqlsd2VK1eEo6OjGD9+fJNtq1QqcfXqVWFpaSnefvttqfzzzz8XAMSePXsabePi4iKmTp3aqDwkJESEhIRIy3v27BEAxODBgzXqXbt2TdjZ2YlRo0ZplNfX14s+ffqIoKCgOxwNIc6ePSsAiHXr1kllr7/+ugAg/vGPf2jU7du3rwAgtmzZIpUplUphb28vxowZ0yjWRx99VKjVaqm8tLRUmJqair/+9a9SjF27dhW+vr6ivr5eqnflyhXh4OAgBg4c2CimxYsXN9qHGTNmiOb8KqmvrxdKpVJs2LBBGBsbi8uXL0vrQkJCBADx448/amzj7e0twsPDpeXk5GQBQOTl5TXZzyeffCIAiM2bN2uUHzhwQAAQq1evvmusRPqOM29E1O42bNiAAwcOaHxMTEywY8cOqFQqREdHa8zKmZubIyQkBPn5+VIbV69eRUJCArp37w4TExOYmJhAoVDg2rVrKCkpuS9xP/PMMxrL33//PS5fvoypU6dqxKtWqxEREYEDBw7g2rVrrerrySef1Fj28vKCTCbDiBEjpDITExN0795d41Rxg+eeew4ymUxadnFxwcCBA7Fnzx4AwMmTJ/H7779jypQpMDL6368ChUKBZ555Bvv27UNtbe0d9/9ujhw5gqeeegqdOnWCsbExTE1NER0djfr6evz8888adR0dHREUFKRR5ufnp7Fv//nPf9CzZ08MHTq0yT6/+uor2NraYtSoURpj0rdvXzg6Omr8DBEZKt6wQETtzsvLS+sNCxcuXAAABAYGat3u1iTjueeew65du5CYmIjAwEBYW1tDJpMhMjLyvp0aazgdeHu8DacOtbl8+TIsLS1b3JednZ3GspmZGSwsLGBubt6ovKamptH2jo6OWsuOHj0KALh06RKAxvsE3LzzV61W488//9S4KUFb3aaUlZXh8ccfR69evfD222/D1dUV5ubm2L9/P2bMmNFojDp16tSoDblcrlHv4sWLeOSRR+7Y74ULF1BVVQUzMzOt6xtOqRMZMiZvRKQ3OnfuDAD497//DRcXlybrVVdX46uvvsLrr7+OBQsWSOV1dXW4fPlys/szNzdHXV1do/I//vhDiuVWt85k3RrvypUrm7xrtEuXLs2Opy1VVFRoLWtIkhq+Nlwrdqvff/8dRkZG6Nixo0b57ft/J1u3bsW1a9ewZcsWjbEsLCxsdhu3s7e3x2+//XbHOp07d0anTp2Qm5urdb2VlVWr+yfSF0zeiEhvhIeHw8TEBKdPn77jKTqZTAYhBORyuUb5+++/j/r6eo2yhjraZuNcXV1RVFSkUfbzzz/j5MmTWpO32w0aNAi2trYoLi7GzJkz71q/PX3yySeIj4+XEq5ff/0V33//PaKjowEAvXr1Qrdu3fDxxx9j/vz5Ur1r165h8+bN0h2od3Pr8e3QoYNU3tDerWMkhMB7773X6n0aMWIEFi9ejN27d2PIkCFa6zz55JP49NNPUV9fj/79+7e6LyJ9xuSNiPSGq6srkpOTsWjRIpw5cwYRERHo2LEjLly4gP3798PS0hJLliyBtbU1Bg8ejOXLl6Nz585wdXVFQUEBPvjgA9ja2mq02bt3bwDA2rVrYWVlBXNzc7i5uaFTp06YMmUKJk+ejNjYWDzzzDP49ddfkZ6eDnt7+2bFq1AosHLlSkydOhWXL1/G2LFj4eDggIsXL+Lo0aO4ePEisrKy2vowNUtlZSWefvppvPjii6iursbrr78Oc3NzLFy4EMDNU9Dp6emYNGkSnnzySUyfPh11dXVYvnw5qqqqkJaW1qx+fH19AQBvvvkmRowYAWNjY/j5+WHYsGEwMzPDxIkT8eqrr+L69evIysrCn3/+2ep9iouLw6ZNmzB69GgsWLAAQUFB+O9//4uCggI8+eSTCAsLw7PPPouNGzciMjISc+bMQVBQEExNTfHbb79hz549GD16NJ5++ulWx0CkF3R9xwQRPTwa7jY9cODAHett3bpVhIWFCWtrayGXy4WLi4sYO3as2Llzp1Tnt99+E88884zo2LGjsLKyEhEREeL48eNa7yDNzMwUbm5uwtjYWOPuTrVaLdLT04W7u7swNzcXAQEBYvfu3U3ebfr5559rjbegoECMHDlS2NnZCVNTU9GtWzcxcuTIJus3uNPdphcvXtSoO3XqVGFpadmojZCQEOHj49Mo1uzsbDF79mxhb28v5HK5ePzxx8XBgwcbbb9161bRv39/YW5uLiwtLcUTTzwhvvvuO406TcUkhBB1dXXir3/9q7C3txcymUwAEGfPnhVCCPHll1+KPn36CHNzc9GtWzfxyiuviP/85z+N7v69fR9u3WcXFxeNsj///FPMmTNHPPLII8LU1FQ4ODiIkSNHip9++kmqo1QqxYoVK6S+FQqF8PT0FNOnTxe//PJLo36IDI1MCCF0ljkSEVGbys/PR1hYGD7//PM73khBRIaLjwohIiIiMiBM3oiIiIgMCE+bEhERERkQzrwRERERGRAmb0REREQGhMkbERERkQHhQ3ofMGq1Gr///jusrKxa9CobIiIi0h0hBK5cuYKuXbtqvMdZGyZvD5jff/8dzs7Oug6DiIiIWuHcuXP4y1/+csc6TN4eMA0vXT579izs7Ox0HA1po1Qq8fXXX2P48OEwNTXVdTikBcdIv3F89B/HqOVqamrg7Ows/R6/EyZvD5iGU6VWVlawtrbWcTSkjVKphIWFBaytrfmfmp7iGOk3jo/+4xi1XnMueeINC0REREQGhMkbERERkQFh8kZERERkQJi8ERERERkQJm9EREREBoTJGxEREZEBYfJGREREZECYvBEREREZECZvRERERAaEyRsRERGRAWHyRkRERGRAmLwRERERGRAmb0REREQGhMkbERERkQFh8kZERERkQJi8ERERERkQJm9EREREBoTJGxEREZEBYfJGREREZECYvBEREREZECZvRERERAaEyRsRERGRAWHyRkRERGRAmLwRERERGRAmb0REREQGRCaEELoOgtpOTU0NbGxs4DFvE1QmlroOh7SQGwukB9Xj1f3GqKuX6Toc0oJjpN84PvpPH8aoNG2kTvptrYbf39XV1bC2tr5jXc68ERERERkQJm9EREREBoTJGxERET2wVCoVXnvtNbi5uaFDhw5wd3dHcnIy1Gq1Rr2SkhI89dRTsLGxgZWVFR577DGUlZVJ69euXYvQ0FBYW1tDJpOhqqqqnffkfx6K5C0pKQl9+/bVdRhERETUzt58802sWbMG7777LkpKSpCeno7ly5dj5cqVUp3Tp08jODgYnp6eyM/Px9GjR5GYmAhzc3OpTm1tLSIiIvD3v/9dF7uhwUTXATRHRUUFUlJSsH37dpw/fx4ODg7o27cv4uLi8MQTT+g6vDYTGhqKgoKCRuWRkZHYvn27DiIiIiIybD/88ANGjx6NkSNv3sDg6uqKTz75BAcPHpTqLFq0CJGRkUhPT5fK3N3dNdqJi4sDAOTn59/3mO9G72feSktL0a9fP+zevRvp6ek4duwYcnNzERYWhhkzZug6vDa1ZcsWlJeXS5/jx4/D2NgY48aN03VoREREBik4OBi7du3Czz//DAA4evQo9u7di8jISACAWq3G9u3b0bNnT4SHh8PBwQH9+/fH1q1bdRj1nel98hYbGwuZTIb9+/dj7Nix6NmzJ3x8fBAfH499+/YBAMrKyjB69GgoFApYW1tj/PjxuHDhQpNthoaGShl0g6ioKEybNk1adnV1xdKlSxEdHQ2FQgEXFxds27YNFy9elPry9fXVyNzXr18PW1tb7NixA15eXlAoFIiIiEB5eXmz9tXOzg6Ojo7SJy8vDxYWFkzeiIiIWikhIQETJ06Ep6cnTE1N4e/vj7i4OEycOBEAUFlZiatXryItLQ0RERH4+uuv8fTTT2PMmDFaz4bpA70+bXr58mXk5uYiJSUFlpaNn1lma2sLIQSioqJgaWmJgoICqFQqxMbGYsKECfc8tZmRkYFly5YhMTERGRkZmDJlCgYNGoSYmBgsX74cCQkJiI6OxokTJyCT3XyOTW1tLVasWIHs7GwYGRlh8uTJmD9/PjZu3Nji/j/44AM8++yzWve9QV1dHerq6qTlmpoaAIDcSMDYmI/w00dyI6HxlfQPx0i/cXz0nz6MkVKpBABs2rQJH330ETZs2ABvb28cPXoU8+fPh4ODA6Kjo6XfoaNGjcLMmTMBAD4+Pti7dy9Wr16NgQMHarSrUqmk9hv6aMt4m0Ovk7dTp05BCAFPT88m6+zcuRNFRUU4e/YsnJ2dAQDZ2dnw8fHBgQMHEBgY2Or+IyMjMX36dADA4sWLkZWVhcDAQGkmLCEhAQMGDMCFCxfg6OgI4ObBX7NmDTw8PAAAM2fORHJycov73r9/P44fP44PPvjgjvVSU1OxZMmSRuWv+athYVHf4n6p/bwRoL57JdIpjpF+4/joP12OUU5ODoCb16o988wzsLKywrlz52BnZ4eIiAi8/vrr6Ny5M5RKJYyNjWFsbCxtAwBmZmYoKirSKAOAY8eOAQC+/vprKBSKNou3tra22XX1OnlrePlDw6yWNiUlJXB2dpYSNwDw9vaGra0tSkpK7il58/Pzk77v0qULAMDX17dRWWVlpZS8WVhYSIkbADg5OaGysrLFfX/wwQfo3bs3goKC7lhv4cKFiI+Pl5Zramrg7OyMpUeMoDI1bnG/dP/JjQTeCFAj8aAR6tR8Orw+4hjpN46P/tOHMTqeFA7gZi7h6+srXeMG3EzA9u/fL5U15Aq31vnwww/Rp08fjTIA0tmw4cOHw9bWts3ibThz1hx6nbz16NEDMpkMJSUliIqK0lpHCKE1uWuqHACMjIxw+1vBtE1XmpqaSt83tKWt7NZnxdy6vqFOS99AVltbi08//bRZM3ZyuRxyubxReZ1aBhVfG6PX6tQyvtpHz3GM9BvHR//pcowafh+PGjUKaWlpcHNzg4+PD44cOYK3334bMTExUp1XX30VEyZMQGhoKMLCwpCbm4vt27cjPz9fqlNRUYGKigqUlpYCAH766SdYWVnhkUcegZ2dXZvF2xx6fcOCnZ0dwsPDsWrVKly7dq3R+qqqKnh7e6OsrAznzp2TyouLi1FdXQ0vLy+t7drb22vcRFBfX4/jx4+3/Q600meffYa6ujpMnjxZ16EQEREZtJUrV2Ls2LGIjY2Fl5cX5s+fj+nTp+ONN96Q6jz99NNYs2YN0tPT4evri/fffx+bN29GcHCwVGfNmjXw9/fHiy++CAAYPHgw/P398cUXX7T7Pun1zBsA6WLBoKAgJCcnw8/PDyqVCnl5ecjKykJxcTH8/PwwadIkZGZmSjcshISEICAgQGubQ4YMQXx8PLZv3w4PDw9kZGTo9EnJt/vggw8QFRWFTp066ToUIiIig2ZlZYXMzExkZmbesV5MTAxiYmKaXJ+UlISkpKS2Da6V9HrmDQDc3Nxw+PBhhIWFYd68eejduzeGDRuGXbt2ISsrCzKZDFu3bkXHjh0xePBgDB06FO7u7ti0aVOTbcbExGDq1KmIjo5GSEgI3NzcEBYW1o571bSff/4Ze/fuxQsvvKDrUIiIiEgPyURLL8givVZTUwMbGxt4zNsElUnTjxgh3ZEbC6QH1ePV/ca8XkdPcYz0G8dH/+nDGJWmjdRJv63V8Pu7uroa1tbWd6yr9zNvRERERPQ/TN7akUKhaPLz7bff6jo8IiIiMgA8bdqOTp061eS6bt26oUOHDvfcR8O06x9//MEbHvSUUqlETk4OIiMjW3RrOLUfjpF+4/joP45Ry7XktKne3236IOnevbuuQyAiIiIDx9OmRERERAaEyRsRERGRAWHyRkRERGRAmLwRERERGRAmb0REREQGhMkbERERkQFh8kZERERkQJi8ERERERkQJm9EREREBoTJGxEREZEBYfJGREREZECYvBEREREZECZvRERERAaEyRsRERGRAWHyRkRERGRAmLwRERERGRAmb0REREQGxETXAdD90T91F1QmlroOg7SQGwukBwG9k3agrl6m63BIC45R00rTRuo6BKKHHmfeiIiIiAwIkzciIiIiA8LkjYiIWiQpKQkymUzj4+joqLHe09MTlpaW6NixI4YOHYoff/xRa1tCCIwYMQIymQxbt25tpz0gMmwPRfKWlJSEvn376joMIqIHho+PD8rLy6XPsWPHpHU9e/bEu+++i2PHjmHv3r1wdXXF8OHDcfHixUbtZGZmQibjdYVELWEQyVtFRQVmzZoFd3d3yOVyODs7Y9SoUdi1a5euQ2tTW7ZsQUBAAGxtbWFpaYm+ffsiOztb12ERETViYmICR0dH6WNvby+te+655zB06FC4u7vDx8cHb731FmpqalBUVKTRxtGjR/HWW2/hww8/bO/wiQya3t9tWlpaikGDBsHW1hbp6enw8/ODUqnEjh07MGPGDPz000+6DrHN2NnZYdGiRfD09ISZmRm++uorPP/883BwcEB4eLiuwyMikvzyyy/o2rUr5HI5+vfvj2XLlsHd3b1RvRs3bmDt2rWwsbFBnz59pPLa2lpMnDgR7777rsYpVyK6O72feYuNjYVMJsP+/fsxduxY9OzZEz4+PoiPj8e+ffsAAGVlZRg9ejQUCgWsra0xfvx4XLhwock2Q0NDERcXp1EWFRWFadOmScuurq5YunQpoqOjoVAo4OLigm3btuHixYtSX76+vjh48KC0zfr162Fra4sdO3bAy8sLCoUCERERKC8vb9a+hoaG4umnn4aXlxc8PDwwZ84c+Pn5Ye/evc0/YERE91n//v2xYcMG7NixA++99x4qKiowcOBAXLp0Sarz1VdfQaFQwNzcHBkZGcjLy0Pnzp2l9XPnzsXAgQMxevRoXewCkUHT65m3y5cvIzc3FykpKbC0bPzMMltbWwghEBUVBUtLSxQUFEClUiE2NhYTJkxAfn7+PfWfkZGBZcuWITExERkZGZgyZQoGDRqEmJgYLF++HAkJCYiOjsaJEyekazZqa2uxYsUKZGdnw8jICJMnT8b8+fOxcePGFvUthMDu3btx8uRJvPnmm03Wq6urQ11dnbRcU1MDAJAbCRgbi1bsNd1vciOh8ZX0D8eoaUqlEkOHDpWWPT09ERAQAE9PT3z44YfSH8bBwcE4cOAALl26hA8++ADjx4/H3r174eDggC+//BK7d+/G/v37oVQqpbZUKpXG8p1iuPUr6R+OUcu15FjpdfJ26tQpCCHg6enZZJ2dO3eiqKgIZ8+ehbOzMwAgOzsbPj4+OHDgAAIDA1vdf2RkJKZPnw4AWLx4MbKyshAYGIhx48YBABISEjBgwABcuHBBmvZXKpVYs2YNPDw8AAAzZ85EcnJys/usrq5Gt27dUFdXB2NjY6xevRrDhg1rsn5qaiqWLFnSqPw1fzUsLOqb3S+1vzcC1LoOge6CY9RYTk6O1nJHR0fs3r0bPXv2bLQuKioKO3bswIIFCzB27FisW7cOp0+f1piJA4AJEybAy8sLKSkpzYolLy+v5TtA7Ypj1Hy1tbXNrqvXyZsQN//qvdOdSCUlJXB2dpYSNwDw9vaGra0tSkpK7il58/Pzk77v0qULAMDX17dRWWVlpZS8WVhYSIkbADg5OaGysrLZfVpZWaGwsBBXr17Frl27EB8fD3d3d4SGhmqtv3DhQsTHx0vLNTU1cHZ2xtIjRlCZGje7X2o/ciOBNwLUSDxohDo177LTRxyjph1Panz9bV1dHWbMmIHRo0cjMjJS63YWFhZwdXVFZGQkHn30Ufzxxx8a6x999FGsWLECI0eOhJub2x1jUCqVyMvLw7Bhw2Bqatr6naH7hmPUcg1nzppDr5O3Hj16QCaToaSkBFFRUVrrCCG0JndNlQOAkZGRlBg20DZdeesPXENb2srUarXWbRrq3N7XnRgZGaF79+4AgL59+6KkpASpqalNJm9yuRxyubxReZ1aBhVf66PX6tQyvnpJz3GMGjM1NcX8+fMxatQoPPLII6isrMTSpUtRU1ODmJgY3LhxAykpKXjqqafg5OSES5cuYfXq1fjtt9/w7LPPwtTUtNEf3A3c3Ny0ztzdKRYmBvqNY9R8LTlOen3Dgp2dHcLDw7Fq1Spcu3at0fqqqip4e3ujrKwM586dk8qLi4tRXV0NLy8vre3a29tr3ERQX1+P48ePt/0OtAEhhMY1bUREuvbbb79h4sSJ6NWrF8aMGQMzMzPs27cPLi4uMDY2xk8//YRnnnkGPXv2xJNPPomLFy/i22+/hY+Pj65DJ3og6PXMGwCsXr0aAwcORFBQEJKTk+Hn5weVSoW8vDxkZWWhuLgYfn5+mDRpEjIzM6UbFkJCQhAQEKC1zSFDhiA+Ph7bt2+Hh4cHMjIyUFVV1b47pkVqaioCAgLg4eGBGzduICcnBxs2bEBWVpauQyMiknz66adNrjM3N8eWLVta3GZLzlAQPez0Pnlzc3PD4cOHkZKSgnnz5qG8vBz29vbo168fsrKypFeqzJo1C4MHD4aRkREiIiKwcuXKJtuMiYnB0aNHER0dDRMTE8ydOxdhYWHtuFfaXbt2DbGxsfjtt9/QoUMHeHp64qOPPsKECRN0HRoRERHpCZngnzsPlJqaGtjY2MBj3iaoTBo/XoV0T24skB5Uj1f3G/N6Kj3FMWpaadpIXYcApVKJnJwcREZG8noqPcUxarmG39/V1dWwtra+Y129vuaNiIiIiDQxeWtHCoWiyc+3336r6/CIiIjIAOj9NW8PksLCwibXdevWrU37+nHhE+jUqVObtklto+F0wvGkcJ5O0FMcIyLSZ0ze2lHD89uIiIiIWounTYmIiIgMCJM3IiIiIgPC5I2IiIjIgDB5IyIiIjIgTN6IiIiIDAiTNyIiIiIDwuSNiIiIyIAweSMiIiIyIEzeiIiIiAwIkzciIiIiA8LkjYiIiMiAMHkjIiIiMiBM3oiIiIgMCJM3IiIiIgPC5I2IiIjIgDB5IyIiIjIgTN6IiIiIDIiJrgOg+6N/6i6oTCx1HQZpITcWSA8CeiftQF29TNfh3JPStJG6DoGI6KHDmTciIiIiA8LkjYiIiMiAMHkjonuSmpqKwMBAWFlZwcHBAVFRUTh58qRGnQsXLmDatGno2rUrLCwsEBERgV9++UWjTmhoKGQymcbn2Wefbc9dISIyCA9F8paUlIS+ffvqOgyiB1JBQQFmzJiBffv2IS8vDyqVCsOHD8e1a9cAAEIIREVF4cyZM9i2bRuOHDkCFxcXDB06VKrT4MUXX0R5ebn0+ec//6mLXSIi0msGkbxVVFRg1qxZcHd3h1wuh7OzM0aNGoVdu3bpOrT75tNPP4VMJkNUVJSuQyG6o9zcXEybNg0+Pj7o06cP1q1bh7KyMhw6dAgA8Msvv2Dfvn3IyspCYGAgevXqhdWrV+Pq1av45JNPNNqysLCAo6Oj9LGxsdHFLhER6TW9T95KS0vRr18/7N69G+np6Th27Bhyc3MRFhaGGTNm6Dq8++LXX3/F/Pnz8fjjj+s6FKIWq66uBgDY2dkBAOrq6gAA5ubmUh1jY2OYmZlh7969Gttu3LgRnTt3ho+PD+bPn48rV660U9RERIZD75O32NhYyGQy7N+/H2PHjkXPnj3h4+OD+Ph47Nu3DwBQVlaG0aNHQ6FQwNraGuPHj8eFCxeabDM0NBRxcXEaZVFRUZg2bZq07OrqiqVLlyI6OhoKhQIuLi7Ytm0bLl68KPXl6+uLgwcPStusX78etra22LFjB7y8vKBQKBAREYHy8vJm7299fT0mTZqEJUuWwN3dvdnbEekDIQTi4+MRHByM3r17AwA8PT3h4uKChQsX4s8//8SNGzeQlpaGiooKjX8bkyZNwieffIL8/HwkJiZi8+bNGDNmjK52hYhIb+n1c94uX76M3NxcpKSkwNKy8TPLbG1tpetpLC0tUVBQAJVKhdjYWEyYMAH5+fn31H9GRgaWLVuGxMREZGRkYMqUKRg0aBBiYmKwfPlyJCQkIDo6GidOnIBMdvN5XbW1tVixYgWys7NhZGSEyZMnY/78+di4cWOz+kxOToa9vT1eeOEFfPvtt3etX1dXJ81sAEBNTQ0AQG4kYGwsWrHXdL/JjYTGV0OmVCo1lmfPno2ioiLs2bNHY92mTZvwt7/9DXZ2djA2NsYTTzyBiIgIjTZu/eOpV69ecHNzw2OPPYb9+/fD39///u/MLRpiun3/SD9wfPQfx6jlWnKs9Dp5O3XqFIQQ8PT0bLLOzp07UVRUhLNnz8LZ2RkAkJ2dDR8fHxw4cACBgYGt7j8yMhLTp08HACxevFi6ZmfcuHEAgISEBAwYMAAXLlyAo6MjgJsHf82aNfDw8AAAzJw5E8nJyc3q77vvvsMHH3yAwsLCZseYmpqKJUuWNCp/zV8NC4v6ZrdD7e+NALWuQ7hnOTk50vdr167Fjz/+iGXLlqGoqAhFRUUadZOTk3Ht2jWoVCrY2NjglVdeQffu3TXauJUQAiYmJvj8889bNHvdlvLy8nTSLzUPx0f/cYyar7a2ttl19Tp5E+LmzETDrJY2JSUlcHZ2lhI3APD29oatrS1KSkruKXnz8/OTvu/SpQsAwNfXt1FZZWWllLxZWFhIiRsAODk5obKy8q59XblyBZMnT8Z7772Hzp07NzvGhQsXIj4+XlquqamBs7Mzlh4xgsrUuNntUPuRGwm8EaBG4kEj1KkN+w0Lx5PCIYRAXFwcCgsL8c0336BHjx533e6XX37B6dOnkZmZiWHDhmlv+/hxqFQqjBgxot2v/1QqlcjLy8OwYcNgamrarn3T3XF89B/HqOUazpw1h14nbz169IBMJkNJSUmTd10KIbQmd02VA4CRkZGUGDbQNl156w9cQ1vaytRqtdZtGurc3pc2p0+fRmlpKUaNGiWVNbRrYmKCkydPaiSFDeRyOeRyeaPyOrUMKgN/9dKDrk4tM/jXY5mamiI2NhYff/wxtm3bBjs7O1y6dAkAYGNjgw4dOgAAPv/8c9jb2+ORRx7BsWPHMGfOHERFRSEyMhLAzZ//jRs3IjIyEp07d0ZxcTHmzZsHf39/hISEwNhYN3+ImJqa8hePHuP46D+OUfO15Djp9Q0LdnZ2CA8Px6pVqxo9DwoAqqqq4O3tjbKyMpw7d04qLy4uRnV1Nby8vLS2a29vr3Eapr6+HsePH2/7HWgBT09PHDt2DIWFhdLnqaeeQlhYGAoLCzVmFon0SVZWFqqrqxEaGgonJyfps2nTJqlOeXk5pkyZAk9PT8yePRtTpkzReEyImZkZdu3ahfDwcPTq1QuzZ8/G8OHDsXPnTp0lbkRE+kqvZ94AYPXq1Rg4cCCCgoKQnJwMPz8/qFQq5OXlISsrC8XFxfDz88OkSZOQmZkp3bAQEhKCgIAArW0OGTIE8fHx2L59Ozw8PJCRkYGqqqr23bHbmJubS3fnNbC1tQWARuVE+qQ5M8uzZ8/G7Nmzm1zv7OyMgoKCtgyLiOiBpdczbwDg5uaGw4cPIywsDPPmzUPv3r0xbNgw7Nq1C1lZWZDJZNi6dSs6duyIwYMHY+jQoXB3d9f4q/92MTExmDp1KqKjoxESEgI3NzeEhYW1414RERERtY5MNOfPZjIYNTU1sLGxgce8TVCZNH68Cume3FggPager+43Nvhr3krTRuo6hPtCqVQiJycHkZGRvF5HD3F89B/HqOUafn9XV1fD2tr6jnX1fuaNiIiIiP6HyVs7UigUTX6a80BeIiIiIr2/YeFBcqeH73br1q1N+/px4RPo1KlTm7ZJbaPhdMLxpHCeTiAiohZj8taOunfvrusQiIiIyMDxtCkRERGRAWHyRkRERGRAmLwRERERGRAmb0REREQGhMkbERERkQFh8kZERERkQJi8ERERERkQJm9EREREBoTJGxEREZEBYfJGREREZECYvBEREREZECZvRERERAaEyRsRERGRAWHyRkRERGRAmLwRERERGRAmb0REREQGhMkbERERkQEx0XUAdH/0T90FlYmlrsMgLeTGAulBQO+kHairl+kkhtK0kTrpl4iI7h1n3oiIiIgMCJM3IiIiIgPC5I3oIZWamorAwEBYWVnBwcEBUVFROHnyZKN6JSUleOqpp2BjYwMrKys89thjKCsrk9avXbsWoaGhsLa2hkwmQ1VVVTvuBRHRw+ehSN6SkpLQt29fXYdBpFcKCgowY8YM7Nu3D3l5eVCpVBg+fDiuXbsm1Tl9+jSCg4Ph6emJ/Px8HD16FImJiTA3N5fq1NbWIiIiAn//+991sRtERA8dg7hhoaKiAikpKdi+fTvOnz8PBwcH9O3bF3FxcXjiiSd0HV6bWb9+PZ5//vlG5f/97381flkStYXc3FyN5XXr1sHBwQGHDh3C4MGDAQCLFi1CZGQk0tPTpXru7u4a28XFxQEA8vPz72u8RER0k97PvJWWlqJfv37YvXs30tPTcezYMeTm5iIsLAwzZszQdXhtztraGuXl5RofJm7UHqqrqwEAdnZ2AAC1Wo3t27ejZ8+eCA8Ph4ODA/r374+tW7fqMEoiItL75C02NhYymQz79+/H2LFj0bNnT/j4+CA+Ph779u0DAJSVlWH06NFQKBSwtrbG+PHjceHChSbbDA0NlWYLGkRFRWHatGnSsqurK5YuXYro6GgoFAq4uLhg27ZtuHjxotSXr68vDh48KG2zfv162NraYseOHfDy8oJCoUBERATKy8ubvb8ymQyOjo4aH6L7TQiB+Ph4BAcHo3fv3gCAyspKXL16FWlpaYiIiMDXX3+Np59+GmPGjEFBQYGOIyYienjp9WnTy5cvIzc3FykpKbC0bPzMMltbWwghEBUVBUtLSxQUFEClUiE2NhYTJky459M4GRkZWLZsGRITE5GRkYEpU6Zg0KBBiImJwfLly5GQkIDo6GicOHECMtnN53XV1tZixYoVyM7OhpGRESZPnoz58+dj48aNzerz6tWrcHFxQX19Pfr27Ys33ngD/v7+Tdavq6tDXV2dtFxTUwMAkBsJGBuLe9h7ul/kRkLjqy4olUqN5dmzZ6OoqAh79uyR1jX8XI0aNQozZ84EAPj4+GDv3r1YvXo1Bg4cqNGGSqWS2r69fUPTEL+h78eDiuOj/zhGLdeSY6XXydupU6cghICnp2eTdXbu3ImioiKcPXsWzs7OAIDs7Gz4+PjgwIEDCAwMbHX/kZGRmD59OgBg8eLFyMrKQmBgIMaNGwcASEhIwIABA3DhwgVphkypVGLNmjXw8PAAAMycORPJycnN6s/T0xPr16+Hr68vampq8Pbbb2PQoEE4evQoevTooXWb1NRULFmypFH5a/5qWFjUt3ifqf28EaDWWd85OTnS92vXrsWPP/6IZcuWoaioCEVFRQBu/iwbGxvD2NhYo76ZmRmKioo0ygDg2LFjAICvv/4aCoWiHfbi/svLy9N1CHQHHB/9xzFqvtra2mbX1evkTYibMxMNs1ralJSUwNnZWUrcAMDb2xu2trYoKSm5p+TNz89P+r5Lly4AAF9f30ZllZWVUvJmYWEhJW4A4OTkhMrKymb199hjj+Gxxx6TlgcNGoRHH30UK1euxDvvvKN1m4ULFyI+Pl5arqmpgbOzM5YeMYLK1LhZ/VL7khsJvBGgRuJBI9SpdfOGheNJ4RBCIC4uDoWFhfjmm2+0/oHQ8O8nMjJSKvvwww/Rp08fjTIA0uz48OHDYWtre/+CbwdKpRJ5eXkYNmwYTE1NdR0O3Ybjo/84Ri3XcOasOfQ6eevRowdkMhlKSkoQFRWltY4QQmty11Q5ABgZGUmJYQNt05W3/sA1tKWtTK1Wa92moc7tfTWXkZERAgMD8csvvzRZRy6XQy6XNyqvU8ug0tGrl6h56tQynb0ey9TUFLGxsfj444+xbds22NnZ4dKlSwAAGxsbdOjQAQDw6quvYsKECQgNDUVYWBhyc3Oxfft25OfnSz/rFRUVqKioQGlpKQDgp59+gpWVFR555BHp5gdDZWpqyl88eozjo/84Rs3XkuOk1zcs2NnZITw8HKtWrdJ49lSDqqoqeHt7o6ysDOfOnZPKi4uLUV1dDS8vL63t2tvba9xEUF9fj+PHj7f9DtwjIQQKCwvh5OSk61DoAZSVlYXq6mqEhobCyclJ+mzatEmq8/TTT2PNmjVIT0+Hr68v3n//fWzevBnBwcFSnTVr1sDf3x8vvvgiAGDw4MHw9/fHF1980e77RET0MNDrmTcA0oXRQUFBSE5Ohp+fH1QqFfLy8pCVlYXi4mL4+flh0qRJyMzMlG5YCAkJQUBAgNY2hwwZgvj4eGzfvh0eHh7IyMjQi6fCL1myBI899hh69OiBmpoavPPOOygsLMSqVat0HRo9gJo7IxwTE4OYmJgm1yclJSEpKamNoiIiorvR++TNzc0Nhw8fRkpKCubNm4fy8nLY29ujX79+yMrKgkwmw9atWzFr1iwMHjwYRkZGiIiIwMqVK5tsMyYmBkePHkV0dDRMTEwwd+5chIWFteNeaVdVVYW//e1vqKiogI2NDfz9/fHNN98gKChI16ERERGRnpCJ1l6QRXqppqYGNjY28Ji3CSqTxo9XId2TGwukB9Xj1f3GOrvmrTRtpE76NRRKpRI5OTmIjIzk9Tp6iOOj/zhGLdfw+7u6uhrW1tZ3rKvX17wRERERkSYmb+1IoVA0+fn22291HR4REREZAL2/5u1BUlhY2OS6bt26tWlfPy58Ap06dWrTNqltNJxOOJ4UztMJRETUYm2WvFVVVRn8gznvt+7du+s6BCIiIjJwrTpt+uabb2o8C2r8+PHo1KkTunXrhqNHj7ZZcERERESkqVXJ2z//+U/pdVR5eXnIy8vDf/7zH4wYMQKvvPJKmwZIRERERP/TqtOm5eXlUvL21VdfYfz48Rg+fDhcXV3Rv3//Ng2QiIiIiP6nVTNvHTt2lF5HlZubi6FDhwK4+cT2+vr6touOiIiIiDS0auZtzJgxeO6559CjRw9cunQJI0aMAHDzbkpelE9ERER0/7QqecvIyICrqyvOnTuH9PR0KBQKADdPp8bGxrZpgERERET0P61K3kxNTTF//vxG5XFxcfcaDxERERHdQavfsJCdnY3g4GB07doVv/76KwAgMzMT27Zta7PgiIiIiEhTq5K3rKwsxMfHY8SIEaiqqpJuUrC1tUVmZmZbxkdEREREt2hV8rZy5Uq89957WLRoEYyNjaXygIAAHDt2rM2CIyIiIiJNrUrezp49C39//0blcrkc165du+egiIiIiEi7ViVvbm5uWl+y/p///Afe3t73GhMRERERNaFVd5u+8sormDFjBq5fvw4hBPbv349PPvkEqampeP/999s6RiIiIiL6/1qVvD3//PNQqVR49dVXUVtbi+eeew7dunXD22+/jWeffbatYyQiIiKi/6/FyZtKpcLGjRsxatQovPjii/jjjz+gVqvh4OBwP+IjIiIiolu0+Jo3ExMTvPzyy6irqwMAdO7cmYkbERERUTtp1Q0L/fv3x5EjR9o6FiIiIiK6i1Zd8xYbG4t58+bht99+Q79+/WBpaamx3s/Pr02Co9brn7oLKhPLu1ekdic3FkgPAnon7UBdvUwqL00bqcOoiIjIULQqeZswYQIAYPbs2VKZTCaDEAIymUx64wIRERERta1WJW9nz55t6ziIiIiIqBladc2bi4vLHT9E1DqpqakIDAyElZUVHBwcEBUVhZMnT2rUEUIgKSkJXbt2RYcOHRAaGooTJ05o1Dl9+jSefvpp2Nvbw9raGuPHj8eFCxfac1eIiOg+adXM24YNG+64Pjo6ulXB3C9JSUnYunWr1rdCEOmTgoICzJgxA4GBgVCpVFi0aBGGDx+O4uJi6drS9PR0vPXWW1i/fj169uyJpUuXYtiwYTh58iSsrKxw7do1DB8+HH369MHu3bsBAImJiRg1ahT27dsHI6NW/c1GRER6olXJ25w5czSWlUolamtrYWZmBgsLizZP3ioqKpCSkoLt27fj/PnzcHBwQN++fREXF4cnnniiTfvSJaVSidTUVPzrX//C+fPn0atXL7z55puIiIjQdWjUTnJzczWW161bBwcHBxw6dAiDBw+GEAKZmZlYtGgRxowZAwD417/+hS5duuDjjz/G9OnT8d1336G0tBRHjhyBtbW11I6dnR12796NoUOHtvt+ERFR22nVn+B//vmnxufq1as4efIkgoOD8cknn7RpgKWlpejXrx92796N9PR0HDt2DLm5uQgLC8OMGTPatC9de+211/DPf/4TK1euRHFxMV566SU8/fTTfCzLQ6y6uhoAYGdnB+Dm9aYVFRUYPny4VEculyMkJATff/89AKCurg4ymQxyuVyqY25uDiMjI+zdu7cdoyciovuhzc6f9OjRA2lpaY1m5e5VbGwsZDIZ9u/fj7Fjx6Jnz57w8fFBfHw89u3bBwAoKyvD6NGjoVAomnV9T2hoKOLi4jTKoqKiMG3aNGnZ1dUVS5cuRXR0NBQKBVxcXLBt2zZcvHhR6svX1xcHDx6Utlm/fj1sbW2xY8cOeHl5QaFQICIiAuXl5c3a1+zsbPz9739HZGQk3N3d8fLLLyM8PBz/+Mc/mn/A6IEhhEB8fDyCg4PRu3dvADdnoQGgS5cuGnW7dOkirXvsscdgaWmJhIQE1NbW4tq1a3jllVegVqub/bNIRET6q1WnTZtibGyM33//vc3au3z5MnJzc5GSktLoWXIAYGtrCyEEoqKiYGlpiYKCAqhUKsTGxmLChAnIz8+/p/4zMjKwbNkyJCYmIiMjA1OmTMGgQYMQExOD5cuXIyEhAdHR0Thx4gRkspvP66qtrcWKFSuQnZ0NIyMjTJ48GfPnz8fGjRvv2l9dXR3Mzc01yjp06HDH2ZK6ujrpbRcAUFNTAwCQGwkYG4vW7DbdZ3IjofG1gVKp1FiePXs2ioqKsGfPHmmdSqWSvt5av+HxPEqlEra2tvjkk08wa9YsvPPOOzAyMsKECRPg7+8PmUzWqB9qrOEY8VjpJ46P/uMYtVxLjlWrkrcvvvhCY1kIgfLycrz77rsYNGhQa5rU6tSpUxBCwNPTs8k6O3fuRFFREc6ePQtnZ2cAN2ewfHx8cODAAQQGBra6/8jISEyfPh0AsHjxYmRlZSEwMBDjxo0DACQkJGDAgAG4cOECHB0dAdw8+GvWrIGHhwcAYObMmUhOTm5Wf+Hh4XjrrbcwePBgeHh4YNeuXdi2bdsdn5uXmpqKJUuWNCp/zV8NCws+b0+fvRGg1ljOycmRvl+7di1+/PFHLFu2DEVFRSgqKgLwv5m3zZs3w93dXap//PhxWFpaarTx1ltvoaamBkZGRlAoFJg2bRr8/Pw06tCd5eXl6ToEugOOj/7jGDVfbW1ts+u2KnmLiorSWJbJZLC3t8eQIUPa9BSfEEJqvyklJSVwdnaWEjcA8Pb2hq2tLUpKSu4pebv1TRENp6l8fX0blVVWVkrJm4WFhZS4AYCTkxMqKyub1d/bb7+NF198EZ6enpDJZPDw8MDzzz+PdevWNbnNwoULER8fLy3X1NTA2dkZS48YQWVq3Kx+qX3JjQTeCFAj8aAR6tT/+9k+nhQOIQTi4uJQWFiIb775Bj169NDYtuExIdevX0dkZCQA4MaNG5g6dSqWLVsmld1uz549qK6uxvz589GrV6/7t3MPCKVSiby8PAwbNgympqa6Doduw/HRfxyjlms4c9YcrUre1Gr13Su1gR49ekAmk6GkpKRRwtig4a0OzS0HACMjIykxbKBtuvLWH7iGtrSV3Xo8bv8hbXjzRHPY29tj69atuH79Oi5duoSuXbtiwYIFcHNza3IbuVyucWF6gzq1DKr6ppNe0r06tUzj9VimpqaIjY3Fxx9/jG3btsHOzg6XLl0CANjY2KBDhw4AgLi4OKSmpsLT0xM9evTAsmXLYGFhgSlTpkg/f+vWrYOXlxfs7e3xww8/YM6cOZg7d6507Rw1j6mpKX/x6DGOj/7jGDVfS45Tq25YSE5O1jq999///rfZpwibw87ODuHh4Vi1ahWuXbvWaH1VVRW8vb1RVlaGc+fOSeXFxcWorq6Gl5eX1nbt7e01Ltyur6/H8ePH2yzue2Vubo5u3bpBpVJh8+bNGD16tK5DonaSlZWF6upqhIaGwsnJSfps2rRJqvPqq68iLi4OsbGxCAgIwPnz5/H111/DyspKqnPy5ElERUXBy8sLycnJWLRoEVasWKGLXSIiojbWquRtyZIluHr1aqPy2tparddf3YvVq1ejvr4eQUFB2Lx5M3755ReUlJTgnXfewYABAzB06FD4+flh0qRJOHz4MPbv34/o6GiEhIQgICBAa5tDhgzB9u3bsX37dvz000+IjY1FVVVVm8bdGj/++CO2bNmCM2fO4Ntvv0VERATUajVeffVVXYdG7UQIofVz653QMpkMSUlJKC8vx/Xr11FQUNBoRi0tLQ0VFRW4ceMGfv75Z8THx9/x8gMiIjIcrUremjolefToUel5VG3Fzc0Nhw8fRlhYGObNm4fevXtj2LBh2LVrF7KysiCTybB161Z07NgRgwcPxtChQ+Hu7q4xU3G7mJgYTJ06VUry3NzcEBYW1qZxt8b169fx2muvwdvbG08//TS6deuGvXv3wtbWVtehERERkZ6QieZekAWgY8eOkMlkqK6uhrW1tUYCV19fj6tXr+Kll17CqlWr7kuwdHc1NTWwsbGBx7xNUJk0frwK6Z7cWCA9qB6v7jfWuOatNG2kDqOiWymVSuTk5CAyMpLX6+ghjo/+4xi1XMPv74Yc605adMNCZmYmhBCIiYnBkiVLYGNjI60zMzODq6srBgwY0LqoiYiIiOiuWpS8TZ06FcDNU5kDBw5kNt1CCoWiyXX/+c9/8Pjjj7djNERERGSIWvWokJCQEOn7//73v40es3G36b6HVWFhYZPrunXr1qZ9/bjwCXTq1KlN26S20XA64XhSOP8AIiKiFmtV8lZbW4tXX30Vn332mfQcqlvd6Y0AD7Pu3bvrOgQiIiIycK262/SVV17B7t27sXr1asjlcrz//vtYsmQJunbtig0bNrR1jERERET0/7Vq5u3LL7/Ehg0bEBoaipiYGDz++OPo3r07XFxcsHHjRkyaNKmt4yQiIiIitHLm7fLly9Irm6ytrXH58mUAQHBwML755pu2i46IiIiINLQqeXN3d0dpaSmAmy+B/+yzzwDcnJHjA2WJiIiI7p9WJW/PP/88jh49CgBYuHChdO3b3Llz8corr7RpgERERET0P6265m3u3LnS92FhYfjpp59w8OBBeHh4oE+fPm0WHBERERFpalXydqvr16/jkUcewSOPPNIW8RARERHRHbTqtGl9fT3eeOMNdOvWDQqFAmfOnAEAJCYm4oMPPmjTAImIiIjof1qVvKWkpGD9+vVIT0+HmZmZVO7r64v333+/zYIjIiIiIk2tSt42bNiAtWvXYtKkSTA2NpbK/fz88NNPP7VZcERERESkqVXJ2/nz57W+6kmtVjd6zykRERERtZ1WJW8+Pj749ttvG5V//vnn8Pf3v+egiIiIiEi7Vt1t+vrrr2PKlCk4f/481Go1tmzZgpMnT2LDhg346quv2jpGIiIiIvr/WjTzdubMGQghMGrUKGzatAk5OTmQyWRYvHgxSkpK8OWXX2LYsGH3K1YiIiKih16LZt569OiB8vJyODg4IDw8HB9++CFOnToFR0fH+xUfEREREd2iRTNvQgiN5f/85z+ora1t04CIiIiIqGmtumGhwe3JHBERERHdXy06bSqTySCTyRqVkf7pn7oLKhNLXYehF0rTRuo6BCIiojbTouRNCIFp06ZBLpcDuPle05deegmWlppJwpYtW9ouQiIiIiKStCh5mzp1qsby5MmT2zQYIiIiIrqzFiVv69atu19xEN1333zzDZYvX45Dhw6hvLwc//d//4eoqCgAgFKpxGuvvYacnBycOXMGNjY2GDp0KNLS0tC1a1epjdOnT2P+/PnYu3cv6urqEBERgZUrV6JLly462isiInrY3NMNC4YiKSkJffv21XUYpGPXrl1Dnz598O677zZaV1tbi8OHDyMxMRGHDx/Gli1b8PPPP+Opp57S2H748OGQyWTYvXs3vvvuO9y4cQOjRo2CWq1uz10hIqKHWKvesNDeKioqkJKSgu3bt+P8+fNwcHBA3759ERcXhyeeeELX4bWpqqoqLFq0CFu2bMGff/4JNzc3/OMf/0BkZKSuQzN4I0aMwIgRI7Sus7GxQV5enkbZypUrERQUhLKyMjzyyCP47rvvUFpaiiNHjsDa2hrAzdloOzs77N69G0OHDr3v+0BERKT3yVtpaSkGDRoEW1tbpKenw8/PD0qlEjt27MCMGTPw008/6TrENnPjxg0MGzYMDg4O+Pe//42//OUvOHfuHKysrHQd2kOpuroaMpkMtra2AIC6ujrIZDLphh0AMDc3h5GREfbu3cvkjYiI2oXenzaNjY2FTCbD/v37MXbsWPTs2RM+Pj6Ij4/Hvn37AABlZWUYPXo0FAoFrK2tMX78eFy4cKHJNkNDQxEXF6dRFhUVhWnTpknLrq6uWLp0KaKjo6FQKODi4oJt27bh4sWLUl++vr44ePCgtM369etha2uLHTt2wMvLCwqFAhERESgvL2/Wvn744Ye4fPkytm7dikGDBsHFxQXBwcHo06dP8w8YtYnr169jwYIFeO6556RZtsceewyWlpZISEhAbW0trl27hldeeQVqtbrZY0xERHSv9Hrm7fLly8jNzUVKSkqjx5EAgK2tLYQQiIqKgqWlJQoKCqBSqRAbG4sJEyYgPz//nvrPyMjAsmXLkJiYiIyMDEyZMgWDBg1CTEwMli9fjoSEBERHR+PEiRPS8+5qa2uxYsUKZGdnw8jICJMnT8b8+fOxcePGu/b3xRdfYMCAAZgxYwa2bdsGe3t7PPfcc0hISICxsbHWberq6lBXVyct19TUAADkRgLGxnyIMnDzZgRtVCqV1nVKpRLPPvss6uvr8fbbb0t1bG1t8cknn2DWrFl45513YGRkhAkTJsDf3x8ymazJfpqKp7n1qf1xjPQbx0f/cYxariXHSq+Tt1OnTkEIAU9Pzybr7Ny5E0VFRTh79iycnZ0BANnZ2fDx8cGBAwcQGBjY6v4jIyMxffp0AMDixYuRlZWFwMBAjBs3DgCQkJCAAQMG4MKFC9L7XZVKJdasWQMPDw8AwMyZM5GcnNys/s6cOYPdu3dj0qRJyMnJwS+//IIZM2ZApVJh8eLFWrdJTU3FkiVLGpW/5q+GhUV9i/f5QZSTk6O1/NChQzA1NdUoU6lUWL58OS5cuIDk5GTs3bu30XZvvfUWampqYGRkBIVCgWnTpsHPz6/Jfppy+zV2pH84RvqN46P/OEbN15LXjep18tbw+q07vcWhpKQEzs7OUuIGAN7e3rC1tUVJSck9JW9+fn7S9w2PgvD19W1UVllZKSVvFhYWUuIGAE5OTqisrGxWf2q1Gg4ODli7di2MjY3Rr18//P7771i+fHmTydvChQsRHx8vLdfU1MDZ2RlLjxhBZap9tu5hczwpXGt5v379NG4EUSqVmDhxIq5cuYLvvvsO9vb2d217z549qK6uxvz589GrV69mxaNUKpGXl4dhw4Y1Sh5JP3CM9BvHR/9xjFqu4cxZc+h18tajRw/IZDKUlJRIz+O6nRBCa3LXVDkAGBkZNXovq7bpylt/4Bra0lZ262Mibv8hlclkzX4HrJOTE0xNTTVOkXp5eaGiogI3btyAmZlZo23kcrnGBfQN6tQyqOr56jLgf2Ny9epVnDp1Sio/d+4cTpw4ATs7O3Tt2hUTJ07E4cOH8dVXX8HIyAiXLl0CANjZ2UnHft26dfDy8oK9vT1++OEHzJkzB3PnzkXv3r1bFRf/U9NvHCP9xvHRfxyj5mvJcdLrGxbs7OwQHh6OVatW4dq1a43WV1VVwdvbG2VlZTh37pxUXlxcjOrqanh5eWlt197eXuMC8/r6ehw/frztd6CFBg0ahFOnTmkkgz///DOcnJy0Jm7UMgcPHoS/vz/8/f0BAPHx8fD398fixYvx22+/4YsvvsBvv/2Gvn37wsnJSfp8//33UhsnT55EVFQUvLy8kJycjEWLFmHFihW62iUiInoI6fXMGwCsXr0aAwcORFBQEJKTk+Hn5weVSoW8vDxkZWWhuLgYfn5+mDRpEjIzM6UbFkJCQhAQEKC1zSFDhiA+Ph7bt2+Hh4cHMjIyUFVV1b47psXLL7+MlStXYs6cOZg1axZ++eUXLFu2DLNnz9Z1aA+E0NDQO86CNmeGNC0tDWlpaW0ZFhERUYvo9cwbALi5ueHw4cMICwvDvHnz0Lt3bwwbNgy7du1CVlYWZDIZtm7dio4dO2Lw4MEYOnQo3N3dsWnTpibbjImJwdSpUxEdHY2QkBC4ubkhLCysHfdKO2dnZ3z99dc4cOAA/Pz8MHv2bMyZMwcLFizQdWhERESkJ2SiuRdkkUGoqamBjY0NPOZtgsqk8eNVHkalaSN1HYIGpVKJnJwcREZG8loQPcUx0m8cH/3HMWq5ht/f1dXV0vNFm6L3M29ERERE9D9M3tqRQqFo8vPtt9/qOjwiIiIyAHp/w8KDpLCwsMl13bp1a9O+flz4BDp16tSmbRIREZHuMXlrR927d9d1CERERGTgeNqUiIiIyIAweSMiIiIyIEzeiIiIiAwIkzciIiIiA8LkjYiIiMiAMHkjIiIiMiBM3oiIiIgMCJM3IiIiIgPC5I2IiIjIgDB5IyIiIjIgTN6IiIiIDAiTNyIiIiIDwuSNiIiIyIAweSMiIiIyIEzeiIiIiAwIkzciIiIiA8LkjYiIiMiAmOg6ALo/+qfugsrEUtdh3FFp2khdh0BERGRwOPNGREREZECYvBEREREZECZvpHMqlQqvvfYa3Nzc0KFDB7i7uyM5ORlqtVqqI4RAUlISunbtig4dOiA0NBQnTpzQYdRERES68VAkb0lJSejbt6+uw6AmvPnmm1izZg3effddlJSUID09HcuXL8fKlSulOunp6Xjrrbfw7rvv4sCBA3B0dMSwYcNw5coVHUZORETU/gwieauoqMCsWbPg7u4OuVwOZ2dnjBo1Crt27dJ1aG0uMzMTvXr1QocOHeDs7Iy5c+fi+vXrug7rvvrhhx8wevRojBw5Eq6urhg7diyGDx+OgwcPArg565aZmYlFixZhzJgx6N27N/71r3+htrYWH3/8sY6jJyIial96n7yVlpaiX79+2L17N9LT03Hs2DHk5uYiLCwMM2bM0HV4bWrjxo1YsGABXn/9dZSUlOCDDz7Apk2bsHDhQl2Hdl8FBwdj165d+PnnnwEAR48exd69exEZGQkAOHv2LCoqKjB8+HBpG7lcjpCQEHz//fc6iZmIiEhX9D55i42NhUwmw/79+zF27Fj07NkTPj4+iI+Px759+wAAZWVlGD16NBQKBaytrTF+/HhcuHChyTZDQ0MRFxenURYVFYVp06ZJy66urli6dCmio6OhUCjg4uKCbdu24eLFi1Jfvr6+0uwQAKxfvx62trbYsWMHvLy8oFAoEBERgfLy8mbt6w8//IBBgwbhueeeg6urK4YPH46JEydq9PEgSkhIwMSJE+Hp6QlTU1P4+/sjLi4OEydOBHBz5hUAunTporFdly5dpHVEREQPC71+ztvly5eRm5uLlJQUWFo2fmaZra0thBCIioqCpaUlCgoKoFKpEBsbiwkTJiA/P/+e+s/IyMCyZcuQmJiIjIwMTJkyBYMGDUJMTAyWL1+OhIQEREdH48SJE5DJZACA2tparFixAtnZ2TAyMsLkyZMxf/58bNy48a79BQcH46OPPsL+/fsRFBSEM2fOICcnB1OnTm1ym7q6OtTV1UnLNTU1AAC5kYCxsbin/b/flEolAGDTpk346KOPsGHDBnh7e+Po0aOYP38+HBwcEB0dDZVKBeDmjQ0N2wBAfX29RjuGoiFeQ4v7YcIx0m8cH/3HMWq5lhwrvU7eTp06BSEEPD09m6yzc+dOFBUV4ezZs3B2dgYAZGdnw8fHBwcOHEBgYGCr+4+MjMT06dMBAIsXL0ZWVhYCAwMxbtw4ADdnjAYMGIALFy7A0dERwM2Dv2bNGnh4eAAAZs6cieTk5Gb19+yzz+LixYsIDg6GEAIqlQovv/wyFixY0OQ2qampWLJkSaPy1/zVsLCob9H+trecnBwAQFxcHJ555hlYWVnh3LlzsLOzQ0REBF5//XV07txZml3bvHkz3N3dpe2PHz8OS0tLqR1Dk5eXp+sQ6C44RvqN46P/OEbNV1tb2+y6ep28CXFz5qhhVkubkpISODs7S4kbAHh7e8PW1hYlJSX3lLz5+flJ3zecsvP19W1UVllZKSVvFhYWUuIGAE5OTqisrGxWf/n5+UhJScHq1avRv39/nDp1CnPmzIGTkxMSExO1brNw4ULEx8dLyzU1NXB2dsbSI0ZQmRo3c09143hSOICb4+zr6ytd4wYAx44dw/79+xEZGSk9JuT69etSnRs3bmDq1KlYtmyZxnaGQKlUIi8vD8OGDYOpqamuwyEtOEb6jeOj/zhGLddw5qw59Dp569GjB2QyGUpKShAVFaW1jhBCa3LXVDkAGBkZSYlhA23Tlbf+wDW0pa3s1ueR3f5DKpPJGvXVlMTEREyZMgV//etfAdxMFK9du4a//e1vWLRoEYyMGl+iKJfLIZfLG5XXqWVQ1Ted9OqDhmM1atQopKWlwc3NDT4+Pjhy5AjefvttxMTESHXi4uKQmpoKT09P9OjRA8uWLYOFhQWmTJlisP8xmJqaGmzsDwuOkX7j+Og/jlHzteQ46fUNC3Z2dggPD8eqVatw7dq1Ruurqqrg7e2NsrIynDt3TiovLi5GdXU1vLy8tLZrb2+vcRNBfX09jh8/3vY70EK1tbWNEjRjY2MIIZqdABqilStXYuzYsYiNjYWXlxfmz5+P6dOn44033pDqvPrqq4iLi0NsbCwCAgJw/vx5fP3117CystJh5ERERO1Pr2feAGD16tUYOHAggoKCkJycDD8/P6hUKuTl5SErKwvFxcXw8/PDpEmTkJmZKd2wEBISgoCAAK1tDhkyBPHx8di+fTs8PDyQkZGBqqqq9t0xLUaNGoW33noL/v7+0mnTxMREPPXUUzA21u9ToPfCysoKmZmZyMzMbLKOTCZDUlISkpKS2i0uIiIifaT3yZubmxsOHz6MlJQUzJs3D+Xl5bC3t0e/fv2QlZUFmUyGrVu3YtasWRg8eDCMjIwQERGh8XT+28XExODo0aOIjo6GiYkJ5s6di7CwsHbcK+1ee+01yGQyvPbaazh//jzs7e0xatQopKSk6Do0IiIi0hMy8SCfj3sI1dTUwMbGBh7zNkFl0vjxKvqkNG2krkPQCaVSiZycHERGRvJaED3FMdJvHB/9xzFquYbf39XV1bC2tr5jXb2+5o2IiIiINDF5a0cKhaLJz7fffqvr8IiIiMgA6P01bw+SwsLCJtd169atTfv6ceET6NSpU5u2SURERLrH5K0dde/eXdchEBERkYHjaVMiIiIiA8LkjYiIiMiAMHkjIiIiMiBM3oiIiIgMCJM3IiIiIgPC5I2IiIjIgDB5IyIiIjIgTN6IiIiIDAiTNyIiIiIDwuSNiIiIyIAweSMiIiIyIEzeiIiIiAwIkzciIiIiA8LkjYiIiMiAMHkjIiIiMiBM3oiIiIgMCJM3IiIiIgNiousA6P7on7oLKhPLFm1TmjbyPkVDREREbYUzb0REREQGhMkbERERkQFh8kYaUlNTERgYCCsrKzg4OCAqKgonT55sVK+kpARPPfUUbGxsYGVlhcceewxlZWU6iJiIiOjhYvDJW1JSEvr27avrMB4YBQUFmDFjBvbt24e8vDyoVCoMHz4c165dk+qcPn0awcHB8PT0RH5+Po4ePYrExESYm5vrMHIiIqKHg86Tt4qKCsyaNQvu7u6Qy+VwdnbGqFGjsGvXLl2H1qZOnDiBZ555Bq6urpDJZMjMzNRab/Xq1XBzc4O5uTn69euHb7/9tl3jzM3NxbRp0+Dj44M+ffpg3bp1KCsrw6FDh6Q6ixYtQmRkJNLT0+Hv7w93d3eMHDkSDg4O7RorERHRw0inyVtpaSn69euH3bt3Iz09HceOHUNubi7CwsIwY8YMXYbW5mpra+Hu7o60tDQ4OjpqrbNp0ybExcVh0aJFOHLkCB5//HGMGDFCp6cjq6urAQB2dnYAALVaje3bt6Nnz54IDw+Hg4MD+vfvj61bt+osRiIiooeJTpO32NhYyGQy7N+/H2PHjkXPnj3h4+OD+Ph47Nu3DwBQVlaG0aNHQ6FQwNraGuPHj8eFCxeabDM0NBRxcXEaZVFRUZg2bZq07OrqiqVLlyI6OhoKhQIuLi7Ytm0bLl68KPXl6+uLgwcPStusX78etra22LFjB7y8vKBQKBAREYHy8vJm7WtgYCCWL1+OZ599FnK5XGudt956Cy+88AL++te/wsvLC5mZmXB2dkZWVlaz+mhrQgjEx8cjODgYvXv3BgBUVlbi6tWrSEtLQ0REBL7++ms8/fTTGDNmDAoKCnQSJxER0cNEZ895u3z5MnJzc5GSkgJLy8bPI7O1tYUQAlFRUbC0tERBQQFUKhViY2MxYcIE5Ofn31P/GRkZWLZsGRITE5GRkYEpU6Zg0KBBiImJwfLly5GQkIDo6GicOHECMpkMwM3ZsxUrViA7OxtGRkaYPHky5s+fj40bN95TLABw48YNHDp0CAsWLNAoHz58OL7//vsmt6urq0NdXZ20XFNTAwCQGwkYG4sWxaBUKjWWZ8+ejaKiIuzZs0da19DXqFGjMHPmTACAj48P9u7di9WrV2PgwIEt6vNh1HAsbz/epD84RvqN46P/OEYt15JjpbPk7dSpUxBCwNPTs8k6O3fuRFFREc6ePQtnZ2cAQHZ2Nnx8fHDgwAEEBga2uv/IyEhMnz4dALB48WJkZWUhMDAQ48aNAwAkJCRgwIABuHDhgnSaU6lUYs2aNfDw8AAAzJw5E8nJya2O4VZ//PEH6uvr0aVLF43yLl26oKKiosntUlNTsWTJkkblr/mrYWFR36IYcnJypO/Xrl2LH3/8EcuWLUNRURGKiooA3DwGxsbGMDY21qhvZmaGoqIijTK6s7y8PF2HQHfBMdJvHB/9xzFqvtra2mbX1VnyJsTNWaGGWS1tSkpK4OzsLCVuAODt7Q1bW1uUlJTcU/Lm5+cnfd+QMPn6+jYqq6yslJI3CwsLKXEDACcnJ1RWVrY6Bm1uPx5CiDseo4ULFyI+Pl5arqmpgbOzM5YeMYLK1LhFfR9PCocQAnFxcSgsLMQ333yDHj16NKrXcNwjIyOlsg8//BB9+vTRKCPtlEol8vLyMGzYMJiamuo6HNKCY6TfOD76j2PUcg1nzppDZ8lbjx49IJPJUFJSgqioKK11mkpc7pTQGBkZSYlhA21Tkbf+MDW0pa1MrVZr3aahzu19tVbnzp1hbGzcaJatsrKy0WzcreRyudZr6OrUMqjqm076tDE1NUVsbCw+/vhjbNu2DXZ2drh06RIAwMbGBh06dAAAvPrqq5gwYQJCQ0MRFhaG3NxcbN++Hfn5+fxH2gKmpqY8XnqOY6TfOD76j2PUfC05Tjq7YcHOzg7h4eFYtWqVxjPEGlRVVcHb2xtlZWU4d+6cVF5cXIzq6mp4eXlpbdfe3l7jJoL6+nocP3687XegjZmZmaFfv36Nppjz8vLa9TqyrKwsVFdXIzQ0FE5OTtJn06ZNUp2nn34aa9asQXp6Onx9ffH+++9j8+bNCA4Obrc4iYiIHlY6fTF9wwXuQUFBSE5Ohp+fH1QqFfLy8pCVlYXi4mL4+flh0qRJyMzMlG5YCAkJQUBAgNY2hwwZgvj4eGzfvh0eHh7IyMhAVVVV++6YFjdu3EBxcbH0/fnz51FYWAiFQoHu3bsDAOLj4zFlyhQEBARgwIABWLt2LcrKyvDSSy+1W5zNnUmMiYlBTEzMfY6GiIiIbqfT5M3NzQ2HDx9GSkoK5s2bh/Lyctjb26Nfv37IysqCTCbD1q1bMWvWLAwePBhGRkaIiIjAypUrm2wzJiYGR48eRXR0NExMTDB37lyEhYW1415p9/vvv8Pf319aXrFiBVasWIGQkBDpztkJEybg0qVLSE5ORnl5OXr37o2cnBy4uLjoKGoiIiLSNzLRVhdtkV6oqamBjY0NPOZtgsqk8SNY7qQ0beR9iopupVQqkZOTg8jISF4Loqc4RvqN46P/OEYt1/D7u7q6GtbW1nesq/PXYxERERFR8zF5ayMKhaLJT3u/n5SIiIgeXDq95u1BUlhY2OS6bt26tV8g/9+PC59Ap06d2r1fIiIiur+YvLWRhjtGiYiIiO4nnjYlIiIiMiBM3oiIiIgMCJM3IiIiIgPC5I2IiIjIgDB5IyIiIjIgTN6IiIiIDAiTNyIiIiIDwuSNiIiIyIAweSMiIiIyIEzeiIiIiAwIkzciIiIiA8LkjYiIiMiAMHkjIiIiMiBM3oiIiIgMCJM3IiIiIgPC5I2IiIjIgDB5IyIiIjIgTN4eUP1Td8F1wXZdh0FERERtjMkbERERkQFh8kZERERkQJi8PQSSkpIgk8k0Po6OjroOi4iIiFrhoUjekpKS0LdvX12HoVM+Pj4oLy+XPseOHdN1SERERNQKBpG8VVRUYNasWXB3d4dcLoezszNGjRqFXbt26Tq0NnXixAk888wzcHV1hUwmQ2ZmZpu1bWJiAkdHR+ljb2/fZm0TERFR+9H75K20tBT9+vXD7t27kZ6ejmPHjiE3NxdhYWGYMWOGrsNrU7W1tXB3d0daWlqbn9b85Zdf0LVrV7i5ueHZZ5/FmTNn2rR9IiIiah96n7zFxsZCJpNh//79GDt2LHr27AkfHx/Ex8dj3759AICysjKMHj0aCoUC1tbWGD9+PC5cuNBkm6GhoYiLi9Moi4qKwrRp06RlV1dXLF26FNHR0VAoFHBxccG2bdtw8eJFqS9fX18cPHhQ2mb9+vWwtbXFjh074OXlBYVCgYiICJSXlzdrXwMDA7F8+XI8++yzkMvlzT9Id9G/f39s2LABO3bswHvvvYeKigoMHDgQly5darM+iIiIqH2Y6DqAO7l8+TJyc3ORkpICS0vLRuttbW0hhEBUVBQsLS1RUFAAlUqF2NhYTJgwAfn5+ffUf0ZGBpYtW4bExERkZGRgypQpGDRoEGJiYrB8+XIkJCQgOjoaJ06cgEwmA3Bz9mzFihXIzs6GkZERJk+ejPnz52Pjxo33FEtT6urqUFdXJy3X1NQAAORGAsbGAkqlEkOHDpXWe3p6IiAgAJ6envjwww8bJbF0/ymVSo2vpH84RvqN46P/OEYt15JjpdfJ26lTpyCEgKenZ5N1du7ciaKiIpw9exbOzs4AgOzsbPj4+ODAgQMIDAxsdf+RkZGYPn06AGDx4sXIyspCYGAgxo0bBwBISEjAgAEDcOHCBek0p1KpxJo1a+Dh4QEAmDlzJpKTk1sdw92kpqZiyZIljcpf81fDwqIeOTk5WrdzdHTE7t270bNnz/sWG91ZXl6erkOgu+AY6TeOj/7jGDVfbW1ts+vqdfImhAAAaVZLm5KSEjg7O0uJGwB4e3vD1tYWJSUl95S8+fn5Sd936dIFAODr69uorLKyUkreLCwspMQNAJycnFBZWdnqGO5m4cKFiI+Pl5Zramrg7OyMpUeMoDI1xvGk8Ebb1NXVYcaMGRg9ejQiIyPvW2yknVKpRF5eHoYNGwZTU1Ndh0NacIz0G8dH/3GMWq7hzFlz6HXy1qNHD8hkMpSUlCAqKkprHSGE1uSuqXIAMDIykhLDBtqmK2/9gWtoS1uZWq3Wuk1Dndv7aktyuVzr9XF1ahlU9TKYmppi/vz5GDVqFB555BFUVlZi6dKlqKmpQUxMDP9R6ZCpqSmPv57jGOk3jo/+4xg1X0uOk17fsGBnZ4fw8HCsWrUK165da7S+qqoK3t7eKCsrw7lz56Ty4uJiVFdXw8vLS2u79vb2GjcR1NfX4/jx422/A3rit99+w8SJE9GrVy+MGTMGZmZm2LdvH1xcXHQdGhEREbWQXs+8AcDq1asxcOBABAUFITk5GX5+flCpVMjLy0NWVhaKi4vh5+eHSZMmITMzU7phISQkBAEBAVrbHDJkCOLj47F9+3Z4eHggIyMDVVVV7btjWty4cQPFxcXS9+fPn0dhYSEUCgW6d+/e6nY//fTTtgqRiIiIdEyvZ94AwM3NDYcPH0ZYWBjmzZuH3r17Y9iwYdi1axeysrIgk8mwdetWdOzYEYMHD8bQoUPh7u6OTZs2NdlmTEwMpk6diujoaISEhMDNzQ1hYWHtuFfa/f777/D394e/vz/Ky8uxYsUK+Pv7469//auuQyMiIiI9IRP384Isanc1NTWwsbGBx7xNUJlYojRtpK5DotsolUrk5OQgMjKS14LoKY6RfuP46D+OUcs1/P6urq6GtbX1Hevq/cwbEREREf0Pk7d2pFAomvx8++23ug6PiIiIDIDe37DwICksLGxyXbdu3dq0rx8XPoFOnTq1aZtERESke0ze2tG93DFKREREBPC0KREREZFBYfJGREREZECYvBEREREZECZvRERERAaEyRsRERGRAWHyRkRERGRAmLwRERERGRAmb0REREQGhMkbERERkQFh8kZERERkQJi8ERERERkQJm9EREREBoTJGxEREZEBYfJGREREZECYvBEREREZECZvRERERAaEyRsRERGRAWHyRkRERGRAmLwRERERGRAmb0REREQGhMkbERERkQFh8kZERERkQJi8ERERERkQJm9EREREBoTJGxEREZEBMdF1ANS2hBAAgCtXrsDU1FTH0ZA2SqUStbW1qKmp4RjpKY6RfuP46D+OUcvV1NQA+N/v8Tth8vaAuXTpEgDAzc1Nx5EQERFRS125cgU2NjZ3rMPk7QFjZ2cHACgrK7vr4JNu1NTUwNnZGefOnYO1tbWuwyEtOEb6jeOj/zhGLSeEwJUrV9C1a9e71mXy9oAxMrp5GaONjQ3/weg5a2trjpGe4xjpN46P/uMYtUxzJ114wwIRERGRAWHyRkRERGRAmLw9YORyOV5//XXI5XJdh0JN4BjpP46RfuP46D+O0f0lE825J5WIiIiI9AJn3oiIiIgMCJM3IiIiIgPC5I2IiIjIgDB5IyIiIjIgTN4eMKtXr4abmxvMzc3Rr18/fPvtt7oO6aGQmpqKwMBAWFlZwcHBAVFRUTh58qRGHSEEkpKS0LVrV3To0AGhoaE4ceKERp26ujrMmjULnTt3hqWlJZ566in89ttv7bkrD4XU1FTIZDLExcVJZRwf3Tt//jwmT56MTp06wcLCAn379sWhQ4ek9Rwj3VKpVHjttdfg5uaGDh06wN3dHcnJyVCr1VIdjlE7EfTA+PTTT4Wpqal47733RHFxsZgzZ46wtLQUv/76q65De+CFh4eLdevWiePHj4vCwkIxcuRI8cgjj4irV69KddLS0oSVlZXYvHmzOHbsmJgwYYJwcnISNTU1Up2XXnpJdOvWTeTl5YnDhw+LsLAw0adPH6FSqXSxWw+k/fv3C1dXV+Hn5yfmzJkjlXN8dOvy5cvCxcVFTJs2Tfz444/i7NmzYufOneLUqVNSHY6Rbi1dulR06tRJfPXVV+Ls2bPi888/FwqFQmRmZkp1OEbtg8nbAyQoKEi89NJLGmWenp5iwYIFOoro4VVZWSkAiIKCAiGEEGq1Wjg6Ooq0tDSpzvXr14WNjY1Ys2aNEEKIqqoqYWpqKj799FOpzvnz54WRkZHIzc1t3x14QF25ckX06NFD5OXliZCQECl54/joXkJCgggODm5yPcdI90aOHCliYmI0ysaMGSMmT54shOAYtSeeNn1A3LhxA4cOHcLw4cM1yocPH47vv/9eR1E9vKqrqwEAdnZ2AICzZ8+ioqJCY3zkcjlCQkKk8Tl06BCUSqVGna5du6J3794cwzYyY8YMjBw5EkOHDtUo5/jo3hdffIGAgACMGzcODg4O8Pf3x3vvvSet5xjpXnBwMHbt2oWff/4ZAHD06FHs3bsXkZGRADhG7Ykvpn9A/PHHH6ivr0eXLl00yrt06YKKigodRfVwEkIgPj4ewcHB6N27NwBIY6BtfH799VepjpmZGTp27NioDsfw3n366ac4dOgQDh482Ggdx0f3zpw5g6ysLMTHx+Pvf/879u/fj9mzZ0MulyM6OppjpAcSEhJQXV0NT09PGBsbo76+HikpKZg4cSIA/jtqT0zeHjAymUxjWQjRqIzur5kzZ6KoqAh79+5ttK4148MxvHfnzp3DnDlz8PXXX8Pc3LzJehwf3VGr1QgICMCyZcsAAP7+/jhx4gSysrIQHR0t1eMY6c6mTZvw0Ucf4eOPP4aPjw8KCwsRFxeHrl27YurUqVI9jtH9x9OmD4jOnTvD2Ni40V8ulZWVjf4Kovtn1qxZ+OKLL7Bnzx785S9/kcodHR0B4I7j4+joiBs3buDPP/9ssg61zqFDh1BZWYl+/frBxMQEJiYmKCgowDvvvAMTExPp+HJ8dMfJyQne3t4aZV5eXigrKwPAf0P64JVXXsGCBQvw7LPPwtfXF1OmTMHcuXORmpoKgGPUnpi8PSDMzMzQr18/5OXlaZTn5eVh4MCBOorq4SGEwMyZM7Flyxbs3r0bbm5uGuvd3Nzg6OioMT43btxAQUGBND79+vWDqampRp3y8nIcP36cY3iPnnjiCRw7dgyFhYXSJyAgAJMmTUJhYSHc3d05Pjo2aNCgRo/X+fnnn+Hi4gKA/4b0QW1tLYyMNNMGY2Nj6VEhHKN2pKMbJeg+aHhUyAcffCCKi4tFXFycsLS0FKWlpboO7YH38ssvCxsbG5Gfny/Ky8ulT21trVQnLS1N2NjYiC1btohjx46JiRMnar2F/i9/+YvYuXOnOHz4sBgyZAhvob9Pbr3bVAiOj67t379fmJiYiJSUFPHLL7+IjRs3CgsLC/HRRx9JdThGujV16lTRrVs36VEhW7ZsEZ07dxavvvqqVIdj1D6YvD1gVq1aJVxcXISZmZl49NFHpUdV0P0FQOtn3bp1Uh21Wi1ef/114ejoKORyuRg8eLA4duyYRjv//e9/xcyZM4WdnZ3o0KGDePLJJ0VZWVk7783D4fbkjeOje19++aXo3bu3kMvlwtPTU6xdu1ZjPcdIt2pqasScOXPEI488IszNzYW7u7tYtGiRqKurk+pwjNqHTAghdDnzR0RERETNx2veiIiIiAwIkzciIiIiA8LkjYiIiMiAMHkjIiIiMiBM3oiIiIgMCJM3IiIiIgPC5I2IiIjIgDB5IyLSA6GhoYiLi9N1GERkAJi8EZHemzZtGmQyWaPPqVOn2qT99evXw9bWtk3aaq0tW7bgjTfe0GkMd5Kfnw+ZTIaqqipdh0L00DPRdQBERM0RERGBdevWaZTZ29vrKJqmKZVKmJqatng7Ozu7+xBN21AqlboOgYhuwZk3IjIIcrkcjo6OGh9jY2MAwJdffol+/frB3Nwc7u7uWLJkCVQqlbTtW2+9BV9fX1haWsLZ2RmxsbG4evUqgJszSs8//zyqq6ulGb2kpCQAgEwmw9atWzXisLW1xfr16wEApaWlkMlk+OyzzxAaGgpzc3N89NFHAIB169bBy8sL5ubm8PT0xOrVq++4f7efNnV1dcXSpUsRHR0NhUIBFxcXbNu2DRcvXsTo0aOhUCjg6+uLgwcPSts0zCBu3boVPXv2hLm5OYYNG4Zz585p9JWVlQUPDw+YmZmhV69eyM7O1lgvk8mwZs0ajB49GpaWlvjrX/+KsLAwAEDHjh0hk8kwbdo0AEBubi6Cg4Nha2uLTp064cknn8Tp06elthqO0ZYtWxAWFgYLCwv06dMHP/zwg0af3333HUJCQmBhYYGOHTsiPDwcf/75JwBACIH09HS4u7ujQ4cO6NOnD/7973/f8XgSPdB0/G5VIqK7mjp1qhg9erTWdbm5ucLa2lqsX79enD59Wnz99dfC1dVVJCUlSXUyMjLE7t27xZkzZ8SuXbtEr169xMsvvyyEEKKurk5kZmYKa2trUV5eLsrLy8WVK1eEEEIAEP/3f/+n0Z+NjY1Yt26dEEKIs2fPCgDC1dVVbN68WZw5c0acP39erF27Vjg5OUllmzdvFnZ2dmL9+vVN7mNISIiYM2eOtOzi4iLs7OzEmjVrxM8//yxefvllYWVlJSIiIsRnn30mTp48KaKiooSXl5dQq9VCCCHWrVsnTE1NRUBAgPj+++/FwYMHRVBQkBg4cKDU7pYtW4SpqalYtWqVOHnypPjHP/4hjI2Nxe7du6U6AISDg4P44IMPxOnTp0VpaanYvHmzACBOnjwpysvLRVVVlRBCiH//+99i8+bN4ueffxZHjhwRo0aNEr6+vqK+vl7jGHl6eoqvvvpKnDx5UowdO1a4uLgIpVIphBDiyJEjQi6Xi5dfflkUFhaK48ePi5UrV4qLFy8KIYT4+9//Ljw9PUVubq44ffq0WLdunZDL5SI/P7/J40n0IGPyRkR6b+rUqcLY2FhYWlpKn7FjxwohhHj88cfFsmXLNOpnZ2cLJyenJtv77LPPRKdOnaTldevWCRsbm0b1mpu8ZWZmatRxdnYWH3/8sUbZG2+8IQYMGNBkTNqSt8mTJ0vL5eXlAoBITEyUyn744QcBQJSXl0v7AUDs27dPqlNSUiIAiB9//FEIIcTAgQPFiy++qNH3uHHjRGRkpMZ+x8XFadTZs2ePACD+/PPPJvdBCCEqKysFAHHs2DEhxP+O0fvvvy/VOXHihAAgSkpKhBBCTJw4UQwaNEhre1evXhXm5ubi+++/1yh/4YUXxMSJE+8YC9GDite8EZFBCAsLQ1ZWlrRsaWkJADh06BAOHDiAlJQUaV19fT2uX7+O2tpaWFhYYM+ePVi2bBmKi4tRU1MDlUqF69ev49q1a1I79yIgIED6/uLFizh37hxeeOEFvPjii1K5SqWCjY1Ni9r18/OTvu/SpQsAwNfXt1FZZWUlHB0dAQAmJiYa8Xh6esLW1hYlJSUICgpCSUkJ/va3v2n0M2jQILz99ttN7tOdnD59GomJidi3bx/++OMPqNVqAEBZWRl69+6tdV+cnJykuD09PVFYWIhx48Zpbb+4uBjXr1/HsGHDNMpv3LgBf3//ZsVI9KBh8kZEBsHS0hLdu3dvVK5Wq7FkyRKMGTOm0Tpzc3P8+uuviIyMxEsvvYQ33ngDdnZ22Lt3L1544YW7Xogvk8kghNAo07bNrQlgQ/Ly3nvvoX///hr1Gq7Ra65bb3yQyWRNljX0eXt5U2W3rxdCNCprblI7atQoODs747333kPXrl2hVqvRu3dv3Lhx46770hB3hw4dmmy/oc727dvRrVs3jXVyubxZMRI9aJi8EZFBe/TRR3Hy5EmtiR0AHDx4ECqVCv/4xz9gZHTzHq3PPvtMo46ZmRnq6+sbbWtvb4/y8nJp+ZdffkFtbe0d4+nSpQu6deuGM2fOYNKkSS3dnXumUqlw8OBBBAUFAQBOnjyJqqoqeHp6AgC8vLywd+9eREdHS9t8//338PLyumO7ZmZmAKBxnC5duoSSkhL885//xOOPPw4A2Lt3b4tj9vPzw65du7BkyZJG67y9vSGXy1FWVoaQkJAWt030IGLyRkQGbfHixXjyySfh7OyMcePGwcjICEVFRTh27BiWLl0KDw8PqFQqrFy5EqNGjcJ3332HNWvWaLTh6uqKq1evYteuXejTpw8sLCxgYWGBIUOG4N1338Vjjz0GtVqNhISEZj0GJCkpCbNnz4a1tTVGjBiBuro6HDx4EH/++Sfi4+Pv16EAcHOGa9asWXjnnXdgamqKmTNn4rHHHpOSuVdeeQXjx4/Ho48+iieeeAJffvkltmzZgp07d96xXRcXF8hkMnz11VeIjIxEhw4d0LFjR3Tq1Alr166Fk5MTysrKsGDBghbHvHDhQvj6+iI2NhYvvfQSzMzMsGfPHowbNw6dO3fG/PnzMXfuXKjVagQHB6Ompgbff/89FAoFpk6d2qrjRGTQdH3RHRHR3dzpblMhbt5xOnDgQNGhQwdhbW0tgoKCxNq1a6X1b731lnBychIdOnQQ4eHhYsOGDY0uvn/ppZdEp06dBADx+uuvCyGEOH/+vBg+fLiwtLQUPXr0EDk5OVpvWDhy5EijmDZu3Cj69u0rzMzMRMeOHcXgwYPFli1bmtwHbTcsZGRkaNTBbTdQ3N5/w40XmzdvFu7u7sLMzEwMGTJElJaWarSzevVq4e7uLkxNTUXPnj3Fhg0b7thPg+TkZOHo6ChkMpmYOnWqEEKIvLw84eXlJeRyufDz8xP5+fka22s7Rn/++acAIPbs2SOV5efni4EDBwq5XC5sbW1FeHi4ND5qtVq8/fbbolevXsLU1FTY29uL8PBwUVBQ0OTxJHqQyYS47YIOIiIySOvXr0dcXBzfgkD0gONDeomIiIgMCJM3IiIiIgPC06ZEREREBoQzb0REREQGhMkbERERkQFh8kZERERkQJi8ERERERkQJm9EREREBoTJGxEREZEBYfJGREREZECYvBEREREZECZvRERERAbk/wHHTCJehtX5VwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here we got importance of features owing to the data\n",
    "lgb.plot_importance(model, height=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2f0cfc",
   "metadata": {},
   "source": [
    "# Implementing LBGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d773d26d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Professional Softwares\\Anaconda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2568\n",
      "[LightGBM] [Info] Number of data points in the train set: 5116, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[1]\tvalid_0's multi_logloss: 1.21251\n",
      "Training until validation scores don't improve for 600 rounds\n",
      "[2]\tvalid_0's multi_logloss: 1.07976\n",
      "[3]\tvalid_0's multi_logloss: 0.971688\n",
      "[4]\tvalid_0's multi_logloss: 0.880329\n",
      "[5]\tvalid_0's multi_logloss: 0.808164\n",
      "[6]\tvalid_0's multi_logloss: 0.745515\n",
      "[7]\tvalid_0's multi_logloss: 0.687624\n",
      "[8]\tvalid_0's multi_logloss: 0.637887\n",
      "[9]\tvalid_0's multi_logloss: 0.596427\n",
      "[10]\tvalid_0's multi_logloss: 0.555697\n",
      "[11]\tvalid_0's multi_logloss: 0.520829\n",
      "[12]\tvalid_0's multi_logloss: 0.489036\n",
      "[13]\tvalid_0's multi_logloss: 0.463642\n",
      "[14]\tvalid_0's multi_logloss: 0.439787\n",
      "[15]\tvalid_0's multi_logloss: 0.41916\n",
      "[16]\tvalid_0's multi_logloss: 0.399951\n",
      "[17]\tvalid_0's multi_logloss: 0.382564\n",
      "[18]\tvalid_0's multi_logloss: 0.367559\n",
      "[19]\tvalid_0's multi_logloss: 0.353374\n",
      "[20]\tvalid_0's multi_logloss: 0.342008\n",
      "[21]\tvalid_0's multi_logloss: 0.331361\n",
      "[22]\tvalid_0's multi_logloss: 0.32216\n",
      "[23]\tvalid_0's multi_logloss: 0.313437\n",
      "[24]\tvalid_0's multi_logloss: 0.305947\n",
      "[25]\tvalid_0's multi_logloss: 0.300355\n",
      "[26]\tvalid_0's multi_logloss: 0.293578\n",
      "[27]\tvalid_0's multi_logloss: 0.288001\n",
      "[28]\tvalid_0's multi_logloss: 0.283733\n",
      "[29]\tvalid_0's multi_logloss: 0.279422\n",
      "[30]\tvalid_0's multi_logloss: 0.276269\n",
      "[31]\tvalid_0's multi_logloss: 0.272492\n",
      "[32]\tvalid_0's multi_logloss: 0.267762\n",
      "[33]\tvalid_0's multi_logloss: 0.264576\n",
      "[34]\tvalid_0's multi_logloss: 0.261252\n",
      "[35]\tvalid_0's multi_logloss: 0.257396\n",
      "[36]\tvalid_0's multi_logloss: 0.254816\n",
      "[37]\tvalid_0's multi_logloss: 0.251773\n",
      "[38]\tvalid_0's multi_logloss: 0.250684\n",
      "[39]\tvalid_0's multi_logloss: 0.248011\n",
      "[40]\tvalid_0's multi_logloss: 0.245386\n",
      "[41]\tvalid_0's multi_logloss: 0.244428\n",
      "[42]\tvalid_0's multi_logloss: 0.241693\n",
      "[43]\tvalid_0's multi_logloss: 0.240322\n",
      "[44]\tvalid_0's multi_logloss: 0.238909\n",
      "[45]\tvalid_0's multi_logloss: 0.237379\n",
      "[46]\tvalid_0's multi_logloss: 0.235542\n",
      "[47]\tvalid_0's multi_logloss: 0.233699\n",
      "[48]\tvalid_0's multi_logloss: 0.232952\n",
      "[49]\tvalid_0's multi_logloss: 0.230986\n",
      "[50]\tvalid_0's multi_logloss: 0.229831\n",
      "[51]\tvalid_0's multi_logloss: 0.227866\n",
      "[52]\tvalid_0's multi_logloss: 0.227619\n",
      "[53]\tvalid_0's multi_logloss: 0.224661\n",
      "[54]\tvalid_0's multi_logloss: 0.22381\n",
      "[55]\tvalid_0's multi_logloss: 0.223078\n",
      "[56]\tvalid_0's multi_logloss: 0.221668\n",
      "[57]\tvalid_0's multi_logloss: 0.22116\n",
      "[58]\tvalid_0's multi_logloss: 0.220017\n",
      "[59]\tvalid_0's multi_logloss: 0.219548\n",
      "[60]\tvalid_0's multi_logloss: 0.218346\n",
      "[61]\tvalid_0's multi_logloss: 0.217064\n",
      "[62]\tvalid_0's multi_logloss: 0.21611\n",
      "[63]\tvalid_0's multi_logloss: 0.215349\n",
      "[64]\tvalid_0's multi_logloss: 0.213892\n",
      "[65]\tvalid_0's multi_logloss: 0.213222\n",
      "[66]\tvalid_0's multi_logloss: 0.212945\n",
      "[67]\tvalid_0's multi_logloss: 0.21247\n",
      "[68]\tvalid_0's multi_logloss: 0.211735\n",
      "[69]\tvalid_0's multi_logloss: 0.211627\n",
      "[70]\tvalid_0's multi_logloss: 0.211473\n",
      "[71]\tvalid_0's multi_logloss: 0.210898\n",
      "[72]\tvalid_0's multi_logloss: 0.210258\n",
      "[73]\tvalid_0's multi_logloss: 0.209932\n",
      "[74]\tvalid_0's multi_logloss: 0.209713\n",
      "[75]\tvalid_0's multi_logloss: 0.209413\n",
      "[76]\tvalid_0's multi_logloss: 0.20948\n",
      "[77]\tvalid_0's multi_logloss: 0.209124\n",
      "[78]\tvalid_0's multi_logloss: 0.208126\n",
      "[79]\tvalid_0's multi_logloss: 0.20877\n",
      "[80]\tvalid_0's multi_logloss: 0.208758\n",
      "[81]\tvalid_0's multi_logloss: 0.208707\n",
      "[82]\tvalid_0's multi_logloss: 0.209141\n",
      "[83]\tvalid_0's multi_logloss: 0.20917\n",
      "[84]\tvalid_0's multi_logloss: 0.209161\n",
      "[85]\tvalid_0's multi_logloss: 0.209184\n",
      "[86]\tvalid_0's multi_logloss: 0.209081\n",
      "[87]\tvalid_0's multi_logloss: 0.209\n",
      "[88]\tvalid_0's multi_logloss: 0.208667\n",
      "[89]\tvalid_0's multi_logloss: 0.208342\n",
      "[90]\tvalid_0's multi_logloss: 0.207853\n",
      "[91]\tvalid_0's multi_logloss: 0.208201\n",
      "[92]\tvalid_0's multi_logloss: 0.208239\n",
      "[93]\tvalid_0's multi_logloss: 0.208502\n",
      "[94]\tvalid_0's multi_logloss: 0.208683\n",
      "[95]\tvalid_0's multi_logloss: 0.208774\n",
      "[96]\tvalid_0's multi_logloss: 0.208905\n",
      "[97]\tvalid_0's multi_logloss: 0.208984\n",
      "[98]\tvalid_0's multi_logloss: 0.209079\n",
      "[99]\tvalid_0's multi_logloss: 0.208853\n",
      "[100]\tvalid_0's multi_logloss: 0.208434\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[90]\tvalid_0's multi_logloss: 0.207853\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       335\n",
      "           1       0.93      0.96      0.94       158\n",
      "           2       0.68      0.65      0.67        26\n",
      "           3       0.50      0.78      0.61         9\n",
      "\n",
      "    accuracy                           0.94       528\n",
      "   macro avg       0.77      0.84      0.80       528\n",
      "weighted avg       0.95      0.94      0.94       528\n",
      "\n",
      "[[323   5   3   4]\n",
      " [  0 151   5   2]\n",
      " [  2   6  17   1]\n",
      " [  1   1   0   7]]\n",
      "Accuracy: 94.32%\n"
     ]
    }
   ],
   "source": [
    "Ytest = copy.copy(Y_test)\n",
    "Y_test=[]\n",
    "# print(Ytest)\n",
    "for i in Ytest:\n",
    "    Y_test.append(int(i))\n",
    "    \n",
    "\n",
    "# Light GBM :\n",
    "\n",
    "# defining parameters \n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_leaves': 7,\n",
    "    'learning_rate': 0.08,\n",
    "    'num_class': 4\n",
    "} \n",
    "\n",
    "\n",
    "# print(len(X_train),len(Y_train),len(X_test),len(Y_test))\n",
    "# laoding data\n",
    "lgb_train = lgb.Dataset(X_train, Y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, Y_test, reference=lgb_train)\n",
    " \n",
    "# fitting the model\n",
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 early_stopping_rounds=600)\n",
    "\n",
    "\n",
    "# prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "Y_pred = argmax(Y_pred, axis=1)\n",
    "cr = classification_report(Y_test, Y_pred)\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    " \n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edabd8f4",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2044bc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.94%\n"
     ]
    }
   ],
   "source": [
    "# Validation and tuning\n",
    "\n",
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "# print(len(X_val))\n",
    "# print(len(Y_val))\n",
    "\n",
    "train = xgb.DMatrix(Xtrain, label = Ytrain)\n",
    "test = xgb.DMatrix(X_val, label = Y_val)\n",
    "\n",
    "# specify hyperparameters\n",
    "params = {\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.21,\n",
    "    'num_class': 4\n",
    "}\n",
    "epochs = 10\n",
    "# train model\n",
    "model = xgb.train(params, train, epochs)\n",
    "# prediction\n",
    "y_pred = model.predict(test)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4adcd4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.35%\n"
     ]
    }
   ],
   "source": [
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "# print(len(X_val))\n",
    "# print(len(Y_val))\n",
    "\n",
    "train = xgb.DMatrix(Xtrain, label = Ytrain)\n",
    "test = xgb.DMatrix(X_val, label = Y_val)\n",
    "\n",
    "# specify hyperparameters\n",
    "params = {\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.21,\n",
    "    'num_class': 4\n",
    "}\n",
    "epochs = 15\n",
    "# train model\n",
    "model = xgb.train(params, train, epochs)\n",
    "# prediction\n",
    "y_pred = model.predict(test)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "823ec525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.23%\n"
     ]
    }
   ],
   "source": [
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "# print(len(X_val))\n",
    "# print(len(Y_val))\n",
    "\n",
    "train = xgb.DMatrix(Xtrain, label = Ytrain)\n",
    "test = xgb.DMatrix(X_val, label = Y_val)\n",
    "\n",
    "# specify hyperparameters\n",
    "params = {\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.21,\n",
    "    'num_class': 4\n",
    "}\n",
    "epochs = 20\n",
    "# train model\n",
    "model = xgb.train(params, train, epochs)\n",
    "# prediction\n",
    "y_pred = model.predict(test)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1fc0bc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.71%\n"
     ]
    }
   ],
   "source": [
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "# print(len(X_val))\n",
    "# print(len(Y_val))\n",
    "\n",
    "train = xgb.DMatrix(Xtrain, label = Ytrain)\n",
    "test = xgb.DMatrix(X_val, label = Y_val)\n",
    "\n",
    "# specify hyperparameters\n",
    "params = {\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.21,\n",
    "    'num_class': 4\n",
    "}\n",
    "epochs = 25\n",
    "# train model\n",
    "model = xgb.train(params, train, epochs)\n",
    "# prediction\n",
    "y_pred = model.predict(test)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c1a91cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.12%\n"
     ]
    }
   ],
   "source": [
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "# print(len(X_val))\n",
    "# print(len(Y_val))\n",
    "\n",
    "train = xgb.DMatrix(Xtrain, label = Ytrain)\n",
    "test = xgb.DMatrix(X_val, label = Y_val)\n",
    "\n",
    "# specify hyperparameters\n",
    "params = {\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.21,\n",
    "    'num_class': 4\n",
    "}\n",
    "epochs = 30\n",
    "# train model\n",
    "model = xgb.train(params, train, epochs)\n",
    "# prediction\n",
    "y_pred = model.predict(test)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fbb74844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.75%\n"
     ]
    }
   ],
   "source": [
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "# print(len(X_val))\n",
    "# print(len(Y_val))\n",
    "\n",
    "train = xgb.DMatrix(Xtrain, label = Ytrain)\n",
    "test = xgb.DMatrix(X_val, label = Y_val)\n",
    "\n",
    "# specify hyperparameters\n",
    "params = {\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.21,\n",
    "    'num_class': 4\n",
    "}\n",
    "epochs = 35\n",
    "# train model\n",
    "model = xgb.train(params, train, epochs)\n",
    "# prediction\n",
    "y_pred = model.predict(test)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a387200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.37%\n"
     ]
    }
   ],
   "source": [
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "# print(len(X_val))\n",
    "# print(len(Y_val))\n",
    "\n",
    "train = xgb.DMatrix(Xtrain, label = Ytrain)\n",
    "test = xgb.DMatrix(X_val, label = Y_val)\n",
    "\n",
    "# specify hyperparameters\n",
    "params = {\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.21,\n",
    "    'num_class': 4\n",
    "}\n",
    "epochs = 40\n",
    "# train model\n",
    "model = xgb.train(params, train, epochs)\n",
    "# prediction\n",
    "y_pred = model.predict(test)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711a2bd3",
   "metadata": {},
   "source": [
    "# Epoch = 40 gives best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c3a434d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.86%\n"
     ]
    }
   ],
   "source": [
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "# print(len(X_val))\n",
    "# print(len(Y_val))\n",
    "\n",
    "train = xgb.DMatrix(Xtrain, label = Ytrain)\n",
    "test = xgb.DMatrix(X_val, label = Y_val)\n",
    "\n",
    "# specify hyperparameters\n",
    "params = {\n",
    "    'max_depth': 2,\n",
    "    'eta': 0.21,\n",
    "    'num_class': 4\n",
    "}\n",
    "epochs = 20\n",
    "# train model\n",
    "model = xgb.train(params, train, epochs)\n",
    "# prediction\n",
    "y_pred = model.predict(test)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30b9856d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.11%\n"
     ]
    }
   ],
   "source": [
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "# print(len(X_val))\n",
    "# print(len(Y_val))\n",
    "\n",
    "train = xgb.DMatrix(Xtrain, label = Ytrain)\n",
    "test = xgb.DMatrix(X_val, label = Y_val)\n",
    "\n",
    "# specify hyperparameters\n",
    "params = {\n",
    "    'max_depth': 1,\n",
    "    'eta': 0.21,\n",
    "    'num_class': 4\n",
    "}\n",
    "epochs = 20\n",
    "# train model\n",
    "model = xgb.train(params, train, epochs)\n",
    "# prediction\n",
    "y_pred = model.predict(test)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "764a2161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.50%\n"
     ]
    }
   ],
   "source": [
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "# print(len(X_val))\n",
    "# print(len(Y_val))\n",
    "\n",
    "train = xgb.DMatrix(Xtrain, label = Ytrain)\n",
    "test = xgb.DMatrix(X_val, label = Y_val)\n",
    "\n",
    "# specify hyperparameters\n",
    "params = {\n",
    "    'max_depth': 5,\n",
    "    'eta': 1.25,\n",
    "    'num_class': 4\n",
    "}\n",
    "epochs = 20\n",
    "# train model\n",
    "model = xgb.train(params, train, epochs)\n",
    "# prediction\n",
    "y_pred = model.predict(test)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ee51ea68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.49%\n"
     ]
    }
   ],
   "source": [
    "Xtrain, X_val, Ytrain, Y_val = train_test_split(X_train, Y_train, \n",
    "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2\n",
    "# print(len(X_val))\n",
    "# print(len(Y_val))\n",
    "\n",
    "train = xgb.DMatrix(Xtrain, label = Ytrain)\n",
    "test = xgb.DMatrix(X_val, label = Y_val)\n",
    "\n",
    "# specify hyperparameters\n",
    "params = {\n",
    "    'max_depth': 4,\n",
    "    'eta': 0.21,\n",
    "    'num_class': 4\n",
    "}\n",
    "epochs = 20\n",
    "# train model\n",
    "model = xgb.train(params, train, epochs)\n",
    "# prediction\n",
    "y_pred = model.predict(test)\n",
    "\n",
    "accuracy = accuracy_score(Y_val, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d499ab1",
   "metadata": {},
   "source": [
    "# Max_depth = 2 gives the best accuracy, epoch =40 and eta=1.25 gives best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd0f5899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.13%\n"
     ]
    }
   ],
   "source": [
    "train = xgb.DMatrix(X_train, label = Y_train)\n",
    "test = xgb.DMatrix(X_test, label = Y_test)\n",
    "\n",
    "# specify hyperparameters\n",
    "params = {\n",
    "    'max_depth': 2,\n",
    "    'eta': 1.25,\n",
    "    'num_class': 4\n",
    "}\n",
    "epochs = 40\n",
    "# train model\n",
    "model = xgb.train(params, train, epochs)\n",
    "# prediction\n",
    "y_pred = model.predict(test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cc3e19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96380d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
